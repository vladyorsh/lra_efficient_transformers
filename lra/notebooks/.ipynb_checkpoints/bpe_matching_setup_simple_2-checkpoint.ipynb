{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0_XMgEPOh7c",
    "outputId": "41697cb2-da6d-47ab-a70d-e6a89e917457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 29 09:49:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGGnygXCDXLf",
    "outputId": "f78f78fc-8a25-40e8-eee9-492e94c97c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'long-range-arena'...\n",
      "remote: Enumerating objects: 474, done.\u001b[K\n",
      "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
      "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
      "remote: Total 474 (delta 330), reused 418 (delta 278), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (474/474), 153.25 KiB | 2.95 MiB/s, done.\n",
      "Resolving deltas: 100% (330/330), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/long-range-arena.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrMqZQQmd-vh",
    "outputId": "a8ae9ad6-efe1-4d77-dbe5-b1f831e99e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "\u001b[K     |█████████████                   | 834.1 MB 1.2 MB/s eta 0:16:18tcmalloc: large alloc 1147494400 bytes == 0x55563d936000 @  0x7f940b731615 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a5bd00 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x5556049ea039 0x555604a2d409 0x5556049e8c52 0x555604a5bc25 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a57915 0x5556049e9afa 0x555604a57c0d 0x555604a569ee\n",
      "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:58tcmalloc: large alloc 1434370048 bytes == 0x555681f8c000 @  0x7f940b731615 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a5bd00 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x5556049ea039 0x555604a2d409 0x5556049e8c52 0x555604a5bc25 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a57915 0x5556049e9afa 0x555604a57c0d 0x555604a569ee\n",
      "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:59tcmalloc: large alloc 1792966656 bytes == 0x555606dbe000 @  0x7f940b731615 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a5bd00 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x5556049ea039 0x555604a2d409 0x5556049e8c52 0x555604a5bc25 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a57915 0x5556049e9afa 0x555604a57c0d 0x555604a569ee\n",
      "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:57tcmalloc: large alloc 2241208320 bytes == 0x555671ba6000 @  0x7f940b731615 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a5bd00 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x555604adac66 0x555604a57daf 0x5556049ea039 0x555604a2d409 0x5556049e8c52 0x555604a5bc25 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a57915 0x5556049e9afa 0x555604a57c0d 0x555604a569ee\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0x5556f7508000 @  0x7f940b7301e7 0x555604a1b067 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x5556049e9afa 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee\n",
      "tcmalloc: large alloc 2551644160 bytes == 0x555770fc8000 @  0x7f940b731615 0x5556049e54cc 0x555604ac547a 0x5556049e82ed 0x555604ad9e1d 0x555604a5be99 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a57c0d 0x5556049e9afa 0x555604a57c0d 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049e9bda 0x555604a58737 0x555604a569ee 0x5556049ea271\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 5.8 kB/s \n",
      "\u001b[?25hCollecting torchvision==0.10.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting torchaudio==0.9.1\n",
      "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 4.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (1.19.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.0+cu111\n",
      "    Uninstalling torchaudio-0.10.0+cu111:\n",
      "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.1+cu111 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.1+cu111 torchaudio-0.9.1 torchvision-0.10.1+cu111\n"
     ]
    }
   ],
   "source": [
    "#Execute if A100 is the current GPU\n",
    "\n",
    "!pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9IIWd0wuEWQ",
    "outputId": "f1da2b6f-6af0-4f3b-a6a0-aa76c9a0fae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-29 09:50:00--  https://storage.googleapis.com/long-range-arena/lra_release.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 172.217.218.128, 142.250.153.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8288700910 (7.7G) [application/octet-stream]\n",
      "Saving to: ‘lra_release.gz’\n",
      "\n",
      "lra_release.gz      100%[===================>]   7.72G  51.7MB/s    in 2m 40s  \n",
      "\n",
      "2021-11-29 09:52:41 (49.5 MB/s) - ‘lra_release.gz’ saved [8288700910/8288700910]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/long-range-arena/lra_release.gz\n",
    "!gzip -d lra_release.gz\n",
    "!tar -xf lra_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxhp_XoYk9lj",
    "outputId": "ee9414c1-7a68-46a8-dd84-0bfd2ea3e619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_text\n",
      "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 15.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
      "Installing collected packages: tensorflow-text\n",
      "Successfully installed tensorflow-text-2.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATXw-aRr0sg-",
    "outputId": "6722ce78-f57f-457d-8668-538ea1eb78cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/long-range-arena\n",
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.train.tsv\n",
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.eval.tsv\n",
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.test.tsv\n",
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    }
   ],
   "source": [
    "%cd /content/long-range-arena\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lra_benchmarks.matching.input_pipeline import get_matching_datasets\n",
    "\n",
    "batch_size=4\n",
    "accumulation_steps=32 // batch_size\n",
    "max_length=4000\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset, encoder = get_matching_datasets(1, None, tokenizer='char', data_dir='/content/lra_release/lra_release/tsv_data', batch_size=batch_size, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gz5sK3-MwaHQ",
    "outputId": "c541b090-7aa8-4a06-c464-4d386aeb0e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['inputs1', 'inputs2', 'targets'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GV8HdFQJN8Pj",
    "outputId": "6bb30b77-b1d6-416b-f9de-2e0299410d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1 Introduction ?Contact center? is a general term for customer service centers, help desks, and information phone lines. Many companies operate contact centers to sell their products, handle customer issues, and address product-related and services-related issues. In contact centers, analysts try to get insights for improving business processes from stored customer contact data. Gigabytes of customer contact records are produced every day in the form of audio recordings of speech, transcripts, call summaries, email, etc. Though analysis by experts results in insights that are very deep and useful, such analysis usually covers only a very small (1-2%) fraction of the total call volume and yet requires significant workload. The demands for extracting trends and knowledge from the whole text data collection by using text mining technology, therefore, are increasing rapidly. In order to acquire valuable knowledge through text mining, it is generally critical to identify important expressions to be monitored and compared within the textual data. For example, given a large collection of contact records at the contact center of a manufacturer, the analysis of expressions for products and expressions for problems often leads to business value by identifying specific problems in a specific product. If 30% of the contact records with expressions for a specific product such as ?ABC? contain expressions about a specific trouble such as ?cracked?, while the expressions about the same trouble appear in only 5% of the contact records for similar products, then it should be a clue that the product ?ABC? may actually have a crack-related problem. An effective way to facilitate this type of analysis is to register important expressions in a lexicon such as ?ABC? and ?cracked? as associated respectively with their categories such as ?product? and ?problem? so that the behavior of terms in the same category can be compared easily. It is actually one of the most important steps of text mining to identify such relevant expressions and their categories that can potentially lead to some valuable insights. A failure in this step often leads to a failure in the text mining. Also, it has been considered an artistic task that requires highly experienced consul458 tants to define such categories, which are often described as the viewpoint for doing the analysis, and their corresponding expressions through trial and error. In this paper, we propose a method to identify important segments of textual data for analysis from full transcripts of conversations. Compared to the written summary of a conversation, a transcription of an entire conversation tends to be quite lengthy and contains various forms of redundancy. Many of the terms appearing in the conversation are not relevant for specific analysis. For example, the terms for greeting such as ?Hello? and ?Welcome to (Company A)? are unlikely to be associated with specific business results such as purchased-or-not and satisfied-or-not, especially because the conversation is transcribed without preserving the nonverbal moods such as tone of voice, emotion etc. Thus it is crucial to identify key segments and notable expressions within conversations for analysis to acquire valuable insights. We exploit the fact that business conversations followset patterns such as an opening followed by a request and the confirmation of details followed by a closing, etc. By taking advantage of this feature of business conversations, we have developed a method to identify key segments and the notable expressions within conversations that tend to discriminate between the business results. Such key segments, the trigger segments, and the notable expressions associated with certain business results lead us to easily understand appropriate viewpoints for analysis. Application of our method for analyzing nearly one thousand conversations from a rental car reservation office enabled us to acquire novel insights for improving agen\n",
      "b'Introduction  Measuring the representativeness (i.e., the  informativeness or domain specificity) of a term? is  essential to various tasks in natural language  processing (NLP) and information retrieval (IR).  Such a measure is particularly crucial to automatic  dictionary construction and IR interfaces to show a  user words indicative of topics in retrievals that  often consist of an intractably large number of  documents (Niwa et al 2000).  This paper proposes a novel and effective  measure of term representativeness that reflects the  bias of the words co-occurring with a term. In the  following, we focus on extracting topic words from  an archive of newspaper articles.   In the literature of NLP and IR, there have been  a number of studies on term weighting, and these are  strongly related to measures of term                                                     ? A term is a word or a word sequence.   representativeness (see section 1). In this paper we  employ the basic idea of the ?baseline method?  proposed by Hisamitsu (Hisamitsu et al 2000). The  idea is that the distribution of words co-occurring  with a representative term should be biased  according to the word distribution of the whole  corpus. Concretely, for any term T and any measure  M for the degree of bias of word occurrences in  D(T), a set of words co-occurring with T, according  to those of the whole corpus D0, the baseline method  defines representativeness of term T by normalizing  M(D(T)). In what follows, D0 is an archive of  newspaper articles and D(T) is defined as the set of  all articles containing T.   The normalization of M(D(T)) is done by a  function BM, called the baseline function, which  estimates the value of M(Drand) using #Drand for any  randomly sampled document (in our case, ?article?)  set Drand, where #Drand stands for the total number of  words contained in Drand. By dividing M(D(T)) by  BM(#D(T)), comparison of M(D(T1)) and M(D(T2))  becomes meaningful even if the frequencies of T1  and T2 are very different. We denote this normalized  value by NormM(D(T)).    Hisamitsu et al reported that NormM(D(T)) is  very effective in capturing topic-specific words  when M(D(T)) is defined as the distance between  two word distributions PD(T) and P0 (see subsection  1.2), which we denote by Dist(D(T)).   Although NormDist(D(T)) outperforms existing  measures, it has still an intrinsic drawback shared by  other measures, that is, words which are irrelevant to  T and simply happen to occur in D(T) --- let us call  these words non-typical words --- contribute tothe  calculation of M(D(T)). Their contribution  accumulates as background noise in M(D(T)), which  is the part to be offset by the baseline function. In  other words, if M(D(T)) were to exclude the  contribution of non-typical words, it would not need  to be normalized and would be more precise.   This consideration led us to propose a different  approach to measure the bias of word occurrences in   a discrete way: that is, we only take words whose  occurrences are saliently biased in D(T) into account,  and let the number of such words be the degree of  bias of word occurrences in D(T). Thus, SAL(D(T),  s), the number of words in D(T) whose saliency is  over a threshold value s, is expected to be free from  the background noise and sensitive to number of  major subtopics in D(T). The essential problem now  is how to define the saliency of bias of word  occurrences and the threshold value of saliency. This  paper solves this problem by giving a  mathematically sound measure. Furthermore, it is  shown that the optimal threshold value can be  defined automatically. The newly defined measure  SAL(D(T), s) outperforms existing measures in  picking out topic-specific words from newspaper  articles.    1. Brief review of term representativeness   measures   1.1 Conventional measures  Regarding term weighting, various measures of  importance or domain specificity of a term have  been proposed \n",
      "\n",
      "b'1 Introduction Word Sense Disambiguation (WSD, see (Agirre and Edmonds, 2006) for an extensive overview) is commonly seen as an enabling technology for applications like semantic parsing, semantic role labeling and semantic retrieval. Throughout recent years, the Senseval and Semeval competitions have shown that a) WordNet as-is is not an adequate semantic resource for reaching high precision and b) supervised WSD approaches outperform unsupervised (i.e. not using sense-annotated examples) approaches. Due to the manual effort involved in creating more adequate word sense inventories and sense-annotated training data, WSD has yet to see its prime-time in real world applications. Since WordNet?s sense distinctions are often too fine-grained for allowing reliable distinctions by machines and humans, the OntoNotes project (Hovy et al, 2006) conflated similar WordNet senses until 90% inter-annotator agreement on sense-labelling was reached. The SemEval 2007 lexical sample task employs this ?coarse-grained? inventory, which allows for higher system performance. To alleviate the bottleneck of sense-labelled sentences, (Biemann and Nygaard, 2010) present an approach for acquiring a sense inventory along with sense-annotated example usages using crowdsourcing, which makes the acquisition process cheaper and potentially quicker. Trying to do away with manual resources entirely, the field of Word Sense Induction aims at inducing the inventory from text corpora by clustering occurrences or senses according to distributional similarity, e.g. (Veronis, 2004). While such unsupervised and knowledge-free systems are capable of discriminating well between different usages, it is not trivial to link their distinctions to existing semantic resources, which is often necessary in applications. Topic Signatures (Mart??nez et al, 2008) is an attempt to account for differences in relevant topics per target word. Here, a large number of contexts for a given sense inventory are collected automatically using relations from a semantic resource, sense by sense. The most discriminating content words per sense are used to identify a sense in an unseen context. This approach is amongst the most successful methods in the field. It requires, however, a semantic resource of sufficient detail and size and a sense-labeled corpus to estimate priors from the sense distribution. Here, a similar approach is described that uses an unlabeled 55 corpus alone for unsupervised topic signature acquisition using graph clustering, not relying on the existence of a WordNet. Unlike in previous evaluations like (Agirre et al, 2006), parameters for word sense induction are not optimized globally, but instead several parameter settings are offered as features to a Machine Learning setup. Experimental results are provided for two datasets: the Semeval-2007 lexical sample task (Pradhan et al., 2007) and the Turk bootstrap Word Sense Inventory (TWSI1, (Biemann and Nygaard, 2010) ). 2 Cluster Co-occurrence Features 2.1 Graph Preperation and Parameterization Similar to the approach in (Widdows and Dorow, 2002), a word graph around each target word is constructed. In this work, sentence-based co-occurrence statistics from a large corpus are used as a basis to to construct several word graphs for different parameterizations. Significant co-occurrences between all content words (nouns, verbs, adjectives as identified by POS tagging) are computed from a large corpus using the tinyCC2 tool. The full word graph fora target word is defined as all words significantly co-occurring with the target as nodes, with edge weights set to the log-likelihood significance of the co-occurrence between the words corresponding to nodes. Edges between words that co-occur only once or with significance smaller than 6.63 (1% confidence level) are omitted. Aiming at different granularities of usage clusters, the graph is parameterized by a size parameter t and a density parameter n: Only the most significant \n",
      "b'1 Introduction Semantic knowledge for particular domains is increasingly important in NLP. Many applications such as Word-Sense Disambiguation, Information Extraction and Speech Recognition all require lexicons. The coverage of handbuilt lexical resources such as WordNet (Fellbaum, 1998) has increased dramatically in recent years, but leaves several problems and challenges. Coverage is poor in many critical, rapidly changing domains such as current affairs, medicine and technology, where much time is still spent by human experts employed to recognise and classify new terms. Most languages remain poorly covered in comparison with English. Hand-built lexical resources which cannot be automatically updated can often be simply misleading. For example, using WordNet to recognise that the word apple refers to a fruit or a tree is a grave error in the many situations where this word refers to a computer manufacturer, a sense which WordNet does not cover. For NLP to reach a wider class of applications in practice, the ability to assemble and update appropriate semantic knowledge automatically will be vital. This paper describes a method for arranging semantic information into a graph (Bolloba?s, 1998), where the nodes are words and the edges (also called links) represent relationships between words. The paper is arranged as follows. Section 2 reviews previous work on semantic similarity and lexical acquisition. Section 3 describes how the graph model was built from the PoS-tagged British National Corpus. Section 4 describes a new incremental algorithm used to build categories of words step by step from the graph model. Section 5 demonstrates this algorithm in action and evaluates the results against WordNet classes, obtaining state-of-the-art results. Section 6 describes how the graph model can be used to recognise when words are polysemous and to obtain groups of words representative of the different senses. 2 Previous Work Most work on automatic lexical acquisition has been based at some point on the notion of semantic similarity. The underlying claim is that words which are semantically similar occur with similar distributions and in similar contexts (Miller and Charles, 1991). The main results to date in the field of automatic lexical acquisition are concerned with extracting lists of words reckoned to belong together in a particular category, such as vehicles or weapons (Riloff and Shepherd, 1997) (Roark and Charniak, 1998). Roark and Charniak describe a ?generic algorithm? for extracting such lists of similar words using the notion of semantic similarity, as follows (Roark and Charniak, 1998, ?1). 1. For a given category, choose a small set of exemplars (or ?seed words?) 2. Count co-occurrence of words and seed words within a corpus 3. Use a figure of merit based upon these counts to select new seed words 4. Return to step 2 and iterate n times 5. Use a figure of merit to rank words for category membership and output a ranked list Algorithms of this type were used by Riloff and Shepherd (1997) and Roark and Charniak (1998), reporting accuracies of 17% and 35% respectively. Like the algorithm we present in Section 5, the similarity measure (or ?figure of merit?) used in these cases was basedon cooccurrence in lists. Both of these works evaluated their results by asking humans to judge whether items generated were appropriate members of the categories sought. Riloff and Shepherd (1997) also give some credit for ?related words? (for example crash might be regarded as being related to the category vehicles). One problem with these techniques is the danger of ?infections? ? once any incorrect or out-of-category word has been admitted, the neighbours of this word are also likely to be admitted. In Section 4 we present an algorithm which goes some way towards reducing such infections. The early results have been improved upon by Riloff and Jones (1999), where a ?mutual bootstrapping? approach is used to extract words in particular se\n",
      "\n",
      "b'1 Introduction Traditionally, NLG systems have been built as deterministic decision-makers, that is to say, they generate one string of words for any given input, in a sequence of decisions that increasingly specify the word string. In practice, this has meant carefully handcrafting generators to make decisions locally, at each step in the generation process. Such generators tend to be specialised and domain-specific, are hard to adapt to new domains, or even subdomains, and have no way of dealing with incomplete or incorrect input. Wide-coverage tools only exist for surface realisation, and tend to require highly specific and often idiosyncratic inputs. The rest of NLP has reached a stage where state-of-the-art tools are expected to be generic: wide-coverage, reusable and robust. NLG is lagging behind the field on all three counts. The last decade has seen a new generation of NLG methodologies that are characterised by a separation between the definition of the generation space (all possible generation processes from inputs to outputs) on the one hand, and control over the decisions that lead to a (set of) output realisation(s), on the other. In making this separation, generate-and-select NLG takes several crucial steps towards genericity: reusing systems becomes easier if the selection mechanism can be adjusted or replaced separately, without changing the definition of the generation space; coverage can be increased more easily if every expansion of the generation space does not have to be accompanied by handcrafted rules controlling the resulting increase in nondeterminism; and certain types of selection methods can provide robustness, for example through probabilistic choice. Statistical generation has aroused by far the most interest among these methods, and it has mostly meant n-gram selection: a packed representation of all alternative (partial) realisations is produced, and an n-gram language model is applied to select the most likely realisation. N -gram methods have several desirable properties: they offer a fully automatic method for building and adapting control mechanisms for generate-and-select NLG from raw corpora (reusability); they base selections on statistical models (robustness); and they can potentially be used for deep as well as surface generation. However, n-gram models are expensive to apply: in order to select the most likely realisation according to an n-gram model, all alternative realisations have to be generated and the probability of each realisation according to the model has to be calculated. This can get very expensive (even if packed representations of the set of alternatives are used), especially when the system accepts incompletely specified input, because the number of alternatives can be vast. In Halogen, Langkilde [2000] deals with trillions of alternatives, and the generator used in the experiments reported in this paper has up to 1040 alternative realisations (see Section 4.3 for empirical evidence of the relative inefficiency of n-gram generation). Furthermore, n-gram models have a built-in bias towards shorter strings. This is because they calculate the likelihood of a string of words as the joint probability of the words, or, more precisely, as the product of the probabilities of each word given the n? 1 preceding words. The likelihood of any string willtherefore generally be lower than that of any of its substrings (see Section 4.3 for empirical evidence of this bias). This is wholly inappropriate for NLG where equally good realisations can vary greatly in length (see Section 5 for discussion of normalisation for length in statistical modelling). The research reported in this paper is part of an ongoing research project1 the purpose of which is to investigate issues in generic NLG. The experiments (Section 4.3) were carried out to evaluate and compare different methods for exploiting the frequencies of word sequences and word sequence cooccurrences in raw text corpora to build mo\n",
      "b'INTRODUCTION  It has been traditionally assumed by  computational linguists and particularly by  designers of large natural language processing  systems such as machine translation systems that  the lexicon should be limited to lexical  information that cannot be derived by rules.  According to this view, a lexicon consists of a  list of basic morphemes along with irregular or  unpredictable words.  In this paper, I would like to reexamine this  traditional view of the lexicon and point out some  of the problems it faces which seriously question  the general adequacy of this model for natural  language processing.  As a trade-off between the often conflicting  linguistic, computational and also practical  considerations, an alternative conception of the  lexicon will be discussed, largely based on  Jackendoff\\'s (1975) proposal. According to this  view, lexical entries are fully-specified but  related to one another. First developed for a  French parser (cf. Wehrli, 1984), this model has  been adopted for an English parser in development,  as well as for the prototype of a French-English  translation system.  This paper is organized as follows: the first  section addresses the general issue of what  constitutes a lexical entry as well as the  question of the relation between lexicon and  morphology from the point of view of both  theoretical linguistics and computational  linguistics. Section 2 discusses the relational  word-based model of the lexicon and the role  morphology is assigned in this model. Finally, it  spells out some of the details of the  implementation of this model.  OVERVIEW OF THE PROBLSM  One of the well-known characteristic features  of natural languages is the size and the  complexity of their lexicons. This is in sharp  constrast with artificial languages, which  typically have small lexicons, in most cases made  up of simple, unambiguous lexical items. Not only  do natural languages have a huge number of lexical  elements -- no matter what precise definition of  this latter term one chooses -- but these lexical  elements can furthermore (i) be ambiguous in  several ways (ii) have a non-trivial internal  structure, or (iii) be part of compounds or  idiomatic expressions, as illustrated in (1)-(A):  (I) ambiguous words:  can, fly, bank, pen, race, etc.  (2) internal structure:  use-ful-ness, mis-understand-ing, lake-s,  tri-ed  (3) compounds:  milkman, moonlight, etc.  (4) idiomatic expressions:  to kick the bucket, by and large,  to pull someone\\'s leg, etc.  In fact, the notion of word, itself, is not  all that clear, as numerous linguists --  theoreticians and/or computational linguists --  have acknowledged. Thus, to take an example from  the computational linguistics literature, Kay  (1977) notes:  \"In common usage, the term word refers  sometimes to sequences of letters that  can be bounded by spaces or punctuation  marks in a text. According to thisview,  run, runs, runnin~ and ran are  different words. But common usage also  allows these to count as instances of  the same word because they belong to the  146  same paradigm in English accidence and  are listed in the same entry in the  dictionary.\"  Some of these problems, as well as the  general question of what constitutes a lexical  entry, whether or not lexical items should be  related to one another, etc. have been much  debated over the last I0 or 15 years within the  framework of generative grammar. Considered as a  relatively minor appendix of the phrase-structure  rule component in the early days of generative  grammar, the lexicon became little by little an  autonomous component of the grammar with its own  specific formalism -- lexical entries as matrices  of features, as advocated by Chomsky (1965).  Finally, it also acquired specific types of rules,  the so-called word formation rules (cf. Halle,  1973; Aronoff, 1976; Lieber, 1980; Selkirk, 1983,  and others), and lexical redundancy rules (cf.  Jackendoff, 1975; Bresnan, 1977).  By a\n",
      "\n",
      "b'1 Introduction The training of single word based translation models (Brown et al, 1993b; Vogel et al, 1996) is an essential building block for most state-of-the-art translation systems. Indeed, even more refined translation models (Wang and Waibel, 1998; Sumita et al, 2004; Deng and Byrne, 2005; Fraser and Marcu, 2007a) are initialized by the parameters of single word based ones. The exception is here the joint approach of Marcu and Wong (2002), but its refinement by Birch et al (2006) again relies on the wellknown IBM models. Traditionally (Brown et al, 1993b; Al-Onaizan et al, 1999) single word based models are trained by the EM-algorithm, which has the advantageous property that the collection of counts can be decomposed over the sentences. Refinements that also allow symmetrized models are based on bipartite graph matching (Matusov et al, 2004; Taskar et al, 2005) or quadratic assignment problems (LacosteJulien et al, 2006). Recently, Bodrumlu et al (2009) proposed the first method that treats a nondecomposable problem by handling all sentence pairs at once and via integer linear programming. Their (non-probabilistic) approach finds dictionaries with a minimal number of entries. However, the approach does not include a position model. In this work we combine the two strategies into a single framework. That is, the dictionary sparsity objective of Bodrumlu et al will become a regularity term in our framework. It is combined with the maximal alignment probability of every sentence pair, where we consider the models IBM-1, IBM-2 and HMM. This allows us to write dictionary sparsity as the (non-convex) L0 norm of the dictionary parameters of the respective models. For supervised training, regularity terms are quite common, e.g. (Taskar et al, 2005; Lacoste-Julien et al., 2006). For the unsupervised problem addressed in this paper they have recently been introduced in the form of posterior constraints (Ganchev et al, 2010). In related fields of NLP lately Dirichlet priors have been investigated, e.g. (Johnson, 2007). We present two strategies to handle the objective function addressed in this paper. One of these schemes relies, like (Germann et al, 2004; LacosteJulien et al, 2006; DeNero and Klein, 2008; Bodrumlu et al, 2009), on integer linear programming 172 (see e.g. (Schrijver, 1986; Achterberg, 2007)), but due to the large-scale nature of our problem we solve only the LP-relaxation, followed by successive strengthening. For the latter, we develop our own, exponentially large set of cuts and show that it can be handled as a polynomially sized system, though in practice this is too inefficient. 2 The Models Before we introduce our objective function we give a brief description of the (standard) models we consider. In all cases, one is given a set of bilingual sentence pairs containing a foreign language and English. The models formalize the probability of obtaining the foreign sentence from a given English sentence, by considering hidden variables called alignments: pd,l(fs|es) = ? as pd,l(fs,as|es) . Here, the subscripts d and l denote two sets of parameters: whereas the set l defines the probability of an alignment without knowing any of the sentences, d describes the translational probabilitygiven an alignment and a source sentence. For a source (English) sentence of length I and a target (foreign) sentence of length J , the set of admissible alignments is generally the set of subsets of {1, . . . , I} ? {1, . . . , J}. However, for computational reasons the considered models only allow restricted alignments, where each target word may align to at most one source word. Any such alignment is expressed as a vector aJ1 ? {0, . . . , I} J . 2.1 Considered models For a source sentence es = eI1 and a target sentence f s = fJ1 , the considered models all factor as follows: pd,l(f s,as|es) = (1) J? j=1 pd(fj |eaj ) ? pl(aj |aj?1, j, I) In all cases, the translational probability is nonparametric, i.e. d contains one parameter fo\n",
      "b'1 Introduction There has been tremendous recent interest in opinion mining from online product reviews and it?s effect on customer purchasing behavior. In this work, we present a novel alternative categorization of comments in online reviews as either being qualified claims or bald claims. Comments in a review are claims that reviewers make about the products they purchase. A customer reads the reviews to help him/her make a purchasing decision. However, comments are often open to interpretation. For example, a simple comment like this camera is small is open to interpretation until qualified by more information about whether it is small in general (for example, based on a poll from a collection of people), or whether it is small compared to some other object. We call such claims bald claims. Customers hesitate to rely on such bald claims unless they identify (from the context or otherwise) themselves to be in a situation similar to the customer who posted the comment. The other category of claims that are not bald are qualified claims. Qualified claims such as it is small enough to fit easily in a coat pocket or purse are more precise claims as they give the reader more details, and are less open to interpretation. Our notion of qualified claims is similar to that proposed in the argumentation literature by Toulmin (1958). This distinction of qualified vs. bald claims can be used to filter out bald claims that can?t be verified. For the qualified claims, the qualifier can be used in personalizing what is presented to the reader. The main contributions of this work are: (i) an annotation scheme that distinguishes qualified claims from bald claims in online reviews, and (ii) a supervised machine learning approach that uses syntactic features to learn this distinction. In the remainder of the paper, we first motivate our work based on a customer behavior study. We then describe the proposed annotation scheme, followed by our supervised learning approach. We conclude the paper with a discussion of our results. 2 Customer Behavior Study In order to study how online product reviews are used to make purchasing decisions, we conducted a user study. The study involved 16 pair of graduate students. In each pair there was a customer and an observer. The goal of the customer was to decide which camera he/she would purchase using a camera review blog1 to inform his/her decision. As the customer read through the reviews, he/she was 1http://www.retrevo.com/s/camera 37 asked to think aloud and the observer recorded their observations. The website used for this study had two types of reviews: expert and user reviews. There were mixed opinions about which type of reviews people wanted to read. About six customers could relate more with user reviews as they felt expert reviews were more like a ?sales pitch?. On the other hand, about five people were interested in only expert reviews as they believed them to be more practical and well reasoned. From this study, it was clear that the customers were sensitive to whether a claim was qualified or not. About 50%of the customers were concerned about the reliability of the comments and whether it applied to them. Half of them felt it was hard to comprehend whether the user criticizing a feature was doing so out of personal bias or if it represented a real concern applicable to everyone. The other half liked to see comments backed up with facts or explanations, to judge if the claim could be qualified. Two customers expressed interest in comments from users similar to themselves as they felt they could base their decision on such comments more reliably. Also, exaggerations in reviews were deemed untrustworthy by at least three customers. 3 Annotation Scheme We now present the guidelines we used to distinguish bald claims from qualified claims. A claim is called qualified if its validity or scope is limited by making the conditions of its applicability more explicit. It could be either a fact or a stat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample1 = next(iter(train_dataset))\n",
    "sample1, sample2 = sample1['inputs1'], sample1['inputs2']\n",
    "\n",
    "for i in range(min(4, batch_size)):\n",
    "  print(encoder.decode(sample1[i]))\n",
    "  print(encoder.decode(sample2[i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4ZHtbE300dO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TEmbedding(nn.Module):\n",
    "  def __init__(self, num_embeddings, hidden_dim, seq_length=1024, padding_idx=0):\n",
    "    super(TEmbedding, self).__init__()\n",
    "    \n",
    "    self.num_embeddings = num_embeddings\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.seq_length = seq_length\n",
    "    self.padding_idx = padding_idx\n",
    "\n",
    "    self.embedding = nn.Embedding(num_embeddings, hidden_dim, padding_idx)\n",
    "    self.pos_embeds  = nn.Parameter(torch.zeros(1, self.seq_length, self.hidden_dim))\n",
    "\n",
    "    self.cls = nn.Parameter(torch.zeros(1, 1, self.hidden_dim)) #!!!!!!! INIT WITH ANOTHER VALUE IF REQUIRED\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size, seq_len = input.shape\n",
    "    \n",
    "    embed = self.embedding(input)\n",
    "    embed = embed + self.pos_embeds\n",
    "    embed = torch.cat([ self.cls.expand(batch_size, 1, -1), embed ], axis=1)\n",
    "\n",
    "    return embed\n",
    "    \n",
    "class TAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(TAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "    \n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "\n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    q = torch.mul(q, 1. / torch.sqrt(torch.tensor(self.qkv_dim)))\n",
    "\n",
    "    qk = torch.matmul(q, k.transpose(-1, -2))\n",
    "    qk = nn.Softmax(dim=-1)(qk)\n",
    "\n",
    "    def assertion_function(tsr):\n",
    "      tsr = torch.sum(tsr, axis=-1)\n",
    "      tsr = tsr - torch.ones_like(tsr)\n",
    "      return torch.max(torch.abs(tsr)) < 1e-5\n",
    "\n",
    "    assert assertion_function(qk)\n",
    "\n",
    "    qk = self.dropout(qk) #Like in TF implementation; could be done before Softmax by random -inf addition\n",
    "\n",
    "    out = torch.matmul(qk, v)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "\n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class HWLinear(nn.Module):\n",
    "  def __init__(self, num_heads, input_dim, output_dim, use_bias):\n",
    "    super(HWLinear, self).__init__()\n",
    "    \n",
    "    self.use_bias = use_bias\n",
    "    if use_bias:\n",
    "      self.bias   = nn.Parameter(torch.zeros( (1, num_heads, 1, output_dim)))\n",
    "\n",
    "    self.weight = nn.Parameter(torch.empty( (num_heads, input_dim, output_dim)))\n",
    "\n",
    "    def he_init(m):\n",
    "      s =  np.sqrt( 2. / input_dim )\n",
    "      m.data.normal_(0, s)\n",
    "\n",
    "    he_init(self.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.matmul(x, self.weight)\n",
    "    if self.use_bias:\n",
    "      x += self.bias\n",
    "    return x\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "  def __init__(self, lambda_, objects=None):\n",
    "      super(Lambda, self).__init__()\n",
    "      self.lambda_ = lambda_\n",
    "      self.objects = objects\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.objects is not None:\n",
    "      return self.lambda_(self.objects, x)\n",
    "    return self.lambda_(x)\n",
    "\n",
    "class LKAAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(LKAAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   = qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    #self.lka = nn.Sequential(\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.GELU(),\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.Softplus(beta=2.5),\n",
    "    #)\n",
    "\n",
    "    #256, 4, 16, 1024\n",
    "    #256, 64, 1, 1024\n",
    "    class AMGOLU(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, gate_rank, dropout_rate, gate_nonlinearity, kernel_nonlinearity, use_bias=False):\n",
    "        super(AMGOLU, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads= num_heads\n",
    "        \n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "\n",
    "        self.gate_weight_a = HWLinear(num_heads, self.head_dim, gate_rank, use_bias)\n",
    "        self.gate_weight_b = HWLinear(num_heads, gate_rank, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        forward_info = self.orth_weight(x)\n",
    "        forward_info = self.kernel_nonlinearity(forward_info)\n",
    "\n",
    "        gate_info = self.gate_weight_a(x)\n",
    "        gate_info = self.gate_weight_b(gate_info)\n",
    "        gate_info = self.gate_nonlinearity(gate_info)\n",
    "\n",
    "        x = forward_info * gate_info\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    class GatedOrthoKernel(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, dropout_rate=0.1, gate_nonlinearity=nn.Sigmoid(), kernel_nonlinearity=nn.Identity(), use_bias=False):\n",
    "        super(GatedOrthoKernel, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "        self.gate_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.kernel_nonlinearity(self.orth_weight(x)) * self.gate_nonlinearity(self.gate_weight(x))\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "\n",
    "    class HeadWiseFF(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, dropout_rate, nonlinearity=nn.Identity(), use_bias=False, residual=False):\n",
    "        super(HeadWiseFF, self).__init__()\n",
    "        \n",
    "        head_dim = qkv_dim // num_heads\n",
    "\n",
    "        self.bias   = nn.Parameter(torch.empty( (1, num_heads, 1, head_dim)))\n",
    "        self.dropout= nn.Dropout(dropout_rate)\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.weight = nn.Parameter(torch.empty( (num_heads, head_dim, head_dim)))\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "\n",
    "        #Orthogonal initialization\n",
    "        #Workaround with torch.stack, since Torch initializes a tensor as orthgonal by flattening its trailing dims and QR-factorizing the resulting 2d\n",
    "        \n",
    "        #self.weight = torch.stack([ nn.init.orthogonal_(torch.empty((head_dim, head_dim))) for _ in range(num_heads) ], dim=0)\n",
    "        #self.weight = nn.Parameter(self.weight)\n",
    "\n",
    "        bound = 1 / math.sqrt(head_dim)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.residual= residual\n",
    "\n",
    "      def forward(self, x):\n",
    "        \n",
    "        x, losses = x\n",
    "\n",
    "        bs, hd, seq, hdim = x.shape\n",
    "        y = self.dropout(x)\n",
    "        y = torch.matmul(y, self.weight) #BS, HD, SEQ, HDIM\n",
    "        if self.use_bias:\n",
    "          y += self.bias\n",
    "        y = self.nonlinearity(y)\n",
    "\n",
    "        #loss = torch.eye(hdim, device=self.weight.device).unsqueeze(0).expand(* self.weight.shape)\n",
    "        #loss = nn.MSELoss()(torch.matmul(self.weight, self.weight.transpose(-1, -2)), loss)\n",
    "        #loss *= LAMBDA\n",
    "\n",
    "        #losses.append(loss)\n",
    "\n",
    "        if self.residual:\n",
    "          return x + y, losses\n",
    "        return y, losses\n",
    "\n",
    "    self.lka = nn.Sequential(\n",
    "        \n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False),\n",
    "        \n",
    "        #HeadWiseFF(self.num_heads, self.qkv_dim, dropout_rate, nn.Softplus(), use_bias=False),\n",
    "        \n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False)\n",
    "\n",
    "        #Lambda(lambda o, x: (o['act'](x[0]), x[1]), { 'act' : nn.Identity() })\n",
    "        \n",
    "    )\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    #BS x HEADS x SEQ x HEAD_DIM\n",
    "    \n",
    "    q, _ = self.lka((q, losses))\n",
    "    k, _ = self.lka((k, losses)) #Use this for var kernel\n",
    "\n",
    "    q = q / math.sqrt(self.head_dim)\n",
    "    k = k / math.sqrt(self.head_dim)\n",
    "\n",
    "    numerator = torch.matmul(k.unsqueeze(-1), v.unsqueeze(-2))\n",
    "    numerator = numerator.sum(axis=2)\n",
    "    numerator = torch.matmul(q, numerator)\n",
    "    \n",
    "    denominator = k.sum(axis=2).unsqueeze(-1)\n",
    "    denominator = q.matmul(denominator)\n",
    "\n",
    "    out = numerator / denominator\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    #TODO: INSERT DROPOUT\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(SimpleAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    #self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v) #BS x HEADS x SEQ x HEAD_DIM\n",
    "\n",
    "    _, _, seq_len, _ = q.shape\n",
    "\n",
    "    kv = torch.matmul(k.transpose(-1, -2), v)\n",
    "    kv *= 1 / math.sqrt(seq_len)\n",
    "    kv = self.dropout(kv)\n",
    "\n",
    "    out = torch.matmul(q, kv)\n",
    "    #out *= 1 / math.sqrt(self.head_dim)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    #out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class FtAttention(nn.Module):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super(FtAttention, self).__init__()\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    return torch.fft.fft(torch.fft.fft(x, dim=-1), dim=-2).real\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, mlp_dim, num_heads, dropout_rate):\n",
    "    super(TBlock, self).__init__()\n",
    "\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.qkv_dim  = qkv_dim\n",
    "    self.mlp_dim  = mlp_dim\n",
    "\n",
    "    self.layernorm_input = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "    self.layernorm_inter = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "    self.attention = TAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, mlp_dim), nn.GELU(), nn.Dropout(dropout_rate),\n",
    "        nn.Linear(mlp_dim, hidden_dim), nn.Dropout(dropout_rate),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input, losses=[]):\n",
    "    x = self.layernorm_input(input)\n",
    "    x = self.attention(x, losses)\n",
    "\n",
    "    x = input + x\n",
    "\n",
    "    y = self.layernorm_inter(x)\n",
    "    x = self.ffn(y) + x\n",
    "\n",
    "    return x\n",
    "\n",
    "class TClassifier(nn.Module):\n",
    "  def __init__(self, classes, hidden_dim, inter_dim, dropout_rate):\n",
    "    super(TClassifier, self).__init__()\n",
    "\n",
    "    self.layernorm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "    self.dropout   = nn.Dropout(dropout_rate)\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, inter_dim), nn.GELU(),\n",
    "    )\n",
    "    self.output    = nn.Linear(inter_dim, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layernorm(x)\n",
    "    x = x[:, 0, :]\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    x = self.ffn(x)\n",
    "    logits = self.output(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class DualClassifier(nn.Module):\n",
    "  def __init__(self, classes, hidden_dim, inter_dim):\n",
    "    super(DualClassifier, self).__init__()\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim * 2, inter_dim), nn.ReLU(),\n",
    "        nn.Linear(inter_dim, inter_dim // 2), nn.ReLU(),\n",
    "    )\n",
    "    self.output    = nn.Linear(inter_dim // 2, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    emb_1, emb_2 = x\n",
    "    x = torch.cat([ emb_1, emb_2 ], dim=-1)\n",
    "    x = x[:, 0, :]\n",
    "    x = self.ffn(x)\n",
    "    logits = self.output(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, classes, num_embeddings, seq_len, hidden_dim, qkv_dim, mlp_dim, num_heads, num_blocks, internal_dropout_rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "    \n",
    "    self.embed_layer = TEmbedding(num_embeddings, hidden_dim, seq_len)\n",
    "    self.blocks      = nn.ModuleList([ TBlock(hidden_dim, qkv_dim, mlp_dim, num_heads, internal_dropout_rate) for _ in range(num_blocks) ])\n",
    "    self.classifier  = DualClassifier(classes, hidden_dim, mlp_dim)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    additional_losses = []\n",
    "\n",
    "    emb_1 = self.embed_layer(inputs[0])\n",
    "    emb_2 = self.embed_layer(inputs[1])\n",
    "\n",
    "    for block in self.blocks:\n",
    "      emb_1 = block(emb_1, additional_losses)\n",
    "      emb_2 = block(emb_2, additional_losses)\n",
    "    \n",
    "    x = self.classifier((emb_1, emb_2))\n",
    "\n",
    "    return x, additional_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKl9SMDoCJeK"
   },
   "outputs": [],
   "source": [
    "def num_parameters(model):\n",
    "  return sum(list(map(\n",
    "      lambda x: np.prod(x[1].shape), model.named_parameters()\n",
    "  )))\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "def model_factory():\n",
    "  model = Transformer(\n",
    "    classes   =n_classes,\n",
    "    num_embeddings=encoder.vocab_size,\n",
    "    seq_len=max_length,\n",
    "    hidden_dim=128,\n",
    "    qkv_dim=128,\n",
    "    num_heads =4,\n",
    "    num_blocks=4,\n",
    "    mlp_dim=512,\n",
    "    internal_dropout_rate=0.1,\n",
    "  ).cuda()\n",
    "  \n",
    "  orig_count = num_parameters(model)\n",
    "\n",
    "  for block in model.blocks:\n",
    "    #block.attention = FtAttention()\n",
    "    #block.attention = LKAAttention(128, 128, 8, 0.1).cuda()\n",
    "    block.attention = SimpleAttention(128, 128, 8, 0.1).cuda()\n",
    "    ...\n",
    "  \n",
    "  new_count = num_parameters(model)\n",
    "  print(f'Original model {orig_count} params, new model {new_count} params, ratio {new_count / orig_count:.3}')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "l0P77jbqTEqK",
    "outputId": "5a9ef4cf-e394-462c-d706-39266f7a99cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb5103bd4d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xW5f3/8dcnCQmGkUAIM4GEvefNcisO1CpaqYIKVEUUpbZaa7Xj29bWXx21WuvEiThYLtQqDtyy7rBBRgx7hrBByLp+f9xHm6QJCWScO8n7+XjcD859netc53Muct+f+5zrDHPOISIi8oMIvwMQEZHwosQgIiKFKDGIiEghSgwiIlKIEoOIiBQS5XcAFaFJkyYuJSXF7zBERKqVtLS0Xc65xKLlNSIxpKSkEAwG/Q5DRKRaMbMNxZXrUJKIiBSixCAiIoUoMYiISCFKDCIiUogSg4iIFKLEICIihSgxiIhIIUoMIj47nJ3LjLTN7D+S43coIkANucBNpLrKz3fcNnUxs1bsoMn70dw5tDPD+yYREWF+hya1mPYYRHz0yCdrmbViB2NPTaV141junLGUnz75DUs27fU7NKnFtMcg4pP3lm7j0U/W8rN+Sfz+oi44B28u2sLf31/FpU98zRX9kvnN0E40qR/jd6hSy2iPQcQHy7fs49fTF9OvTSP+dll3zIyICOPyfkl8escZ3HBaW15fuJmz/vEZL3y9jpy8fL9DllpEiUGkimUeOMq4l4I0io3mqWv6ERMVWWh+g7p1+N2FXfjgV6fTOzmev7yzkvMf/oJZK7ajZ7RLVVBiEKlCR3PzuOnlNHYfzuaZ0QESG5R8mKh90/q8dN0AnhsTICLCuHFyGlc+PZfFGn+QSqbEIFJFnHP88a3lpG3Yw0M/6033VnGlLmNmDOnSjA9+eRr3XtadjF0HufTxr/nFa4vYtPtwFUQttZESg0gVeeHr9UwLbubWs9tzUc8Wx7VsVGQEVw9sw2e/OYtbz27PRyu3M+Shz7n3vZXsPZxdSRFLbaXEIFIFvliTyd/eW8n53Zrxq3M6nnA79WOiuP28Tnx2x1kM692SZ79ax2n3f8qjn6zl4NHcCoxYajOrCYNZgUDA6QluEq4yMkOHf1rGn8Tr40+mXkzFnSW+avt+/vnhGj5cuYPG9aIZf0Y7Rg1uQ906kaUvLLWemaU55wJFy7XHIFKJ9h/JYexLQaIiI3hmdKBCkwJA5+YNmTg6wFu3nEK3lg259z/fcsaDn/Ly3A1k5+oUVzkxSgwilSQv3/GLVxexMeswT17dl+TGsZW2rt7J8Uy+fiBTxg0iuVEsf3hrOUP++Rkz0jaTq2sg5DgpMYhUkvs/WMXnazK5Z1h3BrZNqJJ1DmqbwPSbBvPCtf2JO6kOd0xfwtkPfc6U+Ru1ByFlpsQgUglmpG1m4hcZjB7chqsGtq7SdZsZZ3VqyjsTTuWZ0QHiY+tw1xvLOOsfnzF5znqO5ORVaTxS/WjwWaSCLdy4hxFPzyWQ0ohJ1w2gTqS/v7+cc3y+JpN/z04nbcMemjWMYdzp7bhqQGtOitYgdW1W0uCzEoNIBdq273sueexrYqMjeevmU2hUL9rvkH7knGPOd1k8OnstczN2k1AvmutPS+XqgW2IO6mO3+GJD5QYRCrZ99l5XPH0HNbtOsQbN59Mx2YN/A6pRAvW7+bRT9by5dpd1I+JYuSAZK47NZUWcSf5HZpUISUGkUrknOPWKYt5d+lWnhkV4JyuzfwOqUyWb9nHxC8yeG/ZNgy4pHdLxp3els7NG/odmlSBcl3HYGZDzWy1maWb2V3FzI8xs6ne/HlmllJg3t1e+WozO7+0Ns3sRTNbZ2aLvVfv491Ykar2xGff8c6Srfzm/E7VJikAdG8Vx6Mj+/DZHWcyanAb3l+2naGPfMmY5+fzzXe7dDfXWqrUPQYziwTWAOcCm4EFwEjn3MoCdW4GejrnbjKzEcBlzrkrzawr8BowAGgJfAz8cD+AYts0sxeBd51zM8q6EdpjED99uGI74yanMax3Sx65sjdm1fexnHsPZ/Py3A28+M16dh3MpkerOK47NYULe7T4n9uDS/VXnj2GAUC6cy7DOZcNTAGGFakzDJjkTc8Ahljo0zEMmOKcO+qcWweke+2VpU2RsLd6+wFum7qYXklx3H95z2qdFADiY6OZcHYHvvrt2fy/y3pwKDuX26Yu4ZT7PuXhj9aw88ARv0OUKlCWxNAK2FTg/WavrNg6zrlcYB+QcIxlS2vzXjNbamYPm1mxN6w3s3FmFjSzYGZmZhk2Q6Ri7T6UzdiXFlAvJoqnRwVq1P2J6taJ5KqBrfn4tjN46boB9EyK41+frOWU+2bzqymL9EyIGi4cn/l8N7AdiAYmAr8F7ilayTk30ZtPIBDQgVCpUjl5+dz8Sho79h9l6rhBNI+r63dIlSIiwji9YyKnd0xk3a5DvDRnPdODm3lr8VZ6J8dz7SkpXNC9BdFRula2JinL/+YWILnA+ySvrNg6ZhYFxAFZx1i2xDadc9tcyFHgBUKHnUTCyl/eWcHcjN3cf3kP+rRu5Hc4VSK1ST3+dHE35v5uCH+5pBv7vs/hl1MWc/J9s3lw1io9OKgGKUtiWAB0MLNUM4sGRgAzi9SZCYzxpocDs11oVHsmMMI7aykV6ADMP1abZtbC+9eAS4Hl5dlAkYo2ee4GXp67kRvPaMtlfZL8DqfK1Y+JYszJKXxy+xm8cG1/eifH8eRn33H6g58y5vn5fLhiu27cV82VeijJOZdrZhOAWUAk8LxzboWZ3QMEnXMzgeeAyWaWDuwm9EWPV28asBLIBW5xzuUBFNemt8pXzCwRMGAxcFPFba5I+cz5Lou/zFzB2Z2bcuf5nf0Ox1cREaF7Mp3VqSlb937PlAWbmLpgI+Mmp9G8YV2u6J/MiP7JtIzXRXPVjS5wEymjjVmHGfb4VyTUj+HNm0+mQV3dRqKo3Lx8Zq/aySvzNvLF2kwMOLtzU64a2JrTOyQS5fN9o6Swkk5XDcfBZ5Gwc/BoLje8FCTfwbOjA0oKJYiKjOC8bs05r1tzNu0+zJQFG5m6YDMffxukaYMYLuvbip/1S6Z90/p+hyrHoD0GkVLk5ztufDmN2at2MunaAZzaoYnfIVUrOd5exPTgZj5dvZO8fEef1vEM75fExb1a0lBJ1je6V5LICfrHrNU89mk6f764Kz8/JdXvcKq1zANHeWvRFqanbWLNjoPEREUwtHtzhvdL4pR2TYiIqN4XCFY3SgwiJ+CdJVv5xWuLGNE/mb//tEe1v7I5XDjnWLZlH9ODm3l78Rb2H8mlZVxdLu3Tikv7tArrO9PWJEoMIsdp2eZ9DH/qG3omxfHK2EG6iKuSHMnJ46OVO5ietpmv1maS76BLi4Zc2rsll/RuqVuBVyIlBpHjsPPAES7599dERhhvTziFJvWLvTOLVLDMA0d5d+lW3lq8lSWb9mIGA1Iac2mfVlzYvQVxsRqPqEhKDCJldCQnj5HPzGXVtgPMGD+Ybi3j/A6pVlq36xAzF2/l7cVbyNh1iOjICM7slMiw3q0Y0qVpjbo3lV+UGETKwDnHHdOX8vrCzTx5dV8u6NHC75BqvR/GI95atJV3lm4l88BR6kVHcnaXZlzUozlndlKSOFG6jkGkDJ77ah2vL9zMr87poKQQJsyMnknx9EyK5/cXdWHOd1m8t2wrHyzfzjtLthIbHcnZnZtyUY8WnNmpKSdFK0mUl/YYRDyfrt7J9S8uYGj35jw2sq9OnQxzuXn5zM3YzXvLtjFrxXZ2H8omNjqSs7wkcZaSRKl0KEnkGNJ3HuSyx78mqXEsr48fTGy0dqark9y8fOat85LE8u1kHcrmpDqhPYnzuzfnzE6JupCuGEoMIiXYdziHS5/4mv3f5/D2hFNIahTrd0hSDrl5+cxf9989iV0Hs6kTaQxqm8B5XZtxbtfmNfb5GcdLiUGkGLl5+Vz74gLmZmTx6g2D6J/S2O+QpALl5TsWbdzDRyt3MGvFdtZnhZ4Z0SspjnO7NuO8bs3p0LR+rb1wUYlBpBh/fXclz321jvsv78GV/Vv7HY5UIucc6TsP8uHKHXy4cgdLvMeTpiTE/pgk+rZuRGQtGltSYhApYtqCTdz5+lKuPSWFP13cze9wpIrt2H+Ej7wkMee7XeTkOeJj63BGx0TO7tyU0zsk0qhetN9hViolBpECgut3M/KZuQxMTeDFa/vrOQG13IEjOXy2OpNPV+/k89WZZB3KJsKgT+tGnNUpkbM6N6Vri4Y17pCTEoOIZ8ve7xn22FfUj4nirVtOIT62Zv8qlOOTn+9YumUfs1ft5LPVO1m6eR8AzRrGcFanppzZqSmndmhC/Zjqf+aaEoMIcDg7l+FPzmHT7sO8ecvJtG+qu3jKse08cITPvb2JL9fs4sDRXOpEGgNSG3N6h0RO65BIlxYNquXehBKD1HrOOSa8uoj/LN/G82P6c1bnpn6HJNVMTl4+wfV7+HT1Tj5dtZO1Ow8C0KR+DKd1aMKp7ZtwWocmNG1YPU6HVWKQWu/RT9byz4/WcPcFnbnxjHZ+hyM1wPZ9R/gqfRdfrs3kq7W7yDqUDUDn5g1CSaJjIgNSGoftFdhKDFKrfbB8Oze9nMZP+7TioSt6Vcvdfglv+fmOb7fv58u1oUSxYP0esnPziY6KoH9KI07rkMip7ZvQpUXDsDklVolBaq1vt+3n8ie/oWOzBkwZN0h34pQq8X12HvPX7+bLNZl8lb6LVdsPANCwbhQD2yYwuG0CJ7dPoGPTBr7dl0t3V5VaKevgUcZOCtKgbhQTR/VTUpAqc1J0JGd0TOSMjokA7Nx/hDkZWXyTnsWcjCw+WrkDgMb1ohnUtjGD2yYwuF0C7RL9vxJbiUFqrOzcfMa/spBdB48y7cbB1WZAUGqmpg3rMqx3K4b1bgWETpue812W99rFf5ZtByCxQQyD2iZwcrvQXkWbhNgqTxRKDFIjOef408wVzF+3m3+N6E2v5Hi/QxIppFX8SQzvl8Twfkk459i4+3AoSWSEksU7S7YC0LxhXQakNmZAamMGpjamfRXc20mJQWqkyXM38Nr8jdx8Zrsff6GJhCszo01CPdok1GPEgNY45/gu8xBzMrKYv243czOymOklisb1oumf0oj+KY0ZmJpAlxYNKvzK/TIlBjMbCvwLiASedc7dV2R+DPAS0A/IAq50zq335t0NXA/kAbc652aVsc1Hgeucc/VPeOukVvomfRd/eWcl53Rpyh3ndfI7HJHjZma0b1qf9k3rM2pQmx/3KOat28187zVrRWiM4t1fnEr3VhX7XPJSE4OZRQKPA+cCm4EFZjbTObeyQLXrgT3OufZmNgK4H7jSzLoCI4BuQEvgYzPr6C1TYptmFgAaVcgWSq2yIesQN7+6kHaJ9Xj4yt56CpvUCAX3KK4IJAOhayjmr99NlxYNK3x9Zdn/GACkO+cynHPZwBRgWJE6w4BJ3vQMYIiFDoINA6Y4544659YB6V57JbbpJaIHgTvLt2lS2xw4ksPYSaHTlp8ZHaCBntglNVjzuLpc0qtlpVwTUZbE0ArYVOD9Zq+s2DrOuVxgH5BwjGWP1eYEYKZzbtuxgjKzcWYWNLNgZmZmGTZDarK8fMevpiwmY9chnriqL20S6vkdkki1FVb3GjazlsDPgH+XVtc5N9E5F3DOBRITEys/OAlr//hwNZ+s2smfL+7Kye2b+B2OSLVWlsSwBUgu8D7JKyu2jplFAXGEBqFLWrak8j5AeyDdzNYDsWaWXsZtkVrq7cVbePKz77hqYGuuGdTG73BEqr2yJIYFQAczSzWzaEKDyTOL1JkJjPGmhwOzXeheGzOBEWYWY2apQAdgfkltOufec841d86lOOdSgMPOufbl3UipuZZs2sudM5YyMLUxf764m+9XjIrUBKWeleScyzWzCcAsQqeWPu+cW2Fm9wBB59xM4DlgsvfrfjehL3q8etOAlUAucItzLg+guDYrfvOkJtux/wjjJgdJbBDDE1f3JToqrI6MilRbuomeVEtHcvK4cuJc1u44wOvjT66UU/ZEajrdRE9qDOccd7+xjCWb9vL0qH5KCiIVTPveUu1M/CKDNxdt4dfnduT8bs39DkekxlFikGpl9qod3PfBKn7SswUTztZ5CSKVQYlBqo30nQe49bXFdG3RkAeH6ylsIpVFiUGqhb2Hs7l+UpC6dSJ5ZnQgbJ+hK1ITKDFI2MvNy+eWVxeybe8Rnh7Vj5bxJ/kdkkiNprOSJOz97b1v+To9iweH96RfG910V6SyaY9BwtqU+Rt58Zv1jD01lZ8FkktfQETKTYlBwtb8dbv549vLOb1jIndd0NnvcERqDSUGCUub9xxm/MtpJDeK5d8j+1T4owtFpGT6tEnYOXQ0l7GTgmTn5fPMmABxJ+mBOyJVSYlBwkp+vuOO6UtYs+MAj13Vl3aJeuS3SFVTYpCw8q9P1vL+8u387sIunNFRD2AS8YMSg4SN/yzbxr8+Wcvwfklcf2qq3+GI1FpKDBIWVmzdx6+nLaFv63juvay7bnch4iMlBvFd5oGj3DApSHxsHZ4a1Y+YKN3uQsRPuvJZfJWdm8/4l9PYfTibGTedTNMGdf0OSaTWU2IQ3zjn+ONbywlu2MNjV/Whe6s4v0MSEXQoSXz04jfrmRrcxC/Obs9Perb0OxwR8SgxiC++XJvJX99dyXldm3HbOR39DkdEClBikCq3btchbnllIR2bNeDhK3sTEaEzkETCiRKDVKn9R3IYO2kBUZERPDM6QL0YDXOJhBslBqkyefmOW19bxIaswzxxdV+SG8f6HZKIFEM/16TKPPDBKj5bncm9l3VnUNsEv8MRkRJoj0GqxOtpm3n6iwxGDWrD1QPb+B2OiByDEoNUuoUb93D3G8sY3DaB/7u4q9/hiEgplBikUm3fd4QbJ6fRPK4uT1zdlzp64I5I2CvTp9TMhprZajNLN7O7ipkfY2ZTvfnzzCylwLy7vfLVZnZ+aW2a2XNmtsTMlprZDDPTDfmrqSM5eYybHOTw0VyeHROgUb1ov0MSkTIoNTGYWSTwOHAB0BUYaWZFjwdcD+xxzrUHHgbu95btCowAugFDgSfMLLKUNm9zzvVyzvUENgITyrmN4gPnHHfOWMqyLfv414g+dGzWwO+QRKSMyrLHMABId85lOOeygSnAsCJ1hgGTvOkZwBAL3Td5GDDFOXfUObcOSPfaK7FN59x+AG/5kwBXng0Ufzz5+XfMXLKVO87rxDldm/kdjogch7IkhlbApgLvN3tlxdZxzuUC+4CEYyx7zDbN7AVgO9AZ+HdxQZnZODMLmlkwMzOzDJshVeXjlTt4cNZqLunVkpvPbOd3OCJynMJyJNA5dy3QEvgWuLKEOhOdcwHnXCAxUY+ADBdrdhzgl1MW0aNVHA8M76kH7ohUQ2VJDFuA5ALvk7yyYuuYWRQQB2QdY9lS23TO5RE6xHR5GWKUMLDnUDZjJwWJjYli4qgAdevogTsi1VFZEsMCoIOZpZpZNKHB5JlF6swExnjTw4HZzjnnlY/wzlpKBToA80tq00Law49jDJcAq8q3iVIVcvLyufmVhWzff4SJo/rRPE4P3BGprkq9JYZzLtfMJgCzgEjgeefcCjO7Bwg652YCzwGTzSwd2E3oix6v3jRgJZAL3OLtCVBCmxHAJDNrCBiwBBhfsZssleGv765kTkYW/7yiF31aN/I7HBEpBwv9sK/eAoGACwaDfodRa70ybwO/f3M5N57elrsv7OJ3OCJSRmaW5pwLFC0Py8FnqT7mZmTxp7dXcFanRO4c2tnvcESkAigxyAnbtPsw419Oo01CLP8a2YdIPXBHpEZQYpATcvBoLmMnBcnLdzw7pj8N69bxOyQRqSB6HoMct/x8x+1TF5OeeZAXr+1PapN6fockIhVIewxy3B7+eA0frtzBHy7qwmkddHGhSE2jxCDH5Z0lW/n37HSuDCTz85NT/A5HRCqBEoOU2fIt+/jNjCX0T2nEXy/trttdiNRQSgxSJjsPHOGGl4I0jo3myWv6ER2lPx2RmkqDz1Kqo7l53DQ5jb2Hc5gxfjBN6sf4HZKIVCIlBjkm5xy/f3M5Czfu5cmr+9KtZZzfIYlIJdPxADmm575ax4y0zfxySAcu6NHC73BEpAooMUiJPl+Tyf/7z7dc0L05vxzSwe9wRKSKKDFIsb7LPMiEVxfSqXlDHrqiFxG63YVIraHEIP9j3/c53DApSHRkBM+M7kdstIaiRGoTfeKlkNy8fH7x2iI27TnMqzcMIqlRrN8hiUgVU2KQQu57fxVfrMnkvp/2oH9KY7/DEREf6FCS/Gh6cBPPfrWOn5+cwogBrf0OR0R8osQgAKRt2M3v31zOqe2b8IeL9BQ2kdpMiUHYuvd7bpy8kJbxdXnsqj5ERerPQqQ20xhDLfd9dh7jJgc5kpPHlHEDiY+N9jskEfGZEkMt5pzjjhlLWLF1P8+NCdC+aQO/QxKRMKBjBrXYY7PTeW/pNn47tDNnd27mdzgiEiaUGGqpD5Zv56GP1nBZn1bceHpbv8MRkTCixFALrdq+n9unLaZXcjx//2kPPXBHRApRYqhlsg4eZeykIA3qRjFxVD/q1on0OyQRCTMafK5FsnPzGf/KQnYeOMr0GwfTrGFdv0MSkTBUpj0GMxtqZqvNLN3M7ipmfoyZTfXmzzOzlALz7vbKV5vZ+aW1aWaveOXLzex5M6tTvk0UCJ2B9Od3VjB/3W4eHN6TXsnxfockImGq1MRgZpHA48AFQFdgpJl1LVLtemCPc6498DBwv7dsV2AE0A0YCjxhZpGltPkK0BnoAZwEjC3XFgoAL8/dwKvzNjL+zHYM693K73BEJIyVZY9hAJDunMtwzmUDU4BhReoMAyZ50zOAIRYa0RwGTHHOHXXOrQPSvfZKbNM59x/nAeYDSeXbRPkmfRd/fmclQzo35Y7zOvkdjoiEubIkhlbApgLvN3tlxdZxzuUC+4CEYyxbapveIaRRwAfFBWVm48wsaGbBzMzMMmxG7bQh6xA3v7qQtk3q8ciI3kTqgTsiUopwPivpCeAL59yXxc10zk10zgWcc4HExMQqDq16OHAkh7GTgjgHz44J0KCuhmtEpHRlOStpC5Bc4H2SV1Zcnc1mFgXEAVmlLFtim2b2JyARuLEM8Ukx8vIdt01dTMauQ0y+bgBtEur5HZKIVBNl2WNYAHQws1QziyY0mDyzSJ2ZwBhvejgw2xsjmAmM8M5aSgU6EBo3KLFNMxsLnA+MdM7ll2/zaq+HPlzNx9/u5E8Xd+Xk9k38DkdEqpFS9xicc7lmNgGYBUQCzzvnVpjZPUDQOTcTeA6YbGbpwG5CX/R49aYBK4Fc4BbnXB5AcW16q3wK2ADM8a7IfcM5d0+FbXEt8PbiLTzx2XeMHNCaUYPa+B2OiFQzFvphX70FAgEXDAb9DiMsLNm0lyuenkOv5Hhevn4g0VHhPIwkIn4yszTnXKBoub41apCd+48wbnKQJvVjePLqvkoKInJCdEuMGuJITh7jJqdx4Egur48/mYT6MX6HJCLVlBJDDeCc43dvLGPxpr08dU0/urRo6HdIIlKN6VhDDfDMlxm8sWgLt5/bkaHdm/sdjohUc0oM1dynq3by9/dXcVGPFvzi7PZ+hyMiNYASQzWWvvMAt762iK4tGvLgz3rqgTsiUiGUGKqpfYdDt7uIqRPBxNEBYqM1XCQiFUPfJtVQbl4+t7y6kC17v2fKuEG0ij/J75BEpAZRYqiG7v3Pt3yVvosHhvekX5vGfocjIjWMDiVVM1MXbOSFr9dz/ampXBFILn0BEZHjpMRQjSxYv5s/vLWc0zo04e4LOvsdjojUUEoM1cSWvd9z0+Q0khvF8tjIvkRF6r9ORCqHvl2qgcPZuYydFCQ7L59nxgSIi9UDd0Sk8igxhLn8fMevpy1h9fb9/HtkH9ol1vc7JBGp4ZQYwtyjs9fy/vLt/O7CLpzZqanf4YhILaDEEMbeX7aNRz5ey+V9k7j+1FS/wxGRWkKJIUyt3Lqf26ctoU/reO69rLtudyEiVUaJIQztOniUG14KEh9bh6dH9aNunUi/QxKRWkRXPoeZ7Nx8xr+cRtaho0y/8WSaNqjrd0giUssoMYQR5xz/9/ZyFqzfw79H9qFHUpzfIYlILaRDSWFk0jfrmbJgExPOas/FvVr6HY6I1FJKDGHiq7W7+Ot733Ju12bcfm5Hv8MRkVpMiSEMrNt1iFteXUj7xPo8fGVvIiJ0BpKI+EeJwWf7j+Rww0tBIgyeHROgfoyGfUTEX/oW8lFevuOXry1i/a5DTL5+IMmNY/0OSUREicFPD8xaxaerM/nbpd0Z3C7B73BERIAyHkoys6FmttrM0s3srmLmx5jZVG/+PDNLKTDvbq98tZmdX1qbZjbBK3Nm1qR8mxe+3ly0mac/z+CaQa25ZlAbv8MREflRqYnBzCKBx4ELgK7ASDPrWqTa9cAe51x74GHgfm/ZrsAIoBswFHjCzCJLafNr4BxgQzm3LWwt2riH376+jEFtG/Oni7v5HY6ISCFl2WMYAKQ75zKcc9nAFGBYkTrDgEne9AxgiIVu7jMMmOKcO+qcWweke+2V2KZzbpFzbn05tytsbd93hBsnp9GsYQxPXN2POnrgjoiEmbJ8K7UCNhV4v9krK7aOcy4X2AckHGPZsrRZ4xzJyWPc5CCHjuby7Oj+NK4X7XdIIiL/o9r+XDWzcWYWNLNgZmam3+GUyjnHb19fyrIt+3hkRB86NW/gd0giIsUqS2LYAiQXeJ/klRVbx8yigDgg6xjLlqXNY3LOTXTOBZxzgcTExONZ1BdPfZ7B24u3csd5nTi3azO/wxERKVFZEsMCoIOZpZpZNKHB5JlF6swExnjTw4HZzjnnlY/wzlpKBToA88vYZo3x8codPDBrFRf3asnNZ7bzOxwRkWMqNTF4YwYTgFnAt8A059wKM7vHzC7xqj0HJJhZOnA7cJe37ApgGrAS+AC4xTmXV1KbAGZ2q5ltJrQXsdTMnq24za16a3Yc4JdTFtG9ZRwPXN5TD9wRkbBnoR/21VsgEHDBYNDvMDYijAkAAApvSURBVP7HnkPZDHv8a77PyWPmhFNoEXeS3yGJiPzIzNKcc4Gi5dV28Dnc5eTlc/MrC9m+7whPj+qnpCAi1YZuiVFJ/vbuSuZkZPHQz3rRt3Ujv8MRESkz7TFUglfnbWTSnA2MO70tl/dL8jscEZHjosRQweZlZPF/by/nzE6J/HZoZ7/DERE5bkoMFWjT7sOMf2UhrRNieXRkHyL1wB0RqYaUGCrIoaO53PBSkNy8fJ4dHaBh3Tp+hyQickI0+FwB8vMdt09bzJodB3jx2gG0Tazvd0giIidMewwV4JGP1zBrxQ7+cFFXTu8Y/rfnEBE5FiWGcnp36VYenZ3OFYEkrj0lxe9wRETKTYmhHJZv2ccd05cQaNOIv17aXbe7EJEaQYnhBGUeOMq4l4I0jo3myWv6ERMV6XdIIiIVQoPPJ+Bobh43vZzGnsM5TL9pMIkNYvwOSUSkwigxHCfnHH94czlpG/bw+FV96d4qzu+QREQqlA4lHafnv17P9LTN3DqkAxf1bOF3OCIiFU6J4Th8sSaTe99bydBuzfnVkA5+hyMiUimUGMooI/MgE15dSMdmDXjoil5E6HYXIlJDKTGUwb7vcxj7UpCoyAieGR2gXoyGZkSk5lJiKEVevuPW1xaxMeswT13Tj+TGsX6HJCJSqfTTtxT3vf8tn6/J5O8/7cGA1MZ+hyMiUum0x3AMM9I288yX6xgzuA0jB7T2OxwRkSqhxFCCtA17+N0byzilfQJ//ElXv8MREakySgzF2Lbve26cnEaL+Lo8flVfoiLVTSJSe2iMoYjvs/O44aUgR3LyeO2GgcTHRvsdkohIlVJiKMA5x29mLGHF1v08OzpAh2YN/A5JRKTK6RhJAU989h3vLt3Gned3ZkiXZn6HIyLiCyUGz4crtvPgrNVc2rslN53R1u9wRER8o8QArNq+n9umLqZXUhz3Xd5TD9wRkVqtTInBzIaa2WozSzezu4qZH2NmU73588wspcC8u73y1WZ2fmltmlmq10a612aljv7uPpTN2ElB6sVEMXF0gLp19MAdEandSk0MZhYJPA5cAHQFRppZ0RP7rwf2OOfaAw8D93vLdgVGAN2AocATZhZZSpv3Aw97be3x2q4UOXn5jH85jZ0HjjJxdIBmDetW1qpERKqNsuwxDADSnXMZzrlsYAowrEidYcAkb3oGMMRCx2OGAVOcc0edc+uAdK+9Ytv0ljnbawOvzUtPfPOO7S/vrGDeut08cHlPeifHV9ZqRESqlbIkhlbApgLvN3tlxdZxzuUC+4CEYyxbUnkCsNdro6R1AWBm48wsaGbBzMzMMmxGYc45UhLqcctZ7bi0T7GrEBGplartdQzOuYnARIBAIOCOd3kzY+xpOvtIRKSosuwxbAGSC7xP8sqKrWNmUUAckHWMZUsqzwLivTZKWpeIiFSisiSGBUAH72yhaEKDyTOL1JkJjPGmhwOznXPOKx/hnbWUCnQA5pfUprfMp14beG2+feKbJyIix6vUQ0nOuVwzmwDMAiKB551zK8zsHiDonJsJPAdMNrN0YDehL3q8etOAlUAucItzLg+guDa9Vf4WmGJmfwMWeW2LiEgVsdCP9OotEAi4YDDodxgiItWKmaU55wJFy3Xls4iIFKLEICIihSgxiIhIIUoMIiJSSI0YfDazTGDDCS7eBNhVgeFUhnCPMdzjg/CPMdzjA8VYEcItvjbOucSihTUiMZSHmQWLG5UPJ+EeY7jHB+EfY7jHB4qxIoR7fD/QoSQRESlEiUFERApRYvBuxBfmwj3GcI8Pwj/GcI8PFGNFCPf4AI0xiIhIEdpjEBGRQpQYRESkkFqdGMxsqJmtNrN0M7urCtebbGafmtlKM1thZr/0yhub2Udmttb7t5FXbmb2qBfnUjPrW6CtMV79tWY2pqR1nmCckWa2yMze9d6nmtk8L46p3i3T8W6rPtUrn2dmKQXauNsrX21m51dwfPFmNsPMVpnZt2Y2OAz78Dbv/3i5mb1mZnX97Ecze97MdprZ8gJlFdZnZtbPzJZ5yzxqZlZBMT7o/T8vNbM3zSy+wLxi+6akz3dJ/V/eGAvM+7WZOTNr4r33pR/LxTlXK1+Ebvf9HdAWiAaWAF2raN0tgL7edANgDdAVeAC4yyu/C7jfm74QeB8wYBAwzytvDGR4/zbyphtVYJy3A68C73rvpwEjvOmngPHe9M3AU970CGCqN93V69cYINXr78gKjG8SMNabjgbiw6kPCT2Wdh1wUoH++7mf/QicDvQFlhcoq7A+I/S8lUHeMu8DF1RQjOcBUd70/QViLLZvOMbnu6T+L2+MXnkyoccJbACa+NmP5frbrcqVhdMLGAzMKvD+buBun2J5GzgXWA208MpaAKu96aeBkQXqr/bmjwSeLlBeqF45Y0oCPgHOBt71/kB3Ffhw/th/3gdhsDcd5dWzon1asF4FxBdH6EvXipSHUx/+8Gzzxl6/vAuc73c/AikU/tKtkD7z5q0qUF6oXnliLDLvMuAVb7rYvqGEz/ex/o4rIkZgBtALWM9/E4Nv/Xiir9p8KOmHD+0PNntlVco7XNAHmAc0c85t82ZtB5p50yXFWpnb8AhwJ5DvvU8A9jrncotZ149xePP3efUrM75UIBN4wUKHu541s3qEUR8657YA/wA2AtsI9Usa4dWPUHF91sqbrqw4f3AdoV/RJxLjsf6Oy8XMhgFbnHNLiswK134sUW1ODL4zs/rA68CvnHP7C85zoZ8KvpxLbGY/AXY659L8WH8ZRRHalX/SOdcHOEToMMiP/OxDAO9Y/TBCSawlUA8Y6lc8ZeF3n5XGzH5P6GmQr/gdS0FmFgv8Dvg/v2OpCLU5MWwhdDzwB0leWZUwszqEksIrzrk3vOIdZtbCm98C2FlKrJW1DacAl5jZemAKocNJ/wLizeyHx8EWXNePcXjz44CsSowPQr+iNjvn5nnvZxBKFOHShwDnAOucc5nOuRzgDUJ9G079CBXXZ1u86UqJ08x+DvwEuNpLYCcSYxYl9395tCP0A2CJ97lJAhaaWfMTiLFS+7FMqvK4VTi9CP3izCD0n/nD4FS3Klq3AS8BjxQpf5DCg4APeNMXUXjwar5X3pjQcfZG3msd0LiCYz2T/w4+T6fwoN3N3vQtFB40neZNd6PwwGAGFTv4/CXQyZv+s9d/YdOHwEBgBRDrrXcS8Au/+5H/HWOosD7jfwdNL6ygGIcSenZ8YpF6xfYNx/h8l9T/5Y2xyLz1/HeMwbd+POG/kapcWbi9CJ0tsIbQ2Qu/r8L1nkpod30psNh7XUjo+OcnwFrg4wJ/JAY87sW5DAgUaOs6IN17XVsJsZ7JfxNDW+8PNt37cMV45XW99+ne/LYFlv+9F/dqKvjMCqA3EPT68S3vwxVWfQj8BVgFLAcme19gvvUj8Bqh8Y4cQntd11dknwEBb1u/Ax6jyMkB5YgxndDx+B8+L0+V1jeU8Pkuqf/LG2OR+ev5b2LwpR/L89ItMUREpJDaPMYgIiLFUGIQEZFClBhERKQQJQYRESlEiUFERApRYhARkUKUGEREpJD/D0vnk2SXAVtjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_schedule(warmup_steps):\n",
    "  def lr_schedule(step):\n",
    "    return 1.0 * np.minimum(1.0, step / warmup_steps) / np.sqrt(np.maximum(step, warmup_steps))\n",
    "\n",
    "  return lr_schedule\n",
    "\n",
    "lr=0.05\n",
    "weight_decay=0.1\n",
    "warmup=8000\n",
    "\n",
    "\n",
    "def const_schedule(lr):\n",
    "  def lr_schedule(step):\n",
    "    return lr\n",
    "  return lr_schedule\n",
    "\n",
    "def training_setup():\n",
    "  model = model_factory()\n",
    "  criterion = nn.CrossEntropyLoss().cuda()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  schedule_func = get_schedule(warmup)\n",
    "  #schedule_func = const_schedule(1.0) #<--------- TEMPORARY\n",
    "  scheduler = LambdaLR(optimizer, schedule_func)\n",
    "\n",
    "  return model, criterion, optimizer, schedule_func, scheduler\n",
    "\n",
    "_, _, _, schedule_func, _ = training_setup()\n",
    "\n",
    "plt.plot([ lr * schedule_func(i) for i in range(15000) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_B6ohTx7wgH"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def save_model(model, optimizer, name='/content/drive/MyDrive/Work/Misc/lka-mini-base.tar'):\n",
    "  torch.save({\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              }, name)\n",
    "\n",
    "def progress_bar(len, total, current):\n",
    "  current_scaled = int(round(len * current / total))\n",
    "\n",
    "  s = '[' + '=' * (current_scaled - 1)\n",
    "  s += '>' if current != total else '='\n",
    "  s += '-' * (len - current_scaled) + ']'\n",
    "\n",
    "  return s\n",
    "\n",
    "def accuracy(model_output, labels):\n",
    "  model_output = model_output.argmax(dim=-1)\n",
    "\n",
    "  return (labels == model_output).float().mean().cpu().numpy()\n",
    "\n",
    "def train_model(model, name, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, epochs, epoch_len=64, eps = 1e-5, skip_eval=0):\n",
    "  \n",
    "  best_acc = 0.0\n",
    "  train_datagen = iter(train_dataset)\n",
    "      \n",
    "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "      \n",
    "      #epoch start timestamp\n",
    "      t = time.time()\n",
    "\n",
    "      running_loss = 0.0\n",
    "      running_reg  = 0.0\n",
    "      running_acc  = 0.0\n",
    "\n",
    "      running_momentum = 0.99\n",
    "\n",
    "      epoch_loss = [  ]\n",
    "      epoch_reg  = [  ]\n",
    "      epoch_acc  = [  ]\n",
    "\n",
    "      model.train()\n",
    "\n",
    "      print(f'Epoch {epoch}')\n",
    "\n",
    "      process_inputs = lambda x: torch.Tensor(x.numpy()).to(torch.int64)\n",
    "\n",
    "      for i in range(epoch_len):\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          #accumulate gradients for a certain amount of steps\n",
    "          for k in range(accumulation_steps):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "            try:\n",
    "              data = next(train_datagen)\n",
    "            except StopIteration:\n",
    "              train_datagen = iter(train_dataset)\n",
    "              data = next(train_datagen)\n",
    "            except:\n",
    "              break\n",
    "            inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "            inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "            inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, additional_losses = model((inputs1, inputs2))\n",
    "            loss = criterion(outputs + eps, labels)\n",
    "\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "              print(loss)\n",
    "              return None\n",
    "\n",
    "            additional_losses = sum(additional_losses) if additional_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "            ((loss + additional_losses / 2) / accumulation_steps).backward() #multiply by 1/2 since we have a double input\n",
    "\n",
    "            acc = accuracy(outputs, labels)\n",
    "\n",
    "            running_loss = running_loss * running_momentum + (1 - running_momentum) * loss.item()\n",
    "            running_loss_unb = running_loss / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            running_acc  = running_acc  * running_momentum + (1 - running_momentum) * acc\n",
    "            running_acc_unb = running_acc / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            running_reg  = running_reg  * running_momentum + (1 - running_momentum) * additional_losses.item()\n",
    "            running_reg_unb = running_reg / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "            epoch_reg.append(additional_losses.item())\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "          pbar = progress_bar(20, epoch_len, i + 1)\n",
    "\n",
    "          print(f'\\r{pbar} {i + 1}/{epoch_len}:', end='')\n",
    "          print(f' - running_loss: {running_loss_unb:.4f} - running_reg: {running_reg_unb:.6f} - running_acc: {running_acc_unb:.4f} - lr: {scheduler.get_last_lr()[0]:.5f}', end='')\n",
    "\n",
    "          scheduler.step()\n",
    "      \n",
    "      epoch_loss = np.mean(epoch_loss)\n",
    "      epoch_acc  = np.mean(epoch_acc)\n",
    "      epoch_reg  = np.mean(epoch_reg)\n",
    "      \n",
    "      print(f' - epoch_loss: {epoch_loss:.4f} - epoch_reg: {epoch_reg:.6f} - epoch_acc: {epoch_acc:.4f}', end='')\n",
    "\n",
    "      epoch_loss, epoch_acc, epoch_reg = [], [], []\n",
    "\n",
    "      \n",
    "      if epoch >= skip_eval:\n",
    "        model.eval()\n",
    "        valid_dataset.repeat()\n",
    "        valid_datagen = iter(valid_dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for i, data in enumerate(valid_datagen):\n",
    "\n",
    "            inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "            inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "            inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "            outputs, aux_losses = model((inputs1, inputs2))\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = accuracy(outputs, labels)\n",
    "            aux_losses = sum(aux_losses) if aux_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "            aux_losses /= 2 #Doubled input\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "            epoch_reg.append(aux_losses.item())\n",
    "\n",
    "        epoch_loss, epoch_acc, epoch_reg = np.mean(epoch_loss), np.mean(epoch_acc), np.mean(epoch_reg)\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "          best_acc = epoch_acc\n",
    "          save_model(model, optimizer, name)\n",
    "      \n",
    "      else:\n",
    "        epoch_loss, epoch_acc, epoch_reg = 0.0, 0.0, 0.0\n",
    "\n",
    "      #epoch computing time\n",
    "      t = time.time() - t\n",
    "\n",
    "      print(f' - valid_loss: {epoch_loss:.4f} - valid_reg: {epoch_reg:.6f} - valid_acc: {epoch_acc:.4f} - epoch_time: {t:.4f} s')\n",
    " \n",
    "  checkpoint = torch.load(name)\n",
    "  return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egh-IbW76AN4"
   },
   "outputs": [],
   "source": [
    "def test(model, criterion, test_dataset):\n",
    "  epoch_loss, epoch_acc, epoch_reg = [], [], []\n",
    "\n",
    "  model.eval()\n",
    "  test_dataset.repeat()\n",
    "\n",
    "  process_inputs = lambda x: torch.Tensor(x.numpy()).to(torch.int64)\n",
    "\n",
    "  t = time.time()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(iter(test_dataset)):\n",
    "      inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "      inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "      inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "      outputs, aux_losses = model((inputs1, inputs2))\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = accuracy(outputs, labels)\n",
    "      aux_losses = sum(aux_losses) if aux_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "      aux_losses /= 2 #Doubled input\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_acc.append(acc)\n",
    "      epoch_reg.append(aux_losses.item())\n",
    "\n",
    "  t = time.time() - t\n",
    "\n",
    "  epoch_loss, epoch_acc, epoch_reg = np.mean(epoch_loss), np.mean(epoch_acc), np.mean(epoch_reg)\n",
    "\n",
    "  print(f' - test_loss: {epoch_loss:.4f} - test_reg: {epoch_reg:.6f} - test_acc: {epoch_acc:.4f} - test_time: {t:.4f} s')\n",
    "  return epoch_loss, epoch_reg, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4d0DhgWDbm3",
    "outputId": "f892ba6c-49b8-49c3-cfda-babb1f0d7ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n",
      "Epoch 0\n",
      "[====================] 100/100: - running_loss: 1.2016 - running_reg: 0.000000 - running_acc: 0.5316 - lr: 0.00001 - epoch_loss: 1.4933 - epoch_reg: 0.000000 - epoch_acc: 0.5056 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 49.7709 s\n",
      "Epoch 1\n",
      "[====================] 100/100: - running_loss: 0.9594 - running_reg: 0.000000 - running_acc: 0.5546 - lr: 0.00001 - epoch_loss: 1.0238 - epoch_reg: 0.000000 - epoch_acc: 0.5391 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9568 s\n",
      "Epoch 2\n",
      "[====================] 100/100: - running_loss: 0.9551 - running_reg: 0.000000 - running_acc: 0.4959 - lr: 0.00002 - epoch_loss: 0.9511 - epoch_reg: 0.000000 - epoch_acc: 0.5222 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9578 s\n",
      "Epoch 3\n",
      "[====================] 100/100: - running_loss: 0.8925 - running_reg: 0.000000 - running_acc: 0.4953 - lr: 0.00003 - epoch_loss: 0.8954 - epoch_reg: 0.000000 - epoch_acc: 0.5084 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9701 s\n",
      "Epoch 4\n",
      "[====================] 100/100: - running_loss: 0.8147 - running_reg: 0.000000 - running_acc: 0.5008 - lr: 0.00003 - epoch_loss: 0.8654 - epoch_reg: 0.000000 - epoch_acc: 0.5050 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1170 s\n",
      "Epoch 5\n",
      "[====================] 100/100: - running_loss: 0.8035 - running_reg: 0.000000 - running_acc: 0.5096 - lr: 0.00004 - epoch_loss: 0.8169 - epoch_reg: 0.000000 - epoch_acc: 0.4969 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8831 s\n",
      "Epoch 6\n",
      "[====================] 100/100: - running_loss: 0.8174 - running_reg: 0.000000 - running_acc: 0.4734 - lr: 0.00005 - epoch_loss: 0.8011 - epoch_reg: 0.000000 - epoch_acc: 0.5050 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8299 s\n",
      "Epoch 7\n",
      "[====================] 100/100: - running_loss: 0.8156 - running_reg: 0.000000 - running_acc: 0.4675 - lr: 0.00006 - epoch_loss: 0.7798 - epoch_reg: 0.000000 - epoch_acc: 0.5053 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2340 s\n",
      "Epoch 8\n",
      "[====================] 100/100: - running_loss: 0.7510 - running_reg: 0.000000 - running_acc: 0.5333 - lr: 0.00006 - epoch_loss: 0.7528 - epoch_reg: 0.000000 - epoch_acc: 0.5225 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.4562 s\n",
      "Epoch 9\n",
      "[====================] 100/100: - running_loss: 0.7502 - running_reg: 0.000000 - running_acc: 0.4999 - lr: 0.00007 - epoch_loss: 0.7700 - epoch_reg: 0.000000 - epoch_acc: 0.4969 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.4004 s\n",
      "Epoch 10\n",
      "[====================] 100/100: - running_loss: 0.7294 - running_reg: 0.000000 - running_acc: 0.4943 - lr: 0.00008 - epoch_loss: 0.7400 - epoch_reg: 0.000000 - epoch_acc: 0.5034 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8757 s\n",
      "Epoch 11\n",
      "[====================] 100/100: - running_loss: 0.7567 - running_reg: 0.000000 - running_acc: 0.5199 - lr: 0.00008 - epoch_loss: 0.7366 - epoch_reg: 0.000000 - epoch_acc: 0.5328 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9745 s\n",
      "Epoch 12\n",
      "[====================] 100/100: - running_loss: 0.7310 - running_reg: 0.000000 - running_acc: 0.5292 - lr: 0.00009 - epoch_loss: 0.7286 - epoch_reg: 0.000000 - epoch_acc: 0.5306 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9406 s\n",
      "Epoch 13\n",
      "[====================] 100/100: - running_loss: 0.6887 - running_reg: 0.000000 - running_acc: 0.5987 - lr: 0.00010 - epoch_loss: 0.7062 - epoch_reg: 0.000000 - epoch_acc: 0.5694 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8113 s\n",
      "Epoch 14\n",
      "[====================] 100/100: - running_loss: 0.7059 - running_reg: 0.000000 - running_acc: 0.5789 - lr: 0.00010 - epoch_loss: 0.7195 - epoch_reg: 0.000000 - epoch_acc: 0.5475 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6796 s\n",
      "Epoch 15\n",
      "[====================] 100/100: - running_loss: 0.7161 - running_reg: 0.000000 - running_acc: 0.5572 - lr: 0.00011 - epoch_loss: 0.6939 - epoch_reg: 0.000000 - epoch_acc: 0.5697 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6540 s\n",
      "Epoch 16\n",
      "[====================] 100/100: - running_loss: 0.7153 - running_reg: 0.000000 - running_acc: 0.5795 - lr: 0.00012 - epoch_loss: 0.7028 - epoch_reg: 0.000000 - epoch_acc: 0.5716 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6411 s\n",
      "Epoch 17\n",
      "[====================] 100/100: - running_loss: 0.6902 - running_reg: 0.000000 - running_acc: 0.5454 - lr: 0.00013 - epoch_loss: 0.7011 - epoch_reg: 0.000000 - epoch_acc: 0.5544 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9154 s\n",
      "Epoch 18\n",
      "[====================] 100/100: - running_loss: 0.7192 - running_reg: 0.000000 - running_acc: 0.5083 - lr: 0.00013 - epoch_loss: 0.7045 - epoch_reg: 0.000000 - epoch_acc: 0.5306 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6681 s\n",
      "Epoch 19\n",
      "[====================] 100/100: - running_loss: 0.7227 - running_reg: 0.000000 - running_acc: 0.5404 - lr: 0.00014 - epoch_loss: 0.7070 - epoch_reg: 0.000000 - epoch_acc: 0.5412 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6582 s\n",
      "Epoch 20\n",
      "[====================] 100/100: - running_loss: 0.6636 - running_reg: 0.000000 - running_acc: 0.5781 - lr: 0.00015 - epoch_loss: 0.6683 - epoch_reg: 0.000000 - epoch_acc: 0.5734 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6278 s\n",
      "Epoch 21\n",
      "[====================] 100/100: - running_loss: 0.7136 - running_reg: 0.000000 - running_acc: 0.5167 - lr: 0.00015 - epoch_loss: 0.6932 - epoch_reg: 0.000000 - epoch_acc: 0.5400 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5081 s\n",
      "Epoch 22\n",
      "[====================] 100/100: - running_loss: 0.6773 - running_reg: 0.000000 - running_acc: 0.5537 - lr: 0.00016 - epoch_loss: 0.6881 - epoch_reg: 0.000000 - epoch_acc: 0.5437 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6595 s\n",
      "Epoch 23\n",
      "[====================] 100/100: - running_loss: 0.6784 - running_reg: 0.000000 - running_acc: 0.5851 - lr: 0.00017 - epoch_loss: 0.6856 - epoch_reg: 0.000000 - epoch_acc: 0.5675 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5923 s\n",
      "Epoch 24\n",
      "[====================] 100/100: - running_loss: 0.6714 - running_reg: 0.000000 - running_acc: 0.5775 - lr: 0.00017 - epoch_loss: 0.6780 - epoch_reg: 0.000000 - epoch_acc: 0.5691 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8024 s\n",
      "Epoch 25\n",
      "[====================] 100/100: - running_loss: 0.6585 - running_reg: 0.000000 - running_acc: 0.6128 - lr: 0.00018 - epoch_loss: 0.6703 - epoch_reg: 0.000000 - epoch_acc: 0.5884 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6851 s\n",
      "Epoch 26\n",
      "[====================] 100/100: - running_loss: 0.6740 - running_reg: 0.000000 - running_acc: 0.5739 - lr: 0.00019 - epoch_loss: 0.6668 - epoch_reg: 0.000000 - epoch_acc: 0.5781 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6899 s\n",
      "Epoch 27\n",
      "[====================] 100/100: - running_loss: 0.6816 - running_reg: 0.000000 - running_acc: 0.5817 - lr: 0.00020 - epoch_loss: 0.6668 - epoch_reg: 0.000000 - epoch_acc: 0.5972 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8850 s\n",
      "Epoch 28\n",
      "[====================] 100/100: - running_loss: 0.6863 - running_reg: 0.000000 - running_acc: 0.5602 - lr: 0.00020 - epoch_loss: 0.6854 - epoch_reg: 0.000000 - epoch_acc: 0.5741 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0133 s\n",
      "Epoch 29\n",
      "[====================] 100/100: - running_loss: 0.7142 - running_reg: 0.000000 - running_acc: 0.5102 - lr: 0.00021 - epoch_loss: 0.7055 - epoch_reg: 0.000000 - epoch_acc: 0.5209 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.6569 s\n",
      "Epoch 30\n",
      "[====================] 100/100: - running_loss: 0.6956 - running_reg: 0.000000 - running_acc: 0.5186 - lr: 0.00022 - epoch_loss: 0.7001 - epoch_reg: 0.000000 - epoch_acc: 0.5294 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2298 s\n",
      "Epoch 31\n",
      "[====================] 100/100: - running_loss: 0.6789 - running_reg: 0.000000 - running_acc: 0.5626 - lr: 0.00022 - epoch_loss: 0.6799 - epoch_reg: 0.000000 - epoch_acc: 0.5681 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2934 s\n",
      "Epoch 32\n",
      "[====================] 100/100: - running_loss: 0.6404 - running_reg: 0.000000 - running_acc: 0.6530 - lr: 0.00023 - epoch_loss: 0.6728 - epoch_reg: 0.000000 - epoch_acc: 0.5969 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3173 s\n",
      "Epoch 33\n",
      "[====================] 100/100: - running_loss: 0.6344 - running_reg: 0.000000 - running_acc: 0.6392 - lr: 0.00024 - epoch_loss: 0.6362 - epoch_reg: 0.000000 - epoch_acc: 0.6434 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3719 s\n",
      "Epoch 34\n",
      "[====================] 100/100: - running_loss: 0.6670 - running_reg: 0.000000 - running_acc: 0.5887 - lr: 0.00024 - epoch_loss: 0.6555 - epoch_reg: 0.000000 - epoch_acc: 0.6141 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3345 s\n",
      "Epoch 35\n",
      "[====================] 100/100: - running_loss: 0.6951 - running_reg: 0.000000 - running_acc: 0.5601 - lr: 0.00025 - epoch_loss: 0.6789 - epoch_reg: 0.000000 - epoch_acc: 0.5738 - valid_loss: 0.6942 - valid_reg: 0.000000 - valid_acc: 0.5494 - epoch_time: 143.4669 s\n",
      "Epoch 36\n",
      "[====================] 100/100: - running_loss: 0.6995 - running_reg: 0.000000 - running_acc: 0.5607 - lr: 0.00026 - epoch_loss: 0.6845 - epoch_reg: 0.000000 - epoch_acc: 0.5675 - valid_loss: 0.7321 - valid_reg: 0.000000 - valid_acc: 0.5212 - epoch_time: 144.0623 s\n",
      "Epoch 37\n",
      "[====================] 100/100: - running_loss: 0.6938 - running_reg: 0.000000 - running_acc: 0.5311 - lr: 0.00027 - epoch_loss: 0.7035 - epoch_reg: 0.000000 - epoch_acc: 0.5163 - valid_loss: 0.6914 - valid_reg: 0.000000 - valid_acc: 0.5215 - epoch_time: 141.9215 s\n",
      "Epoch 38\n",
      "[====================] 100/100: - running_loss: 0.7007 - running_reg: 0.000000 - running_acc: 0.5151 - lr: 0.00027 - epoch_loss: 0.6964 - epoch_reg: 0.000000 - epoch_acc: 0.5263 - valid_loss: 0.6923 - valid_reg: 0.000000 - valid_acc: 0.5202 - epoch_time: 142.1866 s\n",
      "Epoch 39\n",
      "[====================] 100/100: - running_loss: 0.7001 - running_reg: 0.000000 - running_acc: 0.5230 - lr: 0.00028 - epoch_loss: 0.6956 - epoch_reg: 0.000000 - epoch_acc: 0.5247 - valid_loss: 0.7218 - valid_reg: 0.000000 - valid_acc: 0.4941 - epoch_time: 141.9140 s\n",
      "Epoch 40\n",
      "[====================] 100/100: - running_loss: 0.6838 - running_reg: 0.000000 - running_acc: 0.5671 - lr: 0.00029 - epoch_loss: 0.6917 - epoch_reg: 0.000000 - epoch_acc: 0.5397 - valid_loss: 0.7427 - valid_reg: 0.000000 - valid_acc: 0.5059 - epoch_time: 141.4898 s\n",
      "Epoch 41\n",
      "[====================] 100/100: - running_loss: 0.6950 - running_reg: 0.000000 - running_acc: 0.5121 - lr: 0.00029 - epoch_loss: 0.6940 - epoch_reg: 0.000000 - epoch_acc: 0.5278 - valid_loss: 0.7029 - valid_reg: 0.000000 - valid_acc: 0.4919 - epoch_time: 141.2017 s\n",
      "Epoch 42\n",
      "[====================] 100/100: - running_loss: 0.6779 - running_reg: 0.000000 - running_acc: 0.5552 - lr: 0.00030 - epoch_loss: 0.6882 - epoch_reg: 0.000000 - epoch_acc: 0.5366 - valid_loss: 0.6930 - valid_reg: 0.000000 - valid_acc: 0.5130 - epoch_time: 140.7876 s\n",
      "Epoch 43\n",
      "[====================] 100/100: - running_loss: 0.6953 - running_reg: 0.000000 - running_acc: 0.5033 - lr: 0.00031 - epoch_loss: 0.6899 - epoch_reg: 0.000000 - epoch_acc: 0.5263 - valid_loss: 0.6825 - valid_reg: 0.000000 - valid_acc: 0.5433 - epoch_time: 140.3158 s\n",
      "Epoch 44\n",
      "[====================] 100/100: - running_loss: 0.6843 - running_reg: 0.000000 - running_acc: 0.5407 - lr: 0.00031 - epoch_loss: 0.6845 - epoch_reg: 0.000000 - epoch_acc: 0.5472 - valid_loss: 0.6914 - valid_reg: 0.000000 - valid_acc: 0.5291 - epoch_time: 141.0025 s\n",
      "Epoch 45\n",
      "[====================] 100/100: - running_loss: 0.6805 - running_reg: 0.000000 - running_acc: 0.5740 - lr: 0.00032 - epoch_loss: 0.6812 - epoch_reg: 0.000000 - epoch_acc: 0.5584 - valid_loss: 0.6802 - valid_reg: 0.000000 - valid_acc: 0.5451 - epoch_time: 143.0128 s\n",
      "Epoch 46\n",
      "[====================] 100/100: - running_loss: 0.6154 - running_reg: 0.000000 - running_acc: 0.6458 - lr: 0.00033 - epoch_loss: 0.6272 - epoch_reg: 0.000000 - epoch_acc: 0.6422 - valid_loss: 0.7353 - valid_reg: 0.000000 - valid_acc: 0.5364 - epoch_time: 140.9717 s\n",
      "Epoch 47\n",
      "[====================] 100/100: - running_loss: 0.6415 - running_reg: 0.000000 - running_acc: 0.6209 - lr: 0.00034 - epoch_loss: 0.6152 - epoch_reg: 0.000000 - epoch_acc: 0.6453 - valid_loss: 0.7021 - valid_reg: 0.000000 - valid_acc: 0.5479 - epoch_time: 141.4803 s\n",
      "Epoch 48\n",
      "[====================] 100/100: - running_loss: 0.6649 - running_reg: 0.000000 - running_acc: 0.5749 - lr: 0.00034 - epoch_loss: 0.6437 - epoch_reg: 0.000000 - epoch_acc: 0.6094 - valid_loss: 0.6796 - valid_reg: 0.000000 - valid_acc: 0.5360 - epoch_time: 141.1681 s\n",
      "Epoch 49\n",
      "[====================] 100/100: - running_loss: 0.6699 - running_reg: 0.000000 - running_acc: 0.5795 - lr: 0.00035 - epoch_loss: 0.6654 - epoch_reg: 0.000000 - epoch_acc: 0.5775 - valid_loss: 0.6668 - valid_reg: 0.000000 - valid_acc: 0.5647 - epoch_time: 141.1528 s\n",
      "Epoch 50\n",
      "[====================] 100/100: - running_loss: 0.6695 - running_reg: 0.000000 - running_acc: 0.5723 - lr: 0.00036 - epoch_loss: 0.6725 - epoch_reg: 0.000000 - epoch_acc: 0.5688 - valid_loss: 0.7226 - valid_reg: 0.000000 - valid_acc: 0.4785 - epoch_time: 141.5276 s\n",
      "Epoch 51\n",
      "[====================] 100/100: - running_loss: 0.6726 - running_reg: 0.000000 - running_acc: 0.5868 - lr: 0.00036 - epoch_loss: 0.6818 - epoch_reg: 0.000000 - epoch_acc: 0.5516 - valid_loss: 0.6932 - valid_reg: 0.000000 - valid_acc: 0.5437 - epoch_time: 141.3522 s\n",
      "Epoch 52\n",
      "[====================] 100/100: - running_loss: 0.6660 - running_reg: 0.000000 - running_acc: 0.5776 - lr: 0.00037 - epoch_loss: 0.6707 - epoch_reg: 0.000000 - epoch_acc: 0.5816 - valid_loss: 0.6784 - valid_reg: 0.000000 - valid_acc: 0.5462 - epoch_time: 140.9898 s\n",
      "Epoch 53\n",
      "[====================] 100/100: - running_loss: 0.6708 - running_reg: 0.000000 - running_acc: 0.5664 - lr: 0.00038 - epoch_loss: 0.6681 - epoch_reg: 0.000000 - epoch_acc: 0.5688 - valid_loss: 0.6736 - valid_reg: 0.000000 - valid_acc: 0.5660 - epoch_time: 141.9196 s\n",
      "Epoch 54\n",
      "[====================] 100/100: - running_loss: 0.6726 - running_reg: 0.000000 - running_acc: 0.5860 - lr: 0.00038 - epoch_loss: 0.6654 - epoch_reg: 0.000000 - epoch_acc: 0.5919 - valid_loss: 0.6710 - valid_reg: 0.000000 - valid_acc: 0.5741 - epoch_time: 142.3587 s\n",
      "Epoch 55\n",
      "[====================] 100/100: - running_loss: 0.6656 - running_reg: 0.000000 - running_acc: 0.5899 - lr: 0.00039 - epoch_loss: 0.6690 - epoch_reg: 0.000000 - epoch_acc: 0.5744 - valid_loss: 0.6708 - valid_reg: 0.000000 - valid_acc: 0.5659 - epoch_time: 143.6652 s\n",
      "Epoch 56\n",
      "[====================] 100/100: - running_loss: 0.6711 - running_reg: 0.000000 - running_acc: 0.5851 - lr: 0.00040 - epoch_loss: 0.6638 - epoch_reg: 0.000000 - epoch_acc: 0.5928 - valid_loss: 0.6676 - valid_reg: 0.000000 - valid_acc: 0.5810 - epoch_time: 141.9829 s\n",
      "Epoch 57\n",
      "[====================] 100/100: - running_loss: 0.6296 - running_reg: 0.000000 - running_acc: 0.6185 - lr: 0.00041 - epoch_loss: 0.6293 - epoch_reg: 0.000000 - epoch_acc: 0.6156 - valid_loss: 0.6845 - valid_reg: 0.000000 - valid_acc: 0.5498 - epoch_time: 141.8379 s\n",
      "Epoch 58\n",
      "[====================] 100/100: - running_loss: 0.5552 - running_reg: 0.000000 - running_acc: 0.7199 - lr: 0.00041 - epoch_loss: 0.5940 - epoch_reg: 0.000000 - epoch_acc: 0.6691 - valid_loss: 0.7418 - valid_reg: 0.000000 - valid_acc: 0.5511 - epoch_time: 141.7306 s\n",
      "Epoch 59\n",
      "[====================] 100/100: - running_loss: 0.5582 - running_reg: 0.000000 - running_acc: 0.7235 - lr: 0.00042 - epoch_loss: 0.5259 - epoch_reg: 0.000000 - epoch_acc: 0.7456 - valid_loss: 0.7612 - valid_reg: 0.000000 - valid_acc: 0.5527 - epoch_time: 141.3086 s\n",
      "Epoch 60\n",
      "[====================] 100/100: - running_loss: 0.5075 - running_reg: 0.000000 - running_acc: 0.7677 - lr: 0.00043 - epoch_loss: 0.5190 - epoch_reg: 0.000000 - epoch_acc: 0.7472 - valid_loss: 0.7209 - valid_reg: 0.000000 - valid_acc: 0.5916 - epoch_time: 141.0796 s\n",
      "Epoch 61\n",
      "[====================] 100/100: - running_loss: 0.5543 - running_reg: 0.000000 - running_acc: 0.7273 - lr: 0.00043 - epoch_loss: 0.5191 - epoch_reg: 0.000000 - epoch_acc: 0.7506 - valid_loss: 0.7046 - valid_reg: 0.000000 - valid_acc: 0.5821 - epoch_time: 141.3057 s\n",
      "Epoch 62\n",
      "[====================] 100/100: - running_loss: 0.5589 - running_reg: 0.000000 - running_acc: 0.6947 - lr: 0.00044 - epoch_loss: 0.5607 - epoch_reg: 0.000000 - epoch_acc: 0.7000 - valid_loss: 0.7191 - valid_reg: 0.000000 - valid_acc: 0.5869 - epoch_time: 145.6716 s\n",
      "Epoch 63\n",
      "[====================] 100/100: - running_loss: 0.6031 - running_reg: 0.000000 - running_acc: 0.6574 - lr: 0.00045 - epoch_loss: 0.6059 - epoch_reg: 0.000000 - epoch_acc: 0.6544 - valid_loss: 0.7454 - valid_reg: 0.000000 - valid_acc: 0.5729 - epoch_time: 146.0240 s\n",
      "Epoch 64\n",
      "[====================] 100/100: - running_loss: 0.5829 - running_reg: 0.000000 - running_acc: 0.6777 - lr: 0.00045 - epoch_loss: 0.6020 - epoch_reg: 0.000000 - epoch_acc: 0.6541 - valid_loss: 0.7141 - valid_reg: 0.000000 - valid_acc: 0.5933 - epoch_time: 141.1748 s\n",
      "Epoch 65\n",
      "[====================] 100/100: - running_loss: 0.5531 - running_reg: 0.000000 - running_acc: 0.6805 - lr: 0.00046 - epoch_loss: 0.5655 - epoch_reg: 0.000000 - epoch_acc: 0.6909 - valid_loss: 0.7058 - valid_reg: 0.000000 - valid_acc: 0.5898 - epoch_time: 140.4005 s\n",
      "Epoch 66\n",
      "[====================] 100/100: - running_loss: 0.5371 - running_reg: 0.000000 - running_acc: 0.7148 - lr: 0.00047 - epoch_loss: 0.5445 - epoch_reg: 0.000000 - epoch_acc: 0.7069 - valid_loss: 0.7787 - valid_reg: 0.000000 - valid_acc: 0.5815 - epoch_time: 140.4813 s\n",
      "Epoch 67\n",
      "[====================] 100/100: - running_loss: 0.5575 - running_reg: 0.000000 - running_acc: 0.7051 - lr: 0.00048 - epoch_loss: 0.5601 - epoch_reg: 0.000000 - epoch_acc: 0.7006 - valid_loss: 0.8176 - valid_reg: 0.000000 - valid_acc: 0.6045 - epoch_time: 140.1798 s\n",
      "Epoch 68\n",
      "[====================] 100/100: - running_loss: 0.5411 - running_reg: 0.000000 - running_acc: 0.7161 - lr: 0.00048 - epoch_loss: 0.5537 - epoch_reg: 0.000000 - epoch_acc: 0.7094 - valid_loss: 0.8624 - valid_reg: 0.000000 - valid_acc: 0.5953 - epoch_time: 140.4952 s\n",
      "Epoch 69\n",
      "[====================] 100/100: - running_loss: 0.5636 - running_reg: 0.000000 - running_acc: 0.6906 - lr: 0.00049 - epoch_loss: 0.5707 - epoch_reg: 0.000000 - epoch_acc: 0.6956 - valid_loss: 0.9794 - valid_reg: 0.000000 - valid_acc: 0.5948 - epoch_time: 140.9294 s\n",
      "Epoch 70\n",
      "[====================] 100/100: - running_loss: 0.6221 - running_reg: 0.000000 - running_acc: 0.6236 - lr: 0.00050 - epoch_loss: 0.5871 - epoch_reg: 0.000000 - epoch_acc: 0.6691 - valid_loss: 0.7542 - valid_reg: 0.000000 - valid_acc: 0.5705 - epoch_time: 185.9304 s\n",
      "Epoch 71\n",
      "[====================] 100/100: - running_loss: 0.6206 - running_reg: 0.000000 - running_acc: 0.6686 - lr: 0.00050 - epoch_loss: 0.5984 - epoch_reg: 0.000000 - epoch_acc: 0.6719 - valid_loss: 0.7233 - valid_reg: 0.000000 - valid_acc: 0.5954 - epoch_time: 141.3315 s\n",
      "Epoch 72\n",
      "[====================] 100/100: - running_loss: 0.5720 - running_reg: 0.000000 - running_acc: 0.6808 - lr: 0.00051 - epoch_loss: 0.5918 - epoch_reg: 0.000000 - epoch_acc: 0.6675 - valid_loss: 0.9750 - valid_reg: 0.000000 - valid_acc: 0.5738 - epoch_time: 141.1019 s\n",
      "Epoch 73\n",
      "[====================] 100/100: - running_loss: 0.5849 - running_reg: 0.000000 - running_acc: 0.6902 - lr: 0.00052 - epoch_loss: 0.5963 - epoch_reg: 0.000000 - epoch_acc: 0.6706 - valid_loss: 0.8656 - valid_reg: 0.000000 - valid_acc: 0.5283 - epoch_time: 140.9983 s\n",
      "Epoch 74\n",
      "[====================] 100/100: - running_loss: 0.6274 - running_reg: 0.000000 - running_acc: 0.6417 - lr: 0.00052 - epoch_loss: 0.6067 - epoch_reg: 0.000000 - epoch_acc: 0.6484 - valid_loss: 0.7281 - valid_reg: 0.000000 - valid_acc: 0.5852 - epoch_time: 141.1815 s\n",
      "Epoch 75\n",
      "[====================] 100/100: - running_loss: 0.6254 - running_reg: 0.000000 - running_acc: 0.6198 - lr: 0.00053 - epoch_loss: 0.6005 - epoch_reg: 0.000000 - epoch_acc: 0.6622 - valid_loss: 0.6446 - valid_reg: 0.000000 - valid_acc: 0.6158 - epoch_time: 141.6528 s\n",
      "Epoch 76\n",
      "[====================] 100/100: - running_loss: 0.5956 - running_reg: 0.000000 - running_acc: 0.6805 - lr: 0.00054 - epoch_loss: 0.5907 - epoch_reg: 0.000000 - epoch_acc: 0.6837 - valid_loss: 0.6295 - valid_reg: 0.000000 - valid_acc: 0.6326 - epoch_time: 141.6103 s\n",
      "Epoch 77\n",
      "[====================] 100/100: - running_loss: 0.5495 - running_reg: 0.000000 - running_acc: 0.7011 - lr: 0.00054 - epoch_loss: 0.5553 - epoch_reg: 0.000000 - epoch_acc: 0.6953 - valid_loss: 0.6432 - valid_reg: 0.000000 - valid_acc: 0.6351 - epoch_time: 141.8546 s\n",
      "Epoch 78\n",
      "[====================] 100/100: - running_loss: 0.5284 - running_reg: 0.000000 - running_acc: 0.7301 - lr: 0.00055 - epoch_loss: 0.5314 - epoch_reg: 0.000000 - epoch_acc: 0.7244 - valid_loss: 0.7953 - valid_reg: 0.000000 - valid_acc: 0.5783 - epoch_time: 141.7197 s\n",
      "Epoch 79\n",
      "[====================] 100/100: - running_loss: 0.5627 - running_reg: 0.000000 - running_acc: 0.7041 - lr: 0.00056 - epoch_loss: 0.5493 - epoch_reg: 0.000000 - epoch_acc: 0.7153 - valid_loss: 0.6556 - valid_reg: 0.000000 - valid_acc: 0.6049 - epoch_time: 141.5981 s\n",
      "Epoch 80\n",
      "[====================] 100/100: - running_loss: 0.5935 - running_reg: 0.000000 - running_acc: 0.6583 - lr: 0.00056 - epoch_loss: 0.5609 - epoch_reg: 0.000000 - epoch_acc: 0.6944 - valid_loss: 0.6312 - valid_reg: 0.000000 - valid_acc: 0.6266 - epoch_time: 141.9842 s\n",
      "Epoch 81\n",
      "[====================] 100/100: - running_loss: 0.6028 - running_reg: 0.000000 - running_acc: 0.6738 - lr: 0.00055 - epoch_loss: 0.5920 - epoch_reg: 0.000000 - epoch_acc: 0.6831 - valid_loss: 0.6441 - valid_reg: 0.000000 - valid_acc: 0.6265 - epoch_time: 140.9635 s\n",
      "Epoch 82\n",
      "[====================] 100/100: - running_loss: 0.6129 - running_reg: 0.000000 - running_acc: 0.6591 - lr: 0.00055 - epoch_loss: 0.5975 - epoch_reg: 0.000000 - epoch_acc: 0.6841 - valid_loss: 0.6362 - valid_reg: 0.000000 - valid_acc: 0.6188 - epoch_time: 141.2483 s\n",
      "Epoch 83\n",
      "[====================] 100/100: - running_loss: 0.6298 - running_reg: 0.000000 - running_acc: 0.6378 - lr: 0.00055 - epoch_loss: 0.6155 - epoch_reg: 0.000000 - epoch_acc: 0.6559 - valid_loss: 0.6300 - valid_reg: 0.000000 - valid_acc: 0.6279 - epoch_time: 141.1814 s\n",
      "Epoch 84\n",
      "[====================] 100/100: - running_loss: 0.6373 - running_reg: 0.000000 - running_acc: 0.6362 - lr: 0.00054 - epoch_loss: 0.6237 - epoch_reg: 0.000000 - epoch_acc: 0.6450 - valid_loss: 0.6441 - valid_reg: 0.000000 - valid_acc: 0.6222 - epoch_time: 141.5242 s\n",
      "Epoch 85\n",
      "[====================] 100/100: - running_loss: 0.6179 - running_reg: 0.000000 - running_acc: 0.6630 - lr: 0.00054 - epoch_loss: 0.6340 - epoch_reg: 0.000000 - epoch_acc: 0.6341 - valid_loss: 0.6933 - valid_reg: 0.000000 - valid_acc: 0.6005 - epoch_time: 141.1108 s\n",
      "Epoch 86\n",
      "[====================] 100/100: - running_loss: 0.6345 - running_reg: 0.000000 - running_acc: 0.6169 - lr: 0.00054 - epoch_loss: 0.6337 - epoch_reg: 0.000000 - epoch_acc: 0.6316 - valid_loss: 0.6946 - valid_reg: 0.000000 - valid_acc: 0.5939 - epoch_time: 141.6270 s\n",
      "Epoch 87\n",
      "[====================] 100/100: - running_loss: 0.6430 - running_reg: 0.000000 - running_acc: 0.6122 - lr: 0.00053 - epoch_loss: 0.6492 - epoch_reg: 0.000000 - epoch_acc: 0.6019 - valid_loss: 0.6623 - valid_reg: 0.000000 - valid_acc: 0.6151 - epoch_time: 141.3760 s\n",
      "Epoch 88\n",
      "[====================] 100/100: - running_loss: 0.6289 - running_reg: 0.000000 - running_acc: 0.6229 - lr: 0.00053 - epoch_loss: 0.6249 - epoch_reg: 0.000000 - epoch_acc: 0.6388 - valid_loss: 0.6449 - valid_reg: 0.000000 - valid_acc: 0.6037 - epoch_time: 141.3070 s\n",
      "Epoch 89\n",
      "[====================] 100/100: - running_loss: 0.6192 - running_reg: 0.000000 - running_acc: 0.6210 - lr: 0.00053 - epoch_loss: 0.6052 - epoch_reg: 0.000000 - epoch_acc: 0.6409 - valid_loss: 0.6295 - valid_reg: 0.000000 - valid_acc: 0.6247 - epoch_time: 140.5815 s\n",
      "Epoch 90\n",
      "[====================] 100/100: - running_loss: 0.6153 - running_reg: 0.000000 - running_acc: 0.6404 - lr: 0.00052 - epoch_loss: 0.6137 - epoch_reg: 0.000000 - epoch_acc: 0.6347 - valid_loss: 0.6449 - valid_reg: 0.000000 - valid_acc: 0.6026 - epoch_time: 140.6493 s\n",
      "Epoch 91\n",
      "[====================] 100/100: - running_loss: 0.6153 - running_reg: 0.000000 - running_acc: 0.6369 - lr: 0.00052 - epoch_loss: 0.5929 - epoch_reg: 0.000000 - epoch_acc: 0.6675 - valid_loss: 0.6426 - valid_reg: 0.000000 - valid_acc: 0.6215 - epoch_time: 143.4202 s\n",
      "Epoch 92\n",
      "[====================] 100/100: - running_loss: 0.5394 - running_reg: 0.000000 - running_acc: 0.7081 - lr: 0.00052 - epoch_loss: 0.5637 - epoch_reg: 0.000000 - epoch_acc: 0.7003 - valid_loss: 0.6871 - valid_reg: 0.000000 - valid_acc: 0.6060 - epoch_time: 140.8420 s\n",
      "Epoch 93\n",
      "[====================] 100/100: - running_loss: 0.5686 - running_reg: 0.000000 - running_acc: 0.6965 - lr: 0.00052 - epoch_loss: 0.5444 - epoch_reg: 0.000000 - epoch_acc: 0.7212 - valid_loss: 0.6588 - valid_reg: 0.000000 - valid_acc: 0.6106 - epoch_time: 141.3078 s\n",
      "Epoch 94\n",
      "[====================] 100/100: - running_loss: 0.5873 - running_reg: 0.000000 - running_acc: 0.6822 - lr: 0.00051 - epoch_loss: 0.5576 - epoch_reg: 0.000000 - epoch_acc: 0.7047 - valid_loss: 0.6443 - valid_reg: 0.000000 - valid_acc: 0.6304 - epoch_time: 141.7250 s\n",
      "Epoch 95\n",
      "[====================] 100/100: - running_loss: 0.6086 - running_reg: 0.000000 - running_acc: 0.6598 - lr: 0.00051 - epoch_loss: 0.5873 - epoch_reg: 0.000000 - epoch_acc: 0.6812 - valid_loss: 0.6512 - valid_reg: 0.000000 - valid_acc: 0.6074 - epoch_time: 142.2363 s\n",
      "Epoch 96\n",
      "[====================] 100/100: - running_loss: 0.6071 - running_reg: 0.000000 - running_acc: 0.6678 - lr: 0.00051 - epoch_loss: 0.5992 - epoch_reg: 0.000000 - epoch_acc: 0.6659 - valid_loss: 0.6508 - valid_reg: 0.000000 - valid_acc: 0.6181 - epoch_time: 141.6757 s\n",
      "Epoch 97\n",
      "[====================] 100/100: - running_loss: 0.6155 - running_reg: 0.000000 - running_acc: 0.6455 - lr: 0.00051 - epoch_loss: 0.6049 - epoch_reg: 0.000000 - epoch_acc: 0.6572 - valid_loss: 0.6399 - valid_reg: 0.000000 - valid_acc: 0.6145 - epoch_time: 141.5845 s\n",
      "Epoch 98\n",
      "[====================] 100/100: - running_loss: 0.5906 - running_reg: 0.000000 - running_acc: 0.6683 - lr: 0.00050 - epoch_loss: 0.5840 - epoch_reg: 0.000000 - epoch_acc: 0.6806 - valid_loss: 0.6521 - valid_reg: 0.000000 - valid_acc: 0.6121 - epoch_time: 141.2367 s\n",
      "Epoch 99\n",
      "[====================] 100/100: - running_loss: 0.6142 - running_reg: 0.000000 - running_acc: 0.6589 - lr: 0.00050 - epoch_loss: 0.6064 - epoch_reg: 0.000000 - epoch_acc: 0.6634 - valid_loss: 0.6395 - valid_reg: 0.000000 - valid_acc: 0.6244 - epoch_time: 141.9838 s\n",
      "Epoch 100\n",
      "[====================] 100/100: - running_loss: 0.5548 - running_reg: 0.000000 - running_acc: 0.7116 - lr: 0.00050 - epoch_loss: 0.5977 - epoch_reg: 0.000000 - epoch_acc: 0.6684 - valid_loss: 0.7329 - valid_reg: 0.000000 - valid_acc: 0.6281 - epoch_time: 141.2236 s\n",
      "Epoch 101\n",
      "[====================] 100/100: - running_loss: 0.5814 - running_reg: 0.000000 - running_acc: 0.6872 - lr: 0.00050 - epoch_loss: 0.5930 - epoch_reg: 0.000000 - epoch_acc: 0.6853 - valid_loss: 0.6441 - valid_reg: 0.000000 - valid_acc: 0.6311 - epoch_time: 141.2051 s\n",
      "Epoch 102\n",
      "[====================] 100/100: - running_loss: 0.5240 - running_reg: 0.000000 - running_acc: 0.7395 - lr: 0.00049 - epoch_loss: 0.5530 - epoch_reg: 0.000000 - epoch_acc: 0.7150 - valid_loss: 0.6382 - valid_reg: 0.000000 - valid_acc: 0.6398 - epoch_time: 141.1210 s\n",
      "Epoch 103\n",
      "[====================] 100/100: - running_loss: 0.4940 - running_reg: 0.000000 - running_acc: 0.7449 - lr: 0.00049 - epoch_loss: 0.4991 - epoch_reg: 0.000000 - epoch_acc: 0.7491 - valid_loss: 0.6983 - valid_reg: 0.000000 - valid_acc: 0.6310 - epoch_time: 141.2304 s\n",
      "Epoch 104\n",
      "[====================] 100/100: - running_loss: 0.4344 - running_reg: 0.000000 - running_acc: 0.7848 - lr: 0.00049 - epoch_loss: 0.4471 - epoch_reg: 0.000000 - epoch_acc: 0.7866 - valid_loss: 0.6993 - valid_reg: 0.000000 - valid_acc: 0.5937 - epoch_time: 143.9423 s\n",
      "Epoch 105\n",
      "[====================] 100/100: - running_loss: 0.3950 - running_reg: 0.000000 - running_acc: 0.8198 - lr: 0.00049 - epoch_loss: 0.4123 - epoch_reg: 0.000000 - epoch_acc: 0.8141 - valid_loss: 0.7425 - valid_reg: 0.000000 - valid_acc: 0.5950 - epoch_time: 145.8144 s\n",
      "Epoch 106\n",
      "[====================] 100/100: - running_loss: 0.4100 - running_reg: 0.000000 - running_acc: 0.8243 - lr: 0.00048 - epoch_loss: 0.4058 - epoch_reg: 0.000000 - epoch_acc: 0.8144 - valid_loss: 0.7604 - valid_reg: 0.000000 - valid_acc: 0.5977 - epoch_time: 142.0015 s\n",
      "Epoch 107\n",
      "[====================] 100/100: - running_loss: 0.4859 - running_reg: 0.000000 - running_acc: 0.7740 - lr: 0.00048 - epoch_loss: 0.4383 - epoch_reg: 0.000000 - epoch_acc: 0.7987 - valid_loss: 0.6519 - valid_reg: 0.000000 - valid_acc: 0.6264 - epoch_time: 141.5615 s\n",
      "Epoch 108\n",
      "[====================] 100/100: - running_loss: 0.5111 - running_reg: 0.000000 - running_acc: 0.7484 - lr: 0.00048 - epoch_loss: 0.4824 - epoch_reg: 0.000000 - epoch_acc: 0.7588 - valid_loss: 0.6420 - valid_reg: 0.000000 - valid_acc: 0.6235 - epoch_time: 140.9100 s\n",
      "Epoch 109\n",
      "[====================] 100/100: - running_loss: 0.5470 - running_reg: 0.000000 - running_acc: 0.7230 - lr: 0.00048 - epoch_loss: 0.5147 - epoch_reg: 0.000000 - epoch_acc: 0.7353 - valid_loss: 0.6659 - valid_reg: 0.000000 - valid_acc: 0.6223 - epoch_time: 140.5991 s\n",
      "Epoch 110\n",
      "[====================] 100/100: - running_loss: 0.5067 - running_reg: 0.000000 - running_acc: 0.7410 - lr: 0.00047 - epoch_loss: 0.5200 - epoch_reg: 0.000000 - epoch_acc: 0.7312 - valid_loss: 0.7146 - valid_reg: 0.000000 - valid_acc: 0.6394 - epoch_time: 141.0495 s\n",
      "Epoch 111\n",
      "[====================] 100/100: - running_loss: 0.4564 - running_reg: 0.000000 - running_acc: 0.7707 - lr: 0.00047 - epoch_loss: 0.4689 - epoch_reg: 0.000000 - epoch_acc: 0.7631 - valid_loss: 0.6522 - valid_reg: 0.000000 - valid_acc: 0.6469 - epoch_time: 140.5096 s\n",
      "Epoch 112\n",
      "[====================] 100/100: - running_loss: 0.4880 - running_reg: 0.000000 - running_acc: 0.7578 - lr: 0.00047 - epoch_loss: 0.4652 - epoch_reg: 0.000000 - epoch_acc: 0.7688 - valid_loss: 0.7367 - valid_reg: 0.000000 - valid_acc: 0.6266 - epoch_time: 140.4065 s\n",
      "Epoch 113\n",
      "[====================] 100/100: - running_loss: 0.4466 - running_reg: 0.000000 - running_acc: 0.7853 - lr: 0.00047 - epoch_loss: 0.4767 - epoch_reg: 0.000000 - epoch_acc: 0.7628 - valid_loss: 0.7921 - valid_reg: 0.000000 - valid_acc: 0.6436 - epoch_time: 140.4358 s\n",
      "Epoch 114\n",
      "[====================] 100/100: - running_loss: 0.4881 - running_reg: 0.000000 - running_acc: 0.7513 - lr: 0.00047 - epoch_loss: 0.4808 - epoch_reg: 0.000000 - epoch_acc: 0.7634 - valid_loss: 0.7594 - valid_reg: 0.000000 - valid_acc: 0.6231 - epoch_time: 141.0884 s\n",
      "Epoch 115\n",
      "[====================] 100/100: - running_loss: 0.4837 - running_reg: 0.000000 - running_acc: 0.7619 - lr: 0.00046 - epoch_loss: 0.4850 - epoch_reg: 0.000000 - epoch_acc: 0.7634 - valid_loss: 0.9125 - valid_reg: 0.000000 - valid_acc: 0.6239 - epoch_time: 141.0585 s\n",
      "Epoch 116\n",
      "[====================] 100/100: - running_loss: 0.4924 - running_reg: 0.000000 - running_acc: 0.7510 - lr: 0.00046 - epoch_loss: 0.4940 - epoch_reg: 0.000000 - epoch_acc: 0.7575 - valid_loss: 0.7937 - valid_reg: 0.000000 - valid_acc: 0.6364 - epoch_time: 140.8351 s\n",
      "Epoch 117\n",
      "[====================] 100/100: - running_loss: 0.5351 - running_reg: 0.000000 - running_acc: 0.7303 - lr: 0.00046 - epoch_loss: 0.5320 - epoch_reg: 0.000000 - epoch_acc: 0.7212 - valid_loss: 0.7361 - valid_reg: 0.000000 - valid_acc: 0.6340 - epoch_time: 140.5437 s\n",
      "Epoch 118\n",
      "[====================] 100/100: - running_loss: 0.5255 - running_reg: 0.000000 - running_acc: 0.7245 - lr: 0.00046 - epoch_loss: 0.5304 - epoch_reg: 0.000000 - epoch_acc: 0.7303 - valid_loss: 0.9199 - valid_reg: 0.000000 - valid_acc: 0.6243 - epoch_time: 141.0335 s\n",
      "Epoch 119\n",
      "[====================] 100/100: - running_loss: 0.5332 - running_reg: 0.000000 - running_acc: 0.7176 - lr: 0.00046 - epoch_loss: 0.5227 - epoch_reg: 0.000000 - epoch_acc: 0.7272 - valid_loss: 1.0022 - valid_reg: 0.000000 - valid_acc: 0.5901 - epoch_time: 141.3775 s\n",
      "Epoch 120\n",
      "[====================] 100/100: - running_loss: 0.5873 - running_reg: 0.000000 - running_acc: 0.6844 - lr: 0.00045 - epoch_loss: 0.5645 - epoch_reg: 0.000000 - epoch_acc: 0.7016 - valid_loss: 0.6697 - valid_reg: 0.000000 - valid_acc: 0.6482 - epoch_time: 141.0904 s\n",
      "Epoch 121\n",
      "[====================] 100/100: - running_loss: 0.5441 - running_reg: 0.000000 - running_acc: 0.7245 - lr: 0.00045 - epoch_loss: 0.5348 - epoch_reg: 0.000000 - epoch_acc: 0.7225 - valid_loss: 0.6193 - valid_reg: 0.000000 - valid_acc: 0.6552 - epoch_time: 141.5164 s\n",
      "Epoch 122\n",
      "[====================] 100/100: - running_loss: 0.5309 - running_reg: 0.000000 - running_acc: 0.7104 - lr: 0.00045 - epoch_loss: 0.5401 - epoch_reg: 0.000000 - epoch_acc: 0.7194 - valid_loss: 0.6028 - valid_reg: 0.000000 - valid_acc: 0.6577 - epoch_time: 141.0126 s\n",
      "Epoch 123\n",
      "[====================] 100/100: - running_loss: 0.4916 - running_reg: 0.000000 - running_acc: 0.7499 - lr: 0.00045 - epoch_loss: 0.5088 - epoch_reg: 0.000000 - epoch_acc: 0.7334 - valid_loss: 0.6344 - valid_reg: 0.000000 - valid_acc: 0.6519 - epoch_time: 140.7947 s\n",
      "Epoch 124\n",
      "[====================] 100/100: - running_loss: 0.4800 - running_reg: 0.000000 - running_acc: 0.7529 - lr: 0.00045 - epoch_loss: 0.4783 - epoch_reg: 0.000000 - epoch_acc: 0.7619 - valid_loss: 0.6693 - valid_reg: 0.000000 - valid_acc: 0.6281 - epoch_time: 141.2315 s\n",
      "Epoch 125\n",
      "[====================] 100/100: - running_loss: 0.5016 - running_reg: 0.000000 - running_acc: 0.7423 - lr: 0.00045 - epoch_loss: 0.5047 - epoch_reg: 0.000000 - epoch_acc: 0.7406 - valid_loss: 0.6322 - valid_reg: 0.000000 - valid_acc: 0.6488 - epoch_time: 140.6150 s\n",
      "Epoch 126\n",
      "[====================] 100/100: - running_loss: 0.5461 - running_reg: 0.000000 - running_acc: 0.7172 - lr: 0.00044 - epoch_loss: 0.5362 - epoch_reg: 0.000000 - epoch_acc: 0.7131 - valid_loss: 0.6238 - valid_reg: 0.000000 - valid_acc: 0.6496 - epoch_time: 140.9127 s\n",
      "Epoch 127\n",
      "[====================] 100/100: - running_loss: 0.5638 - running_reg: 0.000000 - running_acc: 0.7037 - lr: 0.00044 - epoch_loss: 0.5503 - epoch_reg: 0.000000 - epoch_acc: 0.7097 - valid_loss: 0.5887 - valid_reg: 0.000000 - valid_acc: 0.6779 - epoch_time: 141.2070 s\n",
      "Epoch 128\n",
      "[====================] 100/100: - running_loss: 0.5508 - running_reg: 0.000000 - running_acc: 0.7117 - lr: 0.00044 - epoch_loss: 0.5525 - epoch_reg: 0.000000 - epoch_acc: 0.7103 - valid_loss: 0.6270 - valid_reg: 0.000000 - valid_acc: 0.6528 - epoch_time: 140.6171 s\n",
      "Epoch 129\n",
      "[====================] 100/100: - running_loss: 0.5547 - running_reg: 0.000000 - running_acc: 0.7097 - lr: 0.00044 - epoch_loss: 0.5680 - epoch_reg: 0.000000 - epoch_acc: 0.7025 - valid_loss: 0.6074 - valid_reg: 0.000000 - valid_acc: 0.6604 - epoch_time: 140.9770 s\n",
      "Epoch 130\n",
      "[====================] 100/100: - running_loss: 0.5822 - running_reg: 0.000000 - running_acc: 0.6676 - lr: 0.00044 - epoch_loss: 0.5713 - epoch_reg: 0.000000 - epoch_acc: 0.6925 - valid_loss: 0.6306 - valid_reg: 0.000000 - valid_acc: 0.6442 - epoch_time: 140.5687 s\n",
      "Epoch 131\n",
      "[====================] 100/100: - running_loss: 0.5635 - running_reg: 0.000000 - running_acc: 0.6933 - lr: 0.00044 - epoch_loss: 0.5770 - epoch_reg: 0.000000 - epoch_acc: 0.6822 - valid_loss: 0.7620 - valid_reg: 0.000000 - valid_acc: 0.6238 - epoch_time: 140.4106 s\n",
      "Epoch 132\n",
      "[====================] 100/100: - running_loss: 0.5929 - running_reg: 0.000000 - running_acc: 0.6653 - lr: 0.00043 - epoch_loss: 0.6026 - epoch_reg: 0.000000 - epoch_acc: 0.6531 - valid_loss: 0.6946 - valid_reg: 0.000000 - valid_acc: 0.6163 - epoch_time: 141.0302 s\n",
      "Epoch 133\n",
      "[====================] 100/100: - running_loss: 0.6033 - running_reg: 0.000000 - running_acc: 0.6786 - lr: 0.00043 - epoch_loss: 0.5991 - epoch_reg: 0.000000 - epoch_acc: 0.6609 - valid_loss: 0.6089 - valid_reg: 0.000000 - valid_acc: 0.6565 - epoch_time: 140.5566 s\n",
      "Epoch 134\n",
      "[====================] 100/100: - running_loss: 0.5875 - running_reg: 0.000000 - running_acc: 0.6726 - lr: 0.00043 - epoch_loss: 0.5804 - epoch_reg: 0.000000 - epoch_acc: 0.6747 - valid_loss: 0.6141 - valid_reg: 0.000000 - valid_acc: 0.6505 - epoch_time: 140.0957 s\n",
      "Epoch 135\n",
      "[====================] 100/100: - running_loss: 0.5536 - running_reg: 0.000000 - running_acc: 0.6991 - lr: 0.00043 - epoch_loss: 0.5603 - epoch_reg: 0.000000 - epoch_acc: 0.6856 - valid_loss: 0.6457 - valid_reg: 0.000000 - valid_acc: 0.6337 - epoch_time: 140.3840 s\n",
      "Epoch 136\n",
      "[====================] 100/100: - running_loss: 0.5642 - running_reg: 0.000000 - running_acc: 0.6718 - lr: 0.00043 - epoch_loss: 0.5645 - epoch_reg: 0.000000 - epoch_acc: 0.6750 - valid_loss: 0.6129 - valid_reg: 0.000000 - valid_acc: 0.6426 - epoch_time: 140.4813 s\n",
      "Epoch 137\n",
      "[====================] 100/100: - running_loss: 0.5554 - running_reg: 0.000000 - running_acc: 0.6953 - lr: 0.00043 - epoch_loss: 0.5578 - epoch_reg: 0.000000 - epoch_acc: 0.6891 - valid_loss: 0.6469 - valid_reg: 0.000000 - valid_acc: 0.6278 - epoch_time: 202.5262 s\n",
      "Epoch 138\n",
      "[====================] 100/100: - running_loss: 0.5091 - running_reg: 0.000000 - running_acc: 0.7307 - lr: 0.00042 - epoch_loss: 0.5337 - epoch_reg: 0.000000 - epoch_acc: 0.7169 - valid_loss: 0.6348 - valid_reg: 0.000000 - valid_acc: 0.6513 - epoch_time: 141.3326 s\n",
      "Epoch 139\n",
      "[====================] 100/100: - running_loss: 0.5179 - running_reg: 0.000000 - running_acc: 0.7389 - lr: 0.00042 - epoch_loss: 0.5139 - epoch_reg: 0.000000 - epoch_acc: 0.7312 - valid_loss: 0.6296 - valid_reg: 0.000000 - valid_acc: 0.6504 - epoch_time: 140.6363 s\n",
      "Epoch 140\n",
      "[====================] 100/100: - running_loss: 0.5176 - running_reg: 0.000000 - running_acc: 0.7357 - lr: 0.00042 - epoch_loss: 0.5180 - epoch_reg: 0.000000 - epoch_acc: 0.7350 - valid_loss: 0.6165 - valid_reg: 0.000000 - valid_acc: 0.6586 - epoch_time: 140.4441 s\n",
      "Epoch 141\n",
      "[====================] 100/100: - running_loss: 0.5437 - running_reg: 0.000000 - running_acc: 0.7142 - lr: 0.00042 - epoch_loss: 0.5335 - epoch_reg: 0.000000 - epoch_acc: 0.7212 - valid_loss: 0.6277 - valid_reg: 0.000000 - valid_acc: 0.6503 - epoch_time: 140.8611 s\n",
      "Epoch 142\n",
      "[====================] 100/100: - running_loss: 0.5786 - running_reg: 0.000000 - running_acc: 0.6760 - lr: 0.00042 - epoch_loss: 0.5461 - epoch_reg: 0.000000 - epoch_acc: 0.7169 - valid_loss: 0.6213 - valid_reg: 0.000000 - valid_acc: 0.6482 - epoch_time: 140.8775 s\n",
      "Epoch 143\n",
      "[====================] 100/100: - running_loss: 0.5233 - running_reg: 0.000000 - running_acc: 0.7212 - lr: 0.00042 - epoch_loss: 0.5359 - epoch_reg: 0.000000 - epoch_acc: 0.7212 - valid_loss: 0.6771 - valid_reg: 0.000000 - valid_acc: 0.6390 - epoch_time: 141.4033 s\n",
      "Epoch 144\n",
      "[====================] 100/100: - running_loss: 0.5690 - running_reg: 0.000000 - running_acc: 0.6876 - lr: 0.00042 - epoch_loss: 0.5620 - epoch_reg: 0.000000 - epoch_acc: 0.7038 - valid_loss: 0.6327 - valid_reg: 0.000000 - valid_acc: 0.6410 - epoch_time: 141.0095 s\n",
      "Epoch 145\n",
      "[====================] 100/100: - running_loss: 0.5512 - running_reg: 0.000000 - running_acc: 0.7035 - lr: 0.00041 - epoch_loss: 0.5503 - epoch_reg: 0.000000 - epoch_acc: 0.7184 - valid_loss: 0.6141 - valid_reg: 0.000000 - valid_acc: 0.6439 - epoch_time: 140.8311 s\n",
      "Epoch 146\n",
      "[====================] 100/100: - running_loss: 0.5095 - running_reg: 0.000000 - running_acc: 0.7339 - lr: 0.00041 - epoch_loss: 0.5347 - epoch_reg: 0.000000 - epoch_acc: 0.7119 - valid_loss: 0.6635 - valid_reg: 0.000000 - valid_acc: 0.6521 - epoch_time: 144.1910 s\n",
      "Epoch 147\n",
      "[====================] 100/100: - running_loss: 0.4836 - running_reg: 0.000000 - running_acc: 0.7506 - lr: 0.00041 - epoch_loss: 0.4880 - epoch_reg: 0.000000 - epoch_acc: 0.7513 - valid_loss: 0.6398 - valid_reg: 0.000000 - valid_acc: 0.6565 - epoch_time: 146.0435 s\n",
      "Epoch 148\n",
      "[====================] 100/100: - running_loss: 0.4507 - running_reg: 0.000000 - running_acc: 0.7894 - lr: 0.00041 - epoch_loss: 0.4717 - epoch_reg: 0.000000 - epoch_acc: 0.7631 - valid_loss: 0.6102 - valid_reg: 0.000000 - valid_acc: 0.6675 - epoch_time: 141.4848 s\n",
      "Epoch 149\n",
      "[====================] 100/100: - running_loss: 0.3439 - running_reg: 0.000000 - running_acc: 0.8518 - lr: 0.00041 - epoch_loss: 0.4045 - epoch_reg: 0.000000 - epoch_acc: 0.8059 - valid_loss: 0.7054 - valid_reg: 0.000000 - valid_acc: 0.6398 - epoch_time: 141.9219 s\n",
      " - test_loss: 0.5936 - test_reg: 0.000000 - test_acc: 0.6775 - test_time: 95.5556 s\n",
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n",
      "Epoch 0\n",
      "[====================] 100/100: - running_loss: 1.0690 - running_reg: 0.000000 - running_acc: 0.5017 - lr: 0.00001 - epoch_loss: 1.1944 - epoch_reg: 0.000000 - epoch_acc: 0.5003 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 49.7803 s\n",
      "Epoch 1\n",
      "[====================] 100/100: - running_loss: 0.9628 - running_reg: 0.000000 - running_acc: 0.5204 - lr: 0.00001 - epoch_loss: 1.0313 - epoch_reg: 0.000000 - epoch_acc: 0.5038 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8406 s\n",
      "Epoch 2\n",
      "[====================] 100/100: - running_loss: 0.8842 - running_reg: 0.000000 - running_acc: 0.5094 - lr: 0.00002 - epoch_loss: 0.8604 - epoch_reg: 0.000000 - epoch_acc: 0.5359 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8998 s\n",
      "Epoch 3\n",
      "[====================] 100/100: - running_loss: 0.8502 - running_reg: 0.000000 - running_acc: 0.5010 - lr: 0.00003 - epoch_loss: 0.8582 - epoch_reg: 0.000000 - epoch_acc: 0.4941 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9730 s\n",
      "Epoch 4\n",
      "[====================] 100/100: - running_loss: 0.7522 - running_reg: 0.000000 - running_acc: 0.5635 - lr: 0.00003 - epoch_loss: 0.8051 - epoch_reg: 0.000000 - epoch_acc: 0.5169 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8971 s\n",
      "Epoch 5\n",
      "[====================] 100/100: - running_loss: 0.7837 - running_reg: 0.000000 - running_acc: 0.5127 - lr: 0.00004 - epoch_loss: 0.7906 - epoch_reg: 0.000000 - epoch_acc: 0.5069 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0131 s\n",
      "Epoch 6\n",
      "[====================] 100/100: - running_loss: 0.7783 - running_reg: 0.000000 - running_acc: 0.5028 - lr: 0.00005 - epoch_loss: 0.7833 - epoch_reg: 0.000000 - epoch_acc: 0.5044 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9604 s\n",
      "Epoch 7\n",
      "[====================] 100/100: - running_loss: 0.7591 - running_reg: 0.000000 - running_acc: 0.5174 - lr: 0.00006 - epoch_loss: 0.7679 - epoch_reg: 0.000000 - epoch_acc: 0.5153 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3120 s\n",
      "Epoch 8\n",
      "[====================] 100/100: - running_loss: 0.7640 - running_reg: 0.000000 - running_acc: 0.5068 - lr: 0.00006 - epoch_loss: 0.7633 - epoch_reg: 0.000000 - epoch_acc: 0.5141 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3835 s\n",
      "Epoch 9\n",
      "[====================] 100/100: - running_loss: 0.7270 - running_reg: 0.000000 - running_acc: 0.5241 - lr: 0.00007 - epoch_loss: 0.7427 - epoch_reg: 0.000000 - epoch_acc: 0.5119 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.4278 s\n",
      "Epoch 10\n",
      "[====================] 100/100: - running_loss: 0.7394 - running_reg: 0.000000 - running_acc: 0.5104 - lr: 0.00008 - epoch_loss: 0.7413 - epoch_reg: 0.000000 - epoch_acc: 0.5181 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2684 s\n",
      "Epoch 11\n",
      "[====================] 100/100: - running_loss: 0.7264 - running_reg: 0.000000 - running_acc: 0.5313 - lr: 0.00008 - epoch_loss: 0.7295 - epoch_reg: 0.000000 - epoch_acc: 0.5272 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.4831 s\n",
      "Epoch 12\n",
      "[====================] 100/100: - running_loss: 0.7017 - running_reg: 0.000000 - running_acc: 0.5293 - lr: 0.00009 - epoch_loss: 0.7338 - epoch_reg: 0.000000 - epoch_acc: 0.5144 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3272 s\n",
      "Epoch 13\n",
      "[====================] 100/100: - running_loss: 0.7335 - running_reg: 0.000000 - running_acc: 0.5505 - lr: 0.00010 - epoch_loss: 0.7156 - epoch_reg: 0.000000 - epoch_acc: 0.5578 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0890 s\n",
      "Epoch 14\n",
      "[====================] 100/100: - running_loss: 0.6749 - running_reg: 0.000000 - running_acc: 0.5804 - lr: 0.00010 - epoch_loss: 0.6770 - epoch_reg: 0.000000 - epoch_acc: 0.5800 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9069 s\n",
      "Epoch 15\n",
      "[====================] 100/100: - running_loss: 0.6858 - running_reg: 0.000000 - running_acc: 0.5739 - lr: 0.00011 - epoch_loss: 0.6873 - epoch_reg: 0.000000 - epoch_acc: 0.5875 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0902 s\n",
      "Epoch 16\n",
      "[====================] 100/100: - running_loss: 0.6956 - running_reg: 0.000000 - running_acc: 0.5543 - lr: 0.00012 - epoch_loss: 0.6980 - epoch_reg: 0.000000 - epoch_acc: 0.5672 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0510 s\n",
      "Epoch 17\n",
      "[====================] 100/100: - running_loss: 0.6961 - running_reg: 0.000000 - running_acc: 0.5436 - lr: 0.00013 - epoch_loss: 0.6914 - epoch_reg: 0.000000 - epoch_acc: 0.5634 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0687 s\n",
      "Epoch 18\n",
      "[====================] 100/100: - running_loss: 0.6864 - running_reg: 0.000000 - running_acc: 0.5629 - lr: 0.00013 - epoch_loss: 0.6883 - epoch_reg: 0.000000 - epoch_acc: 0.5544 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9674 s\n",
      "Epoch 19\n",
      "[====================] 100/100: - running_loss: 0.7224 - running_reg: 0.000000 - running_acc: 0.5305 - lr: 0.00014 - epoch_loss: 0.6922 - epoch_reg: 0.000000 - epoch_acc: 0.5556 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9025 s\n",
      "Epoch 20\n",
      "[====================] 100/100: - running_loss: 0.6860 - running_reg: 0.000000 - running_acc: 0.5497 - lr: 0.00015 - epoch_loss: 0.6830 - epoch_reg: 0.000000 - epoch_acc: 0.5506 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9438 s\n",
      "Epoch 21\n",
      "[====================] 100/100: - running_loss: 0.6739 - running_reg: 0.000000 - running_acc: 0.5596 - lr: 0.00015 - epoch_loss: 0.6646 - epoch_reg: 0.000000 - epoch_acc: 0.5728 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0466 s\n",
      "Epoch 22\n",
      "[====================] 100/100: - running_loss: 0.7012 - running_reg: 0.000000 - running_acc: 0.5529 - lr: 0.00016 - epoch_loss: 0.6739 - epoch_reg: 0.000000 - epoch_acc: 0.5659 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1780 s\n",
      "Epoch 23\n",
      "[====================] 100/100: - running_loss: 0.6664 - running_reg: 0.000000 - running_acc: 0.5949 - lr: 0.00017 - epoch_loss: 0.6701 - epoch_reg: 0.000000 - epoch_acc: 0.5813 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0261 s\n",
      "Epoch 24\n",
      "[====================] 100/100: - running_loss: 0.6784 - running_reg: 0.000000 - running_acc: 0.5717 - lr: 0.00017 - epoch_loss: 0.6762 - epoch_reg: 0.000000 - epoch_acc: 0.5719 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9738 s\n",
      "Epoch 25\n",
      "[====================] 100/100: - running_loss: 0.6856 - running_reg: 0.000000 - running_acc: 0.5725 - lr: 0.00018 - epoch_loss: 0.6694 - epoch_reg: 0.000000 - epoch_acc: 0.5909 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0139 s\n",
      "Epoch 26\n",
      "[====================] 100/100: - running_loss: 0.6765 - running_reg: 0.000000 - running_acc: 0.5912 - lr: 0.00019 - epoch_loss: 0.6715 - epoch_reg: 0.000000 - epoch_acc: 0.5888 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2856 s\n",
      "Epoch 27\n",
      "[====================] 100/100: - running_loss: 0.6554 - running_reg: 0.000000 - running_acc: 0.6051 - lr: 0.00020 - epoch_loss: 0.6658 - epoch_reg: 0.000000 - epoch_acc: 0.5994 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0983 s\n",
      "Epoch 28\n",
      "[====================] 100/100: - running_loss: 0.6996 - running_reg: 0.000000 - running_acc: 0.5464 - lr: 0.00020 - epoch_loss: 0.6767 - epoch_reg: 0.000000 - epoch_acc: 0.5866 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0630 s\n",
      "Epoch 29\n",
      "[====================] 100/100: - running_loss: 0.6867 - running_reg: 0.000000 - running_acc: 0.5485 - lr: 0.00021 - epoch_loss: 0.6856 - epoch_reg: 0.000000 - epoch_acc: 0.5516 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2115 s\n",
      "Epoch 30\n",
      "[====================] 100/100: - running_loss: 0.6775 - running_reg: 0.000000 - running_acc: 0.5582 - lr: 0.00022 - epoch_loss: 0.6970 - epoch_reg: 0.000000 - epoch_acc: 0.5300 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9129 s\n",
      "Epoch 31\n",
      "[====================] 100/100: - running_loss: 0.6620 - running_reg: 0.000000 - running_acc: 0.5889 - lr: 0.00022 - epoch_loss: 0.6675 - epoch_reg: 0.000000 - epoch_acc: 0.5944 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9134 s\n",
      "Epoch 32\n",
      "[====================] 100/100: - running_loss: 0.6568 - running_reg: 0.000000 - running_acc: 0.5981 - lr: 0.00023 - epoch_loss: 0.6443 - epoch_reg: 0.000000 - epoch_acc: 0.6225 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0670 s\n",
      "Epoch 33\n",
      "[====================] 100/100: - running_loss: 0.6180 - running_reg: 0.000000 - running_acc: 0.6460 - lr: 0.00024 - epoch_loss: 0.6265 - epoch_reg: 0.000000 - epoch_acc: 0.6438 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0683 s\n",
      "Epoch 34\n",
      "[====================] 100/100: - running_loss: 0.6502 - running_reg: 0.000000 - running_acc: 0.6197 - lr: 0.00024 - epoch_loss: 0.6463 - epoch_reg: 0.000000 - epoch_acc: 0.6278 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0191 s\n",
      "Epoch 35\n",
      "[====================] 100/100: - running_loss: 0.6580 - running_reg: 0.000000 - running_acc: 0.6158 - lr: 0.00025 - epoch_loss: 0.6540 - epoch_reg: 0.000000 - epoch_acc: 0.6072 - valid_loss: 0.7186 - valid_reg: 0.000000 - valid_acc: 0.5412 - epoch_time: 142.3866 s\n",
      "Epoch 36\n",
      "[====================] 100/100: - running_loss: 0.6795 - running_reg: 0.000000 - running_acc: 0.5586 - lr: 0.00026 - epoch_loss: 0.6839 - epoch_reg: 0.000000 - epoch_acc: 0.5562 - valid_loss: 0.6846 - valid_reg: 0.000000 - valid_acc: 0.5407 - epoch_time: 141.1527 s\n",
      "Epoch 37\n",
      "[====================] 100/100: - running_loss: 0.6912 - running_reg: 0.000000 - running_acc: 0.5406 - lr: 0.00027 - epoch_loss: 0.6820 - epoch_reg: 0.000000 - epoch_acc: 0.5553 - valid_loss: 0.6727 - valid_reg: 0.000000 - valid_acc: 0.5626 - epoch_time: 142.6685 s\n",
      "Epoch 38\n",
      "[====================] 100/100: - running_loss: 0.6958 - running_reg: 0.000000 - running_acc: 0.5215 - lr: 0.00027 - epoch_loss: 0.6915 - epoch_reg: 0.000000 - epoch_acc: 0.5306 - valid_loss: 0.6999 - valid_reg: 0.000000 - valid_acc: 0.5095 - epoch_time: 142.1724 s\n",
      "Epoch 39\n",
      "[====================] 100/100: - running_loss: 0.6886 - running_reg: 0.000000 - running_acc: 0.5296 - lr: 0.00028 - epoch_loss: 0.6910 - epoch_reg: 0.000000 - epoch_acc: 0.5247 - valid_loss: 0.6859 - valid_reg: 0.000000 - valid_acc: 0.5664 - epoch_time: 141.4604 s\n",
      "Epoch 40\n",
      "[====================] 100/100: - running_loss: 0.6798 - running_reg: 0.000000 - running_acc: 0.5996 - lr: 0.00029 - epoch_loss: 0.6831 - epoch_reg: 0.000000 - epoch_acc: 0.5606 - valid_loss: 0.7345 - valid_reg: 0.000000 - valid_acc: 0.5026 - epoch_time: 141.0708 s\n",
      "Epoch 41\n",
      "[====================] 100/100: - running_loss: 0.6785 - running_reg: 0.000000 - running_acc: 0.5581 - lr: 0.00029 - epoch_loss: 0.6830 - epoch_reg: 0.000000 - epoch_acc: 0.5587 - valid_loss: 0.6728 - valid_reg: 0.000000 - valid_acc: 0.5671 - epoch_time: 140.8945 s\n",
      "Epoch 42\n",
      "[====================] 100/100: - running_loss: 0.7000 - running_reg: 0.000000 - running_acc: 0.5243 - lr: 0.00030 - epoch_loss: 0.6868 - epoch_reg: 0.000000 - epoch_acc: 0.5406 - valid_loss: 0.6795 - valid_reg: 0.000000 - valid_acc: 0.5574 - epoch_time: 140.9106 s\n",
      "Epoch 43\n",
      "[====================] 100/100: - running_loss: 0.6882 - running_reg: 0.000000 - running_acc: 0.5248 - lr: 0.00031 - epoch_loss: 0.6737 - epoch_reg: 0.000000 - epoch_acc: 0.5512 - valid_loss: 0.6745 - valid_reg: 0.000000 - valid_acc: 0.5621 - epoch_time: 141.7153 s\n",
      "Epoch 44\n",
      "[====================] 100/100: - running_loss: 0.6672 - running_reg: 0.000000 - running_acc: 0.5760 - lr: 0.00031 - epoch_loss: 0.6720 - epoch_reg: 0.000000 - epoch_acc: 0.5600 - valid_loss: 0.6828 - valid_reg: 0.000000 - valid_acc: 0.5161 - epoch_time: 139.9006 s\n",
      "Epoch 45\n",
      "[====================] 100/100: - running_loss: 0.6782 - running_reg: 0.000000 - running_acc: 0.5642 - lr: 0.00032 - epoch_loss: 0.6752 - epoch_reg: 0.000000 - epoch_acc: 0.5575 - valid_loss: 0.6908 - valid_reg: 0.000000 - valid_acc: 0.5182 - epoch_time: 143.4383 s\n",
      "Epoch 46\n",
      "[====================] 100/100: - running_loss: 0.6178 - running_reg: 0.000000 - running_acc: 0.6568 - lr: 0.00033 - epoch_loss: 0.6097 - epoch_reg: 0.000000 - epoch_acc: 0.6606 - valid_loss: 0.6815 - valid_reg: 0.000000 - valid_acc: 0.5376 - epoch_time: 140.4005 s\n",
      "Epoch 47\n",
      "[====================] 100/100: - running_loss: 0.6231 - running_reg: 0.000000 - running_acc: 0.6298 - lr: 0.00034 - epoch_loss: 0.5946 - epoch_reg: 0.000000 - epoch_acc: 0.6759 - valid_loss: 0.6715 - valid_reg: 0.000000 - valid_acc: 0.5463 - epoch_time: 140.7965 s\n",
      "Epoch 48\n",
      "[====================] 100/100: - running_loss: 0.6686 - running_reg: 0.000000 - running_acc: 0.5888 - lr: 0.00034 - epoch_loss: 0.6413 - epoch_reg: 0.000000 - epoch_acc: 0.6103 - valid_loss: 0.6693 - valid_reg: 0.000000 - valid_acc: 0.5670 - epoch_time: 141.4932 s\n",
      "Epoch 49\n",
      "[====================] 100/100: - running_loss: 0.6817 - running_reg: 0.000000 - running_acc: 0.5308 - lr: 0.00035 - epoch_loss: 0.6609 - epoch_reg: 0.000000 - epoch_acc: 0.5656 - valid_loss: 0.6765 - valid_reg: 0.000000 - valid_acc: 0.5776 - epoch_time: 141.5196 s\n",
      "Epoch 50\n",
      "[====================] 100/100: - running_loss: 0.6956 - running_reg: 0.000000 - running_acc: 0.5253 - lr: 0.00036 - epoch_loss: 0.6761 - epoch_reg: 0.000000 - epoch_acc: 0.5516 - valid_loss: 0.6794 - valid_reg: 0.000000 - valid_acc: 0.5572 - epoch_time: 141.9343 s\n",
      "Epoch 51\n",
      "[====================] 100/100: - running_loss: 0.6559 - running_reg: 0.000000 - running_acc: 0.6132 - lr: 0.00036 - epoch_loss: 0.6609 - epoch_reg: 0.000000 - epoch_acc: 0.5856 - valid_loss: 0.7125 - valid_reg: 0.000000 - valid_acc: 0.5295 - epoch_time: 141.8583 s\n",
      "Epoch 52\n",
      "[====================] 100/100: - running_loss: 0.6375 - running_reg: 0.000000 - running_acc: 0.6460 - lr: 0.00037 - epoch_loss: 0.6437 - epoch_reg: 0.000000 - epoch_acc: 0.6125 - valid_loss: 0.7577 - valid_reg: 0.000000 - valid_acc: 0.5095 - epoch_time: 141.1797 s\n",
      "Epoch 53\n",
      "[====================] 100/100: - running_loss: 0.6664 - running_reg: 0.000000 - running_acc: 0.5402 - lr: 0.00038 - epoch_loss: 0.6669 - epoch_reg: 0.000000 - epoch_acc: 0.5741 - valid_loss: 0.6519 - valid_reg: 0.000000 - valid_acc: 0.5784 - epoch_time: 142.3362 s\n",
      "Epoch 54\n",
      "[====================] 100/100: - running_loss: 0.6630 - running_reg: 0.000000 - running_acc: 0.5737 - lr: 0.00038 - epoch_loss: 0.6617 - epoch_reg: 0.000000 - epoch_acc: 0.5663 - valid_loss: 0.6662 - valid_reg: 0.000000 - valid_acc: 0.5718 - epoch_time: 142.1069 s\n",
      "Epoch 55\n",
      "[====================] 100/100: - running_loss: 0.6700 - running_reg: 0.000000 - running_acc: 0.5839 - lr: 0.00039 - epoch_loss: 0.6622 - epoch_reg: 0.000000 - epoch_acc: 0.5844 - valid_loss: 0.6610 - valid_reg: 0.000000 - valid_acc: 0.5934 - epoch_time: 142.0116 s\n",
      "Epoch 56\n",
      "[====================] 100/100: - running_loss: 0.6124 - running_reg: 0.000000 - running_acc: 0.6407 - lr: 0.00040 - epoch_loss: 0.6360 - epoch_reg: 0.000000 - epoch_acc: 0.6159 - valid_loss: 0.6531 - valid_reg: 0.000000 - valid_acc: 0.6042 - epoch_time: 141.8439 s\n",
      "Epoch 57\n",
      "[====================] 100/100: - running_loss: 0.5816 - running_reg: 0.000000 - running_acc: 0.6894 - lr: 0.00041 - epoch_loss: 0.6209 - epoch_reg: 0.000000 - epoch_acc: 0.6494 - valid_loss: 0.7149 - valid_reg: 0.000000 - valid_acc: 0.5840 - epoch_time: 141.4583 s\n",
      "Epoch 58\n",
      "[====================] 100/100: - running_loss: 0.5691 - running_reg: 0.000000 - running_acc: 0.7018 - lr: 0.00041 - epoch_loss: 0.5781 - epoch_reg: 0.000000 - epoch_acc: 0.6866 - valid_loss: 0.6694 - valid_reg: 0.000000 - valid_acc: 0.5864 - epoch_time: 141.6229 s\n",
      "Epoch 59\n",
      "[====================] 100/100: - running_loss: 0.5145 - running_reg: 0.000000 - running_acc: 0.7339 - lr: 0.00042 - epoch_loss: 0.5321 - epoch_reg: 0.000000 - epoch_acc: 0.7322 - valid_loss: 0.6857 - valid_reg: 0.000000 - valid_acc: 0.5702 - epoch_time: 141.9956 s\n",
      "Epoch 60\n",
      "[====================] 100/100: - running_loss: 0.4831 - running_reg: 0.000000 - running_acc: 0.7642 - lr: 0.00043 - epoch_loss: 0.5116 - epoch_reg: 0.000000 - epoch_acc: 0.7534 - valid_loss: 0.7802 - valid_reg: 0.000000 - valid_acc: 0.5877 - epoch_time: 141.6260 s\n",
      "Epoch 61\n",
      "[====================] 100/100: - running_loss: 0.5157 - running_reg: 0.000000 - running_acc: 0.7550 - lr: 0.00043 - epoch_loss: 0.5217 - epoch_reg: 0.000000 - epoch_acc: 0.7547 - valid_loss: 0.7228 - valid_reg: 0.000000 - valid_acc: 0.5767 - epoch_time: 141.4986 s\n",
      "Epoch 62\n",
      "[====================] 100/100: - running_loss: 0.5979 - running_reg: 0.000000 - running_acc: 0.6584 - lr: 0.00044 - epoch_loss: 0.5651 - epoch_reg: 0.000000 - epoch_acc: 0.6975 - valid_loss: 0.6632 - valid_reg: 0.000000 - valid_acc: 0.5867 - epoch_time: 144.6466 s\n",
      "Epoch 63\n",
      "[====================] 100/100: - running_loss: 0.6578 - running_reg: 0.000000 - running_acc: 0.6119 - lr: 0.00045 - epoch_loss: 0.6175 - epoch_reg: 0.000000 - epoch_acc: 0.6463 - valid_loss: 0.7012 - valid_reg: 0.000000 - valid_acc: 0.5804 - epoch_time: 146.2690 s\n",
      "Epoch 64\n",
      "[====================] 100/100: - running_loss: 0.6129 - running_reg: 0.000000 - running_acc: 0.6704 - lr: 0.00045 - epoch_loss: 0.6105 - epoch_reg: 0.000000 - epoch_acc: 0.6653 - valid_loss: 0.6550 - valid_reg: 0.000000 - valid_acc: 0.6066 - epoch_time: 141.4155 s\n",
      "Epoch 65\n",
      "[====================] 100/100: - running_loss: 0.5702 - running_reg: 0.000000 - running_acc: 0.7065 - lr: 0.00046 - epoch_loss: 0.5796 - epoch_reg: 0.000000 - epoch_acc: 0.7019 - valid_loss: 0.7644 - valid_reg: 0.000000 - valid_acc: 0.5873 - epoch_time: 140.5255 s\n",
      "Epoch 66\n",
      "[====================] 100/100: - running_loss: 0.5323 - running_reg: 0.000000 - running_acc: 0.7456 - lr: 0.00047 - epoch_loss: 0.5538 - epoch_reg: 0.000000 - epoch_acc: 0.7200 - valid_loss: 0.8167 - valid_reg: 0.000000 - valid_acc: 0.5765 - epoch_time: 141.3710 s\n",
      "Epoch 67\n",
      "[====================] 100/100: - running_loss: 0.5369 - running_reg: 0.000000 - running_acc: 0.7184 - lr: 0.00048 - epoch_loss: 0.5491 - epoch_reg: 0.000000 - epoch_acc: 0.7109 - valid_loss: 0.8284 - valid_reg: 0.000000 - valid_acc: 0.5815 - epoch_time: 141.6920 s\n",
      "Epoch 68\n",
      "[====================] 100/100: - running_loss: 0.5700 - running_reg: 0.000000 - running_acc: 0.7073 - lr: 0.00048 - epoch_loss: 0.5765 - epoch_reg: 0.000000 - epoch_acc: 0.6866 - valid_loss: 0.9893 - valid_reg: 0.000000 - valid_acc: 0.5802 - epoch_time: 141.3330 s\n",
      "Epoch 69\n",
      "[====================] 100/100: - running_loss: 0.5952 - running_reg: 0.000000 - running_acc: 0.6834 - lr: 0.00049 - epoch_loss: 0.5899 - epoch_reg: 0.000000 - epoch_acc: 0.6872 - valid_loss: 0.8507 - valid_reg: 0.000000 - valid_acc: 0.5744 - epoch_time: 141.5847 s\n",
      "Epoch 70\n",
      "[====================] 100/100: - running_loss: 0.6001 - running_reg: 0.000000 - running_acc: 0.6750 - lr: 0.00050 - epoch_loss: 0.5892 - epoch_reg: 0.000000 - epoch_acc: 0.6806 - valid_loss: 0.7437 - valid_reg: 0.000000 - valid_acc: 0.5845 - epoch_time: 141.8874 s\n",
      "Epoch 71\n",
      "[====================] 100/100: - running_loss: 0.5966 - running_reg: 0.000000 - running_acc: 0.6621 - lr: 0.00050 - epoch_loss: 0.5948 - epoch_reg: 0.000000 - epoch_acc: 0.6628 - valid_loss: 0.9416 - valid_reg: 0.000000 - valid_acc: 0.5896 - epoch_time: 141.7094 s\n",
      "Epoch 72\n",
      "[====================] 100/100: - running_loss: 0.5993 - running_reg: 0.000000 - running_acc: 0.6547 - lr: 0.00051 - epoch_loss: 0.5964 - epoch_reg: 0.000000 - epoch_acc: 0.6650 - valid_loss: 0.7477 - valid_reg: 0.000000 - valid_acc: 0.5993 - epoch_time: 141.2370 s\n",
      "Epoch 73\n",
      "[====================] 100/100: - running_loss: 0.5957 - running_reg: 0.000000 - running_acc: 0.6883 - lr: 0.00052 - epoch_loss: 0.5864 - epoch_reg: 0.000000 - epoch_acc: 0.6797 - valid_loss: 0.8195 - valid_reg: 0.000000 - valid_acc: 0.5571 - epoch_time: 140.8483 s\n",
      "Epoch 74\n",
      "[====================] 100/100: - running_loss: 0.6165 - running_reg: 0.000000 - running_acc: 0.6450 - lr: 0.00052 - epoch_loss: 0.6041 - epoch_reg: 0.000000 - epoch_acc: 0.6653 - valid_loss: 0.7444 - valid_reg: 0.000000 - valid_acc: 0.6097 - epoch_time: 140.5431 s\n",
      "Epoch 75\n",
      "[====================] 100/100: - running_loss: 0.6000 - running_reg: 0.000000 - running_acc: 0.6918 - lr: 0.00053 - epoch_loss: 0.6033 - epoch_reg: 0.000000 - epoch_acc: 0.6766 - valid_loss: 0.6756 - valid_reg: 0.000000 - valid_acc: 0.6076 - epoch_time: 141.5278 s\n",
      "Epoch 76\n",
      "[====================] 100/100: - running_loss: 0.6269 - running_reg: 0.000000 - running_acc: 0.6503 - lr: 0.00054 - epoch_loss: 0.6109 - epoch_reg: 0.000000 - epoch_acc: 0.6566 - valid_loss: 0.6224 - valid_reg: 0.000000 - valid_acc: 0.6432 - epoch_time: 141.5620 s\n",
      "Epoch 77\n",
      "[====================] 100/100: - running_loss: 0.5544 - running_reg: 0.000000 - running_acc: 0.6920 - lr: 0.00054 - epoch_loss: 0.5603 - epoch_reg: 0.000000 - epoch_acc: 0.6922 - valid_loss: 0.6747 - valid_reg: 0.000000 - valid_acc: 0.5881 - epoch_time: 140.6854 s\n",
      "Epoch 78\n",
      "[====================] 100/100: - running_loss: 0.5279 - running_reg: 0.000000 - running_acc: 0.7122 - lr: 0.00055 - epoch_loss: 0.5389 - epoch_reg: 0.000000 - epoch_acc: 0.7097 - valid_loss: 0.6892 - valid_reg: 0.000000 - valid_acc: 0.5939 - epoch_time: 140.5223 s\n",
      "Epoch 79\n",
      "[====================] 100/100: - running_loss: 0.5417 - running_reg: 0.000000 - running_acc: 0.7021 - lr: 0.00056 - epoch_loss: 0.5485 - epoch_reg: 0.000000 - epoch_acc: 0.7103 - valid_loss: 0.6860 - valid_reg: 0.000000 - valid_acc: 0.6080 - epoch_time: 140.9601 s\n",
      "Epoch 80\n",
      "[====================] 100/100: - running_loss: 0.5841 - running_reg: 0.000000 - running_acc: 0.6903 - lr: 0.00056 - epoch_loss: 0.5671 - epoch_reg: 0.000000 - epoch_acc: 0.6991 - valid_loss: 0.6816 - valid_reg: 0.000000 - valid_acc: 0.6178 - epoch_time: 141.4618 s\n",
      "Epoch 81\n",
      "[====================] 100/100: - running_loss: 0.5978 - running_reg: 0.000000 - running_acc: 0.6799 - lr: 0.00055 - epoch_loss: 0.5953 - epoch_reg: 0.000000 - epoch_acc: 0.6787 - valid_loss: 0.6269 - valid_reg: 0.000000 - valid_acc: 0.6396 - epoch_time: 141.0172 s\n",
      "Epoch 82\n",
      "[====================] 100/100: - running_loss: 0.6340 - running_reg: 0.000000 - running_acc: 0.6471 - lr: 0.00055 - epoch_loss: 0.6087 - epoch_reg: 0.000000 - epoch_acc: 0.6650 - valid_loss: 0.6629 - valid_reg: 0.000000 - valid_acc: 0.5876 - epoch_time: 140.7268 s\n",
      "Epoch 83\n",
      "[====================] 100/100: - running_loss: 0.6205 - running_reg: 0.000000 - running_acc: 0.6729 - lr: 0.00055 - epoch_loss: 0.6297 - epoch_reg: 0.000000 - epoch_acc: 0.6475 - valid_loss: 0.6219 - valid_reg: 0.000000 - valid_acc: 0.6411 - epoch_time: 140.7045 s\n",
      "Epoch 84\n",
      "[====================] 100/100: - running_loss: 0.6499 - running_reg: 0.000000 - running_acc: 0.6207 - lr: 0.00054 - epoch_loss: 0.6423 - epoch_reg: 0.000000 - epoch_acc: 0.6244 - valid_loss: 0.6315 - valid_reg: 0.000000 - valid_acc: 0.6367 - epoch_time: 140.9751 s\n",
      "Epoch 85\n",
      "[====================] 100/100: - running_loss: 0.6435 - running_reg: 0.000000 - running_acc: 0.6317 - lr: 0.00054 - epoch_loss: 0.6438 - epoch_reg: 0.000000 - epoch_acc: 0.6162 - valid_loss: 0.6768 - valid_reg: 0.000000 - valid_acc: 0.6014 - epoch_time: 141.5076 s\n",
      "Epoch 86\n",
      "[====================] 100/100: - running_loss: 0.6290 - running_reg: 0.000000 - running_acc: 0.6202 - lr: 0.00054 - epoch_loss: 0.6383 - epoch_reg: 0.000000 - epoch_acc: 0.6272 - valid_loss: 0.7376 - valid_reg: 0.000000 - valid_acc: 0.6018 - epoch_time: 142.1486 s\n",
      "Epoch 87\n",
      "[====================] 100/100: - running_loss: 0.6567 - running_reg: 0.000000 - running_acc: 0.5982 - lr: 0.00053 - epoch_loss: 0.6426 - epoch_reg: 0.000000 - epoch_acc: 0.6134 - valid_loss: 0.6596 - valid_reg: 0.000000 - valid_acc: 0.5804 - epoch_time: 141.3098 s\n",
      "Epoch 88\n",
      "[====================] 100/100: - running_loss: 0.6074 - running_reg: 0.000000 - running_acc: 0.6556 - lr: 0.00053 - epoch_loss: 0.6303 - epoch_reg: 0.000000 - epoch_acc: 0.6256 - valid_loss: 0.6455 - valid_reg: 0.000000 - valid_acc: 0.6139 - epoch_time: 141.0293 s\n",
      "Epoch 89\n",
      "[====================] 100/100: - running_loss: 0.6071 - running_reg: 0.000000 - running_acc: 0.6432 - lr: 0.00053 - epoch_loss: 0.6173 - epoch_reg: 0.000000 - epoch_acc: 0.6353 - valid_loss: 0.6416 - valid_reg: 0.000000 - valid_acc: 0.6147 - epoch_time: 140.7221 s\n",
      "Epoch 90\n",
      "[====================] 100/100: - running_loss: 0.5775 - running_reg: 0.000000 - running_acc: 0.6832 - lr: 0.00052 - epoch_loss: 0.5994 - epoch_reg: 0.000000 - epoch_acc: 0.6566 - valid_loss: 0.6731 - valid_reg: 0.000000 - valid_acc: 0.6175 - epoch_time: 140.1119 s\n",
      "Epoch 91\n",
      "[====================] 100/100: - running_loss: 0.6031 - running_reg: 0.000000 - running_acc: 0.6677 - lr: 0.00052 - epoch_loss: 0.6094 - epoch_reg: 0.000000 - epoch_acc: 0.6366 - valid_loss: 0.6530 - valid_reg: 0.000000 - valid_acc: 0.5706 - epoch_time: 143.6606 s\n",
      "Epoch 92\n",
      "[====================] 100/100: - running_loss: 0.5373 - running_reg: 0.000000 - running_acc: 0.7139 - lr: 0.00052 - epoch_loss: 0.5680 - epoch_reg: 0.000000 - epoch_acc: 0.6963 - valid_loss: 0.6670 - valid_reg: 0.000000 - valid_acc: 0.5770 - epoch_time: 141.1639 s\n",
      "Epoch 93\n",
      "[====================] 100/100: - running_loss: 0.5669 - running_reg: 0.000000 - running_acc: 0.6846 - lr: 0.00052 - epoch_loss: 0.5568 - epoch_reg: 0.000000 - epoch_acc: 0.7081 - valid_loss: 0.6514 - valid_reg: 0.000000 - valid_acc: 0.6346 - epoch_time: 141.2784 s\n",
      "Epoch 94\n",
      "[====================] 100/100: - running_loss: 0.5945 - running_reg: 0.000000 - running_acc: 0.6944 - lr: 0.00051 - epoch_loss: 0.5869 - epoch_reg: 0.000000 - epoch_acc: 0.6841 - valid_loss: 0.6619 - valid_reg: 0.000000 - valid_acc: 0.6094 - epoch_time: 142.0429 s\n",
      "Epoch 95\n",
      "[====================] 100/100: - running_loss: 0.5820 - running_reg: 0.000000 - running_acc: 0.6823 - lr: 0.00051 - epoch_loss: 0.6031 - epoch_reg: 0.000000 - epoch_acc: 0.6587 - valid_loss: 0.6466 - valid_reg: 0.000000 - valid_acc: 0.6367 - epoch_time: 141.8903 s\n",
      "Epoch 96\n",
      "[====================] 100/100: - running_loss: 0.6304 - running_reg: 0.000000 - running_acc: 0.6431 - lr: 0.00051 - epoch_loss: 0.6164 - epoch_reg: 0.000000 - epoch_acc: 0.6597 - valid_loss: 0.6610 - valid_reg: 0.000000 - valid_acc: 0.5992 - epoch_time: 141.4174 s\n",
      "Epoch 97\n",
      "[====================] 100/100: - running_loss: 0.6110 - running_reg: 0.000000 - running_acc: 0.6590 - lr: 0.00051 - epoch_loss: 0.6175 - epoch_reg: 0.000000 - epoch_acc: 0.6497 - valid_loss: 0.6431 - valid_reg: 0.000000 - valid_acc: 0.6116 - epoch_time: 141.4470 s\n",
      "Epoch 98\n",
      "[====================] 100/100: - running_loss: 0.6098 - running_reg: 0.000000 - running_acc: 0.6446 - lr: 0.00050 - epoch_loss: 0.6093 - epoch_reg: 0.000000 - epoch_acc: 0.6522 - valid_loss: 0.6438 - valid_reg: 0.000000 - valid_acc: 0.6204 - epoch_time: 140.5556 s\n",
      "Epoch 99\n",
      "[====================] 100/100: - running_loss: 0.6246 - running_reg: 0.000000 - running_acc: 0.6354 - lr: 0.00050 - epoch_loss: 0.6177 - epoch_reg: 0.000000 - epoch_acc: 0.6500 - valid_loss: 0.6240 - valid_reg: 0.000000 - valid_acc: 0.6385 - epoch_time: 140.9641 s\n",
      "Epoch 100\n",
      "[====================] 100/100: - running_loss: 0.6016 - running_reg: 0.000000 - running_acc: 0.6588 - lr: 0.00050 - epoch_loss: 0.6127 - epoch_reg: 0.000000 - epoch_acc: 0.6587 - valid_loss: 0.6283 - valid_reg: 0.000000 - valid_acc: 0.6558 - epoch_time: 140.5523 s\n",
      "Epoch 101\n",
      "[====================] 100/100: - running_loss: 0.5931 - running_reg: 0.000000 - running_acc: 0.6766 - lr: 0.00050 - epoch_loss: 0.6053 - epoch_reg: 0.000000 - epoch_acc: 0.6644 - valid_loss: 0.6511 - valid_reg: 0.000000 - valid_acc: 0.6309 - epoch_time: 140.9649 s\n",
      "Epoch 102\n",
      "[====================] 100/100: - running_loss: 0.5591 - running_reg: 0.000000 - running_acc: 0.6956 - lr: 0.00049 - epoch_loss: 0.5855 - epoch_reg: 0.000000 - epoch_acc: 0.6881 - valid_loss: 0.6550 - valid_reg: 0.000000 - valid_acc: 0.6251 - epoch_time: 141.2511 s\n",
      "Epoch 103\n",
      "[====================] 100/100: - running_loss: 0.5313 - running_reg: 0.000000 - running_acc: 0.7233 - lr: 0.00049 - epoch_loss: 0.5384 - epoch_reg: 0.000000 - epoch_acc: 0.7294 - valid_loss: 0.6231 - valid_reg: 0.000000 - valid_acc: 0.6305 - epoch_time: 141.5843 s\n",
      "Epoch 104\n",
      "[====================] 100/100: - running_loss: 0.4339 - running_reg: 0.000000 - running_acc: 0.8006 - lr: 0.00049 - epoch_loss: 0.4671 - epoch_reg: 0.000000 - epoch_acc: 0.7812 - valid_loss: 0.7457 - valid_reg: 0.000000 - valid_acc: 0.6062 - epoch_time: 141.7471 s\n",
      "Epoch 105\n",
      "[====================] 100/100: - running_loss: 0.4471 - running_reg: 0.000000 - running_acc: 0.7849 - lr: 0.00049 - epoch_loss: 0.4546 - epoch_reg: 0.000000 - epoch_acc: 0.7950 - valid_loss: 0.7376 - valid_reg: 0.000000 - valid_acc: 0.5960 - epoch_time: 146.5873 s\n",
      "Epoch 106\n",
      "[====================] 100/100: - running_loss: 0.4822 - running_reg: 0.000000 - running_acc: 0.7674 - lr: 0.00048 - epoch_loss: 0.4501 - epoch_reg: 0.000000 - epoch_acc: 0.7894 - valid_loss: 0.7330 - valid_reg: 0.000000 - valid_acc: 0.5872 - epoch_time: 144.7245 s\n",
      "Epoch 107\n",
      "[====================] 100/100: - running_loss: 0.5026 - running_reg: 0.000000 - running_acc: 0.7483 - lr: 0.00048 - epoch_loss: 0.4718 - epoch_reg: 0.000000 - epoch_acc: 0.7750 - valid_loss: 0.6635 - valid_reg: 0.000000 - valid_acc: 0.6134 - epoch_time: 141.3587 s\n",
      "Epoch 108\n",
      "[====================] 100/100: - running_loss: 0.5510 - running_reg: 0.000000 - running_acc: 0.6856 - lr: 0.00048 - epoch_loss: 0.5135 - epoch_reg: 0.000000 - epoch_acc: 0.7337 - valid_loss: 0.6761 - valid_reg: 0.000000 - valid_acc: 0.6272 - epoch_time: 141.4923 s\n",
      "Epoch 109\n",
      "[====================] 100/100: - running_loss: 0.5443 - running_reg: 0.000000 - running_acc: 0.7060 - lr: 0.00048 - epoch_loss: 0.5387 - epoch_reg: 0.000000 - epoch_acc: 0.7125 - valid_loss: 0.6653 - valid_reg: 0.000000 - valid_acc: 0.6238 - epoch_time: 140.7281 s\n",
      "Epoch 110\n",
      "[====================] 100/100: - running_loss: 0.5326 - running_reg: 0.000000 - running_acc: 0.7329 - lr: 0.00047 - epoch_loss: 0.5497 - epoch_reg: 0.000000 - epoch_acc: 0.7153 - valid_loss: 0.6942 - valid_reg: 0.000000 - valid_acc: 0.6282 - epoch_time: 141.5109 s\n",
      "Epoch 111\n",
      "[====================] 100/100: - running_loss: 0.5091 - running_reg: 0.000000 - running_acc: 0.7527 - lr: 0.00047 - epoch_loss: 0.5124 - epoch_reg: 0.000000 - epoch_acc: 0.7481 - valid_loss: 0.6851 - valid_reg: 0.000000 - valid_acc: 0.6080 - epoch_time: 140.7555 s\n",
      "Epoch 112\n",
      "[====================] 100/100: - running_loss: 0.5335 - running_reg: 0.000000 - running_acc: 0.7236 - lr: 0.00047 - epoch_loss: 0.5080 - epoch_reg: 0.000000 - epoch_acc: 0.7359 - valid_loss: 0.7453 - valid_reg: 0.000000 - valid_acc: 0.6177 - epoch_time: 141.5246 s\n",
      "Epoch 113\n",
      "[====================] 100/100: - running_loss: 0.4860 - running_reg: 0.000000 - running_acc: 0.7581 - lr: 0.00047 - epoch_loss: 0.5070 - epoch_reg: 0.000000 - epoch_acc: 0.7403 - valid_loss: 0.7642 - valid_reg: 0.000000 - valid_acc: 0.6264 - epoch_time: 141.2800 s\n",
      "Epoch 114\n",
      "[====================] 100/100: - running_loss: 0.5217 - running_reg: 0.000000 - running_acc: 0.7537 - lr: 0.00047 - epoch_loss: 0.5017 - epoch_reg: 0.000000 - epoch_acc: 0.7484 - valid_loss: 0.7903 - valid_reg: 0.000000 - valid_acc: 0.6042 - epoch_time: 141.1121 s\n",
      "Epoch 115\n",
      "[====================] 100/100: - running_loss: 0.5328 - running_reg: 0.000000 - running_acc: 0.7381 - lr: 0.00046 - epoch_loss: 0.5127 - epoch_reg: 0.000000 - epoch_acc: 0.7453 - valid_loss: 0.7287 - valid_reg: 0.000000 - valid_acc: 0.6248 - epoch_time: 141.6251 s\n",
      "Epoch 116\n",
      "[====================] 100/100: - running_loss: 0.5102 - running_reg: 0.000000 - running_acc: 0.7506 - lr: 0.00046 - epoch_loss: 0.5080 - epoch_reg: 0.000000 - epoch_acc: 0.7513 - valid_loss: 0.9066 - valid_reg: 0.000000 - valid_acc: 0.5986 - epoch_time: 140.9536 s\n",
      "Epoch 117\n",
      "[====================] 100/100: - running_loss: 0.5263 - running_reg: 0.000000 - running_acc: 0.7244 - lr: 0.00046 - epoch_loss: 0.5347 - epoch_reg: 0.000000 - epoch_acc: 0.7294 - valid_loss: 1.0299 - valid_reg: 0.000000 - valid_acc: 0.6107 - epoch_time: 141.4683 s\n",
      "Epoch 118\n",
      "[====================] 100/100: - running_loss: 0.5478 - running_reg: 0.000000 - running_acc: 0.7299 - lr: 0.00046 - epoch_loss: 0.5431 - epoch_reg: 0.000000 - epoch_acc: 0.7281 - valid_loss: 0.8060 - valid_reg: 0.000000 - valid_acc: 0.6229 - epoch_time: 141.1405 s\n",
      "Epoch 119\n",
      "[====================] 100/100: - running_loss: 0.5495 - running_reg: 0.000000 - running_acc: 0.6994 - lr: 0.00046 - epoch_loss: 0.5544 - epoch_reg: 0.000000 - epoch_acc: 0.7069 - valid_loss: 0.7355 - valid_reg: 0.000000 - valid_acc: 0.6241 - epoch_time: 141.0429 s\n",
      "Epoch 120\n",
      "[====================] 100/100: - running_loss: 0.6000 - running_reg: 0.000000 - running_acc: 0.6698 - lr: 0.00045 - epoch_loss: 0.5699 - epoch_reg: 0.000000 - epoch_acc: 0.6988 - valid_loss: 0.6431 - valid_reg: 0.000000 - valid_acc: 0.6408 - epoch_time: 140.5376 s\n",
      "Epoch 121\n",
      "[====================] 100/100: - running_loss: 0.5501 - running_reg: 0.000000 - running_acc: 0.7117 - lr: 0.00045 - epoch_loss: 0.5676 - epoch_reg: 0.000000 - epoch_acc: 0.6969 - valid_loss: 0.6187 - valid_reg: 0.000000 - valid_acc: 0.6486 - epoch_time: 141.0008 s\n",
      "Epoch 122\n",
      "[====================] 100/100: - running_loss: 0.5109 - running_reg: 0.000000 - running_acc: 0.7407 - lr: 0.00045 - epoch_loss: 0.5400 - epoch_reg: 0.000000 - epoch_acc: 0.7103 - valid_loss: 0.6103 - valid_reg: 0.000000 - valid_acc: 0.6701 - epoch_time: 140.5842 s\n",
      "Epoch 123\n",
      "[====================] 100/100: - running_loss: 0.5002 - running_reg: 0.000000 - running_acc: 0.7505 - lr: 0.00045 - epoch_loss: 0.5324 - epoch_reg: 0.000000 - epoch_acc: 0.7322 - valid_loss: 0.6793 - valid_reg: 0.000000 - valid_acc: 0.6257 - epoch_time: 140.8211 s\n",
      "Epoch 124\n",
      "[====================] 100/100: - running_loss: 0.4994 - running_reg: 0.000000 - running_acc: 0.7379 - lr: 0.00045 - epoch_loss: 0.4953 - epoch_reg: 0.000000 - epoch_acc: 0.7497 - valid_loss: 0.6281 - valid_reg: 0.000000 - valid_acc: 0.6545 - epoch_time: 140.5619 s\n",
      "Epoch 125\n",
      "[====================] 100/100: - running_loss: 0.5294 - running_reg: 0.000000 - running_acc: 0.7229 - lr: 0.00045 - epoch_loss: 0.5243 - epoch_reg: 0.000000 - epoch_acc: 0.7356 - valid_loss: 0.6605 - valid_reg: 0.000000 - valid_acc: 0.6205 - epoch_time: 140.7762 s\n",
      "Epoch 126\n",
      "[====================] 100/100: - running_loss: 0.5258 - running_reg: 0.000000 - running_acc: 0.7368 - lr: 0.00044 - epoch_loss: 0.5370 - epoch_reg: 0.000000 - epoch_acc: 0.7250 - valid_loss: 0.6094 - valid_reg: 0.000000 - valid_acc: 0.6726 - epoch_time: 141.1534 s\n",
      "Epoch 127\n",
      "[====================] 100/100: - running_loss: 0.5506 - running_reg: 0.000000 - running_acc: 0.7241 - lr: 0.00044 - epoch_loss: 0.5550 - epoch_reg: 0.000000 - epoch_acc: 0.7147 - valid_loss: 0.6514 - valid_reg: 0.000000 - valid_acc: 0.6306 - epoch_time: 141.2288 s\n",
      "Epoch 128\n",
      "[====================] 100/100: - running_loss: 0.6055 - running_reg: 0.000000 - running_acc: 0.6602 - lr: 0.00044 - epoch_loss: 0.5943 - epoch_reg: 0.000000 - epoch_acc: 0.6809 - valid_loss: 0.6102 - valid_reg: 0.000000 - valid_acc: 0.6508 - epoch_time: 141.3479 s\n",
      "Epoch 129\n",
      "[====================] 100/100: - running_loss: 0.6096 - running_reg: 0.000000 - running_acc: 0.6705 - lr: 0.00044 - epoch_loss: 0.6068 - epoch_reg: 0.000000 - epoch_acc: 0.6659 - valid_loss: 0.6262 - valid_reg: 0.000000 - valid_acc: 0.6505 - epoch_time: 141.1050 s\n",
      "Epoch 130\n",
      "[====================] 100/100: - running_loss: 0.6109 - running_reg: 0.000000 - running_acc: 0.6753 - lr: 0.00044 - epoch_loss: 0.6065 - epoch_reg: 0.000000 - epoch_acc: 0.6734 - valid_loss: 0.6188 - valid_reg: 0.000000 - valid_acc: 0.6516 - epoch_time: 141.0484 s\n",
      "Epoch 131\n",
      "[====================] 100/100: - running_loss: 0.6126 - running_reg: 0.000000 - running_acc: 0.6508 - lr: 0.00044 - epoch_loss: 0.5980 - epoch_reg: 0.000000 - epoch_acc: 0.6675 - valid_loss: 0.6541 - valid_reg: 0.000000 - valid_acc: 0.6489 - epoch_time: 141.0342 s\n",
      "Epoch 132\n",
      "[====================] 100/100: - running_loss: 0.6125 - running_reg: 0.000000 - running_acc: 0.6677 - lr: 0.00043 - epoch_loss: 0.5973 - epoch_reg: 0.000000 - epoch_acc: 0.6697 - valid_loss: 0.6483 - valid_reg: 0.000000 - valid_acc: 0.6448 - epoch_time: 141.3655 s\n",
      "Epoch 133\n",
      "[====================] 100/100: - running_loss: 0.6015 - running_reg: 0.000000 - running_acc: 0.6757 - lr: 0.00043 - epoch_loss: 0.6150 - epoch_reg: 0.000000 - epoch_acc: 0.6534 - valid_loss: 0.6111 - valid_reg: 0.000000 - valid_acc: 0.6570 - epoch_time: 141.9714 s\n",
      "Epoch 134\n",
      "[====================] 100/100: - running_loss: 0.6184 - running_reg: 0.000000 - running_acc: 0.6456 - lr: 0.00043 - epoch_loss: 0.5948 - epoch_reg: 0.000000 - epoch_acc: 0.6637 - valid_loss: 0.6217 - valid_reg: 0.000000 - valid_acc: 0.6447 - epoch_time: 140.9922 s\n",
      "Epoch 135\n",
      "[====================] 100/100: - running_loss: 0.5696 - running_reg: 0.000000 - running_acc: 0.6953 - lr: 0.00043 - epoch_loss: 0.5785 - epoch_reg: 0.000000 - epoch_acc: 0.6775 - valid_loss: 0.6102 - valid_reg: 0.000000 - valid_acc: 0.6514 - epoch_time: 141.0486 s\n",
      "Epoch 136\n",
      "[====================] 100/100: - running_loss: 0.5706 - running_reg: 0.000000 - running_acc: 0.6894 - lr: 0.00043 - epoch_loss: 0.5700 - epoch_reg: 0.000000 - epoch_acc: 0.6859 - valid_loss: 0.6253 - valid_reg: 0.000000 - valid_acc: 0.6389 - epoch_time: 141.7788 s\n",
      "Epoch 137\n",
      "[====================] 100/100: - running_loss: 0.5963 - running_reg: 0.000000 - running_acc: 0.6650 - lr: 0.00043 - epoch_loss: 0.5719 - epoch_reg: 0.000000 - epoch_acc: 0.6862 - valid_loss: 0.6442 - valid_reg: 0.000000 - valid_acc: 0.6277 - epoch_time: 144.7462 s\n",
      "Epoch 138\n",
      "[====================] 100/100: - running_loss: 0.5224 - running_reg: 0.000000 - running_acc: 0.7232 - lr: 0.00042 - epoch_loss: 0.5493 - epoch_reg: 0.000000 - epoch_acc: 0.7119 - valid_loss: 0.5993 - valid_reg: 0.000000 - valid_acc: 0.6703 - epoch_time: 141.8118 s\n",
      "Epoch 139\n",
      "[====================] 100/100: - running_loss: 0.5211 - running_reg: 0.000000 - running_acc: 0.7343 - lr: 0.00042 - epoch_loss: 0.5216 - epoch_reg: 0.000000 - epoch_acc: 0.7359 - valid_loss: 0.6875 - valid_reg: 0.000000 - valid_acc: 0.6264 - epoch_time: 142.1310 s\n",
      "Epoch 140\n",
      "[====================] 100/100: - running_loss: 0.5516 - running_reg: 0.000000 - running_acc: 0.7143 - lr: 0.00042 - epoch_loss: 0.5414 - epoch_reg: 0.000000 - epoch_acc: 0.7203 - valid_loss: 0.6267 - valid_reg: 0.000000 - valid_acc: 0.6505 - epoch_time: 141.1897 s\n",
      "Epoch 141\n",
      "[====================] 100/100: - running_loss: 0.5879 - running_reg: 0.000000 - running_acc: 0.6887 - lr: 0.00042 - epoch_loss: 0.5811 - epoch_reg: 0.000000 - epoch_acc: 0.6906 - valid_loss: 0.6087 - valid_reg: 0.000000 - valid_acc: 0.6623 - epoch_time: 141.7782 s\n",
      "Epoch 142\n",
      "[====================] 100/100: - running_loss: 0.5575 - running_reg: 0.000000 - running_acc: 0.7176 - lr: 0.00042 - epoch_loss: 0.5597 - epoch_reg: 0.000000 - epoch_acc: 0.7066 - valid_loss: 0.6539 - valid_reg: 0.000000 - valid_acc: 0.6329 - epoch_time: 141.2826 s\n",
      "Epoch 143\n",
      "[====================] 100/100: - running_loss: 0.5615 - running_reg: 0.000000 - running_acc: 0.7085 - lr: 0.00042 - epoch_loss: 0.5754 - epoch_reg: 0.000000 - epoch_acc: 0.6928 - valid_loss: 0.6782 - valid_reg: 0.000000 - valid_acc: 0.6311 - epoch_time: 141.2423 s\n",
      "Epoch 144\n",
      "[====================] 100/100: - running_loss: 0.5920 - running_reg: 0.000000 - running_acc: 0.6806 - lr: 0.00042 - epoch_loss: 0.5699 - epoch_reg: 0.000000 - epoch_acc: 0.6950 - valid_loss: 0.6125 - valid_reg: 0.000000 - valid_acc: 0.6607 - epoch_time: 141.1628 s\n",
      "Epoch 145\n",
      "[====================] 100/100: - running_loss: 0.5705 - running_reg: 0.000000 - running_acc: 0.6807 - lr: 0.00041 - epoch_loss: 0.5706 - epoch_reg: 0.000000 - epoch_acc: 0.6916 - valid_loss: 0.6202 - valid_reg: 0.000000 - valid_acc: 0.6498 - epoch_time: 140.9478 s\n",
      "Epoch 146\n",
      "[====================] 100/100: - running_loss: 0.5909 - running_reg: 0.000000 - running_acc: 0.6683 - lr: 0.00041 - epoch_loss: 0.5765 - epoch_reg: 0.000000 - epoch_acc: 0.6862 - valid_loss: 0.6060 - valid_reg: 0.000000 - valid_acc: 0.6671 - epoch_time: 141.2261 s\n",
      "Epoch 147\n",
      "[====================] 100/100: - running_loss: 0.5247 - running_reg: 0.000000 - running_acc: 0.7382 - lr: 0.00041 - epoch_loss: 0.5194 - epoch_reg: 0.000000 - epoch_acc: 0.7378 - valid_loss: 0.6193 - valid_reg: 0.000000 - valid_acc: 0.6643 - epoch_time: 145.9855 s\n",
      "Epoch 148\n",
      "[====================] 100/100: - running_loss: 0.4709 - running_reg: 0.000000 - running_acc: 0.7759 - lr: 0.00041 - epoch_loss: 0.4794 - epoch_reg: 0.000000 - epoch_acc: 0.7628 - valid_loss: 0.6189 - valid_reg: 0.000000 - valid_acc: 0.6645 - epoch_time: 146.8323 s\n",
      "Epoch 149\n",
      "[====================] 100/100: - running_loss: 0.3805 - running_reg: 0.000000 - running_acc: 0.8308 - lr: 0.00041 - epoch_loss: 0.4107 - epoch_reg: 0.000000 - epoch_acc: 0.8084 - valid_loss: 0.6829 - valid_reg: 0.000000 - valid_acc: 0.6618 - epoch_time: 141.7429 s\n",
      " - test_loss: 0.6202 - test_reg: 0.000000 - test_acc: 0.6581 - test_time: 96.9103 s\n",
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n",
      "Epoch 0\n",
      "[====================] 100/100: - running_loss: 1.0301 - running_reg: 0.000000 - running_acc: 0.5379 - lr: 0.00001 - epoch_loss: 1.6368 - epoch_reg: 0.000000 - epoch_acc: 0.5041 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 50.9912 s\n",
      "Epoch 1\n",
      "[====================] 100/100: - running_loss: 0.8741 - running_reg: 0.000000 - running_acc: 0.5482 - lr: 0.00001 - epoch_loss: 0.9772 - epoch_reg: 0.000000 - epoch_acc: 0.5266 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.3458 s\n",
      "Epoch 2\n",
      "[====================] 100/100: - running_loss: 0.8226 - running_reg: 0.000000 - running_acc: 0.5439 - lr: 0.00002 - epoch_loss: 0.8812 - epoch_reg: 0.000000 - epoch_acc: 0.5294 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1239 s\n",
      "Epoch 3\n",
      "[====================] 100/100: - running_loss: 0.8374 - running_reg: 0.000000 - running_acc: 0.4976 - lr: 0.00003 - epoch_loss: 0.8356 - epoch_reg: 0.000000 - epoch_acc: 0.5206 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.2435 s\n",
      "Epoch 4\n",
      "[====================] 100/100: - running_loss: 0.7883 - running_reg: 0.000000 - running_acc: 0.5100 - lr: 0.00003 - epoch_loss: 0.7967 - epoch_reg: 0.000000 - epoch_acc: 0.5053 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9607 s\n",
      "Epoch 5\n",
      "[====================] 100/100: - running_loss: 0.7872 - running_reg: 0.000000 - running_acc: 0.5134 - lr: 0.00004 - epoch_loss: 0.7896 - epoch_reg: 0.000000 - epoch_acc: 0.5031 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9414 s\n",
      "Epoch 6\n",
      "[====================] 100/100: - running_loss: 0.7762 - running_reg: 0.000000 - running_acc: 0.4957 - lr: 0.00005 - epoch_loss: 0.7798 - epoch_reg: 0.000000 - epoch_acc: 0.5025 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9067 s\n",
      "Epoch 7\n",
      "[====================] 100/100: - running_loss: 0.7793 - running_reg: 0.000000 - running_acc: 0.4790 - lr: 0.00006 - epoch_loss: 0.7748 - epoch_reg: 0.000000 - epoch_acc: 0.4925 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8748 s\n",
      "Epoch 8\n",
      "[====================] 100/100: - running_loss: 0.7474 - running_reg: 0.000000 - running_acc: 0.4966 - lr: 0.00006 - epoch_loss: 0.7525 - epoch_reg: 0.000000 - epoch_acc: 0.5034 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1234 s\n",
      "Epoch 9\n",
      "[====================] 100/100: - running_loss: 0.7510 - running_reg: 0.000000 - running_acc: 0.5279 - lr: 0.00007 - epoch_loss: 0.7535 - epoch_reg: 0.000000 - epoch_acc: 0.5050 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1857 s\n",
      "Epoch 10\n",
      "[====================] 100/100: - running_loss: 0.7295 - running_reg: 0.000000 - running_acc: 0.5066 - lr: 0.00008 - epoch_loss: 0.7336 - epoch_reg: 0.000000 - epoch_acc: 0.5156 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9742 s\n",
      "Epoch 11\n",
      "[====================] 100/100: - running_loss: 0.7467 - running_reg: 0.000000 - running_acc: 0.5084 - lr: 0.00008 - epoch_loss: 0.7327 - epoch_reg: 0.000000 - epoch_acc: 0.5275 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1590 s\n",
      "Epoch 12\n",
      "[====================] 100/100: - running_loss: 0.7474 - running_reg: 0.000000 - running_acc: 0.5326 - lr: 0.00009 - epoch_loss: 0.7315 - epoch_reg: 0.000000 - epoch_acc: 0.5256 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0478 s\n",
      "Epoch 13\n",
      "[====================] 100/100: - running_loss: 0.6732 - running_reg: 0.000000 - running_acc: 0.5991 - lr: 0.00010 - epoch_loss: 0.7016 - epoch_reg: 0.000000 - epoch_acc: 0.5672 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9906 s\n",
      "Epoch 14\n",
      "[====================] 100/100: - running_loss: 0.6959 - running_reg: 0.000000 - running_acc: 0.5683 - lr: 0.00010 - epoch_loss: 0.6977 - epoch_reg: 0.000000 - epoch_acc: 0.5741 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9081 s\n",
      "Epoch 15\n",
      "[====================] 100/100: - running_loss: 0.6981 - running_reg: 0.000000 - running_acc: 0.5862 - lr: 0.00011 - epoch_loss: 0.6816 - epoch_reg: 0.000000 - epoch_acc: 0.6028 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9634 s\n",
      "Epoch 16\n",
      "[====================] 100/100: - running_loss: 0.6821 - running_reg: 0.000000 - running_acc: 0.5756 - lr: 0.00012 - epoch_loss: 0.6915 - epoch_reg: 0.000000 - epoch_acc: 0.5653 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9887 s\n",
      "Epoch 17\n",
      "[====================] 100/100: - running_loss: 0.7000 - running_reg: 0.000000 - running_acc: 0.5320 - lr: 0.00013 - epoch_loss: 0.7154 - epoch_reg: 0.000000 - epoch_acc: 0.5425 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9522 s\n",
      "Epoch 18\n",
      "[====================] 100/100: - running_loss: 0.7000 - running_reg: 0.000000 - running_acc: 0.5597 - lr: 0.00013 - epoch_loss: 0.6999 - epoch_reg: 0.000000 - epoch_acc: 0.5531 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8910 s\n",
      "Epoch 19\n",
      "[====================] 100/100: - running_loss: 0.6816 - running_reg: 0.000000 - running_acc: 0.5854 - lr: 0.00014 - epoch_loss: 0.6858 - epoch_reg: 0.000000 - epoch_acc: 0.5700 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8332 s\n",
      "Epoch 20\n",
      "[====================] 100/100: - running_loss: 0.6567 - running_reg: 0.000000 - running_acc: 0.5719 - lr: 0.00015 - epoch_loss: 0.6819 - epoch_reg: 0.000000 - epoch_acc: 0.5584 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9536 s\n",
      "Epoch 21\n",
      "[====================] 100/100: - running_loss: 0.6674 - running_reg: 0.000000 - running_acc: 0.5610 - lr: 0.00015 - epoch_loss: 0.6712 - epoch_reg: 0.000000 - epoch_acc: 0.5666 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8907 s\n",
      "Epoch 22\n",
      "[====================] 100/100: - running_loss: 0.6589 - running_reg: 0.000000 - running_acc: 0.5889 - lr: 0.00016 - epoch_loss: 0.6697 - epoch_reg: 0.000000 - epoch_acc: 0.5628 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9011 s\n",
      "Epoch 23\n",
      "[====================] 100/100: - running_loss: 0.6764 - running_reg: 0.000000 - running_acc: 0.5739 - lr: 0.00017 - epoch_loss: 0.6587 - epoch_reg: 0.000000 - epoch_acc: 0.5894 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8216 s\n",
      "Epoch 24\n",
      "[====================] 100/100: - running_loss: 0.6731 - running_reg: 0.000000 - running_acc: 0.5507 - lr: 0.00017 - epoch_loss: 0.6715 - epoch_reg: 0.000000 - epoch_acc: 0.5781 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9453 s\n",
      "Epoch 25\n",
      "[====================] 100/100: - running_loss: 0.6879 - running_reg: 0.000000 - running_acc: 0.5661 - lr: 0.00018 - epoch_loss: 0.6710 - epoch_reg: 0.000000 - epoch_acc: 0.5847 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0234 s\n",
      "Epoch 26\n",
      "[====================] 100/100: - running_loss: 0.6820 - running_reg: 0.000000 - running_acc: 0.5811 - lr: 0.00019 - epoch_loss: 0.6742 - epoch_reg: 0.000000 - epoch_acc: 0.5831 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9723 s\n",
      "Epoch 27\n",
      "[====================] 100/100: - running_loss: 0.6459 - running_reg: 0.000000 - running_acc: 0.6324 - lr: 0.00020 - epoch_loss: 0.6729 - epoch_reg: 0.000000 - epoch_acc: 0.5944 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.1608 s\n",
      "Epoch 28\n",
      "[====================] 100/100: - running_loss: 0.6816 - running_reg: 0.000000 - running_acc: 0.5668 - lr: 0.00020 - epoch_loss: 0.6842 - epoch_reg: 0.000000 - epoch_acc: 0.5728 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9780 s\n",
      "Epoch 29\n",
      "[====================] 100/100: - running_loss: 0.6952 - running_reg: 0.000000 - running_acc: 0.5331 - lr: 0.00021 - epoch_loss: 0.6895 - epoch_reg: 0.000000 - epoch_acc: 0.5441 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9068 s\n",
      "Epoch 30\n",
      "[====================] 100/100: - running_loss: 0.6841 - running_reg: 0.000000 - running_acc: 0.5427 - lr: 0.00022 - epoch_loss: 0.6919 - epoch_reg: 0.000000 - epoch_acc: 0.5450 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0022 s\n",
      "Epoch 31\n",
      "[====================] 100/100: - running_loss: 0.6668 - running_reg: 0.000000 - running_acc: 0.6110 - lr: 0.00022 - epoch_loss: 0.6779 - epoch_reg: 0.000000 - epoch_acc: 0.5884 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8691 s\n",
      "Epoch 32\n",
      "[====================] 100/100: - running_loss: 0.6788 - running_reg: 0.000000 - running_acc: 0.5607 - lr: 0.00023 - epoch_loss: 0.6687 - epoch_reg: 0.000000 - epoch_acc: 0.5987 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9356 s\n",
      "Epoch 33\n",
      "[====================] 100/100: - running_loss: 0.6362 - running_reg: 0.000000 - running_acc: 0.6318 - lr: 0.00024 - epoch_loss: 0.6357 - epoch_reg: 0.000000 - epoch_acc: 0.6450 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8621 s\n",
      "Epoch 34\n",
      "[====================] 100/100: - running_loss: 0.6528 - running_reg: 0.000000 - running_acc: 0.6168 - lr: 0.00024 - epoch_loss: 0.6420 - epoch_reg: 0.000000 - epoch_acc: 0.6319 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7427 s\n",
      "Epoch 35\n",
      "[====================] 100/100: - running_loss: 0.6741 - running_reg: 0.000000 - running_acc: 0.5803 - lr: 0.00025 - epoch_loss: 0.6624 - epoch_reg: 0.000000 - epoch_acc: 0.6028 - valid_loss: 0.6835 - valid_reg: 0.000000 - valid_acc: 0.5547 - epoch_time: 142.2456 s\n",
      "Epoch 36\n",
      "[====================] 100/100: - running_loss: 0.6883 - running_reg: 0.000000 - running_acc: 0.5314 - lr: 0.00026 - epoch_loss: 0.6729 - epoch_reg: 0.000000 - epoch_acc: 0.5694 - valid_loss: 0.6876 - valid_reg: 0.000000 - valid_acc: 0.5488 - epoch_time: 141.2716 s\n",
      "Epoch 37\n",
      "[====================] 100/100: - running_loss: 0.6962 - running_reg: 0.000000 - running_acc: 0.5202 - lr: 0.00027 - epoch_loss: 0.6914 - epoch_reg: 0.000000 - epoch_acc: 0.5397 - valid_loss: 0.7069 - valid_reg: 0.000000 - valid_acc: 0.5143 - epoch_time: 141.4098 s\n",
      "Epoch 38\n",
      "[====================] 100/100: - running_loss: 0.6941 - running_reg: 0.000000 - running_acc: 0.5146 - lr: 0.00027 - epoch_loss: 0.6908 - epoch_reg: 0.000000 - epoch_acc: 0.5350 - valid_loss: 0.6836 - valid_reg: 0.000000 - valid_acc: 0.5579 - epoch_time: 141.0118 s\n",
      "Epoch 39\n",
      "[====================] 100/100: - running_loss: 0.6906 - running_reg: 0.000000 - running_acc: 0.5217 - lr: 0.00028 - epoch_loss: 0.6944 - epoch_reg: 0.000000 - epoch_acc: 0.5234 - valid_loss: 0.6907 - valid_reg: 0.000000 - valid_acc: 0.5186 - epoch_time: 140.9771 s\n",
      "Epoch 40\n",
      "[====================] 100/100: - running_loss: 0.6929 - running_reg: 0.000000 - running_acc: 0.5270 - lr: 0.00029 - epoch_loss: 0.6910 - epoch_reg: 0.000000 - epoch_acc: 0.5403 - valid_loss: 0.7120 - valid_reg: 0.000000 - valid_acc: 0.5023 - epoch_time: 140.8493 s\n",
      "Epoch 41\n",
      "[====================] 100/100: - running_loss: 0.6906 - running_reg: 0.000000 - running_acc: 0.5167 - lr: 0.00029 - epoch_loss: 0.6906 - epoch_reg: 0.000000 - epoch_acc: 0.5391 - valid_loss: 0.6807 - valid_reg: 0.000000 - valid_acc: 0.5567 - epoch_time: 140.9650 s\n",
      "Epoch 42\n",
      "[====================] 100/100: - running_loss: 0.6906 - running_reg: 0.000000 - running_acc: 0.5483 - lr: 0.00030 - epoch_loss: 0.6873 - epoch_reg: 0.000000 - epoch_acc: 0.5478 - valid_loss: 0.6986 - valid_reg: 0.000000 - valid_acc: 0.5082 - epoch_time: 140.2711 s\n",
      "Epoch 43\n",
      "[====================] 100/100: - running_loss: 0.6833 - running_reg: 0.000000 - running_acc: 0.5580 - lr: 0.00031 - epoch_loss: 0.6800 - epoch_reg: 0.000000 - epoch_acc: 0.5594 - valid_loss: 0.6812 - valid_reg: 0.000000 - valid_acc: 0.5545 - epoch_time: 141.1491 s\n",
      "Epoch 44\n",
      "[====================] 100/100: - running_loss: 0.6764 - running_reg: 0.000000 - running_acc: 0.5630 - lr: 0.00031 - epoch_loss: 0.6772 - epoch_reg: 0.000000 - epoch_acc: 0.5675 - valid_loss: 0.6679 - valid_reg: 0.000000 - valid_acc: 0.5895 - epoch_time: 140.5166 s\n",
      "Epoch 45\n",
      "[====================] 100/100: - running_loss: 0.6794 - running_reg: 0.000000 - running_acc: 0.5744 - lr: 0.00032 - epoch_loss: 0.6707 - epoch_reg: 0.000000 - epoch_acc: 0.5728 - valid_loss: 0.6779 - valid_reg: 0.000000 - valid_acc: 0.5463 - epoch_time: 143.2597 s\n",
      "Epoch 46\n",
      "[====================] 100/100: - running_loss: 0.6329 - running_reg: 0.000000 - running_acc: 0.6572 - lr: 0.00033 - epoch_loss: 0.6243 - epoch_reg: 0.000000 - epoch_acc: 0.6525 - valid_loss: 0.7093 - valid_reg: 0.000000 - valid_acc: 0.5679 - epoch_time: 141.0292 s\n",
      "Epoch 47\n",
      "[====================] 100/100: - running_loss: 0.6283 - running_reg: 0.000000 - running_acc: 0.6418 - lr: 0.00034 - epoch_loss: 0.6041 - epoch_reg: 0.000000 - epoch_acc: 0.6709 - valid_loss: 0.7043 - valid_reg: 0.000000 - valid_acc: 0.5264 - epoch_time: 140.9585 s\n",
      "Epoch 48\n",
      "[====================] 100/100: - running_loss: 0.6656 - running_reg: 0.000000 - running_acc: 0.5810 - lr: 0.00034 - epoch_loss: 0.6471 - epoch_reg: 0.000000 - epoch_acc: 0.6087 - valid_loss: 0.6693 - valid_reg: 0.000000 - valid_acc: 0.5770 - epoch_time: 141.5431 s\n",
      "Epoch 49\n",
      "[====================] 100/100: - running_loss: 0.6560 - running_reg: 0.000000 - running_acc: 0.5853 - lr: 0.00035 - epoch_loss: 0.6622 - epoch_reg: 0.000000 - epoch_acc: 0.5756 - valid_loss: 0.6780 - valid_reg: 0.000000 - valid_acc: 0.5662 - epoch_time: 140.9201 s\n",
      "Epoch 50\n",
      "[====================] 100/100: - running_loss: 0.6726 - running_reg: 0.000000 - running_acc: 0.5868 - lr: 0.00036 - epoch_loss: 0.6873 - epoch_reg: 0.000000 - epoch_acc: 0.5688 - valid_loss: 0.6709 - valid_reg: 0.000000 - valid_acc: 0.5829 - epoch_time: 141.4682 s\n",
      "Epoch 51\n",
      "[====================] 100/100: - running_loss: 0.6579 - running_reg: 0.000000 - running_acc: 0.5801 - lr: 0.00036 - epoch_loss: 0.6701 - epoch_reg: 0.000000 - epoch_acc: 0.5663 - valid_loss: 0.6584 - valid_reg: 0.000000 - valid_acc: 0.5959 - epoch_time: 141.9805 s\n",
      "Epoch 52\n",
      "[====================] 100/100: - running_loss: 0.6756 - running_reg: 0.000000 - running_acc: 0.5817 - lr: 0.00037 - epoch_loss: 0.6674 - epoch_reg: 0.000000 - epoch_acc: 0.5888 - valid_loss: 0.6794 - valid_reg: 0.000000 - valid_acc: 0.5589 - epoch_time: 141.4774 s\n",
      "Epoch 53\n",
      "[====================] 100/100: - running_loss: 0.6514 - running_reg: 0.000000 - running_acc: 0.5907 - lr: 0.00038 - epoch_loss: 0.6682 - epoch_reg: 0.000000 - epoch_acc: 0.5791 - valid_loss: 0.6692 - valid_reg: 0.000000 - valid_acc: 0.5858 - epoch_time: 141.6111 s\n",
      "Epoch 54\n",
      "[====================] 100/100: - running_loss: 0.6678 - running_reg: 0.000000 - running_acc: 0.5713 - lr: 0.00038 - epoch_loss: 0.6598 - epoch_reg: 0.000000 - epoch_acc: 0.5825 - valid_loss: 0.6673 - valid_reg: 0.000000 - valid_acc: 0.5836 - epoch_time: 142.0705 s\n",
      "Epoch 55\n",
      "[====================] 100/100: - running_loss: 0.6705 - running_reg: 0.000000 - running_acc: 0.5971 - lr: 0.00039 - epoch_loss: 0.6692 - epoch_reg: 0.000000 - epoch_acc: 0.5769 - valid_loss: 0.6576 - valid_reg: 0.000000 - valid_acc: 0.6000 - epoch_time: 141.6655 s\n",
      "Epoch 56\n",
      "[====================] 100/100: - running_loss: 0.6460 - running_reg: 0.000000 - running_acc: 0.6347 - lr: 0.00040 - epoch_loss: 0.6587 - epoch_reg: 0.000000 - epoch_acc: 0.6059 - valid_loss: 0.6631 - valid_reg: 0.000000 - valid_acc: 0.5845 - epoch_time: 141.7155 s\n",
      "Epoch 57\n",
      "[====================] 100/100: - running_loss: 0.6376 - running_reg: 0.000000 - running_acc: 0.6273 - lr: 0.00041 - epoch_loss: 0.6339 - epoch_reg: 0.000000 - epoch_acc: 0.6381 - valid_loss: 0.6979 - valid_reg: 0.000000 - valid_acc: 0.5672 - epoch_time: 141.5471 s\n",
      "Epoch 58\n",
      "[====================] 100/100: - running_loss: 0.5494 - running_reg: 0.000000 - running_acc: 0.7148 - lr: 0.00041 - epoch_loss: 0.5888 - epoch_reg: 0.000000 - epoch_acc: 0.6869 - valid_loss: 0.6678 - valid_reg: 0.000000 - valid_acc: 0.5855 - epoch_time: 141.7783 s\n",
      "Epoch 59\n",
      "[====================] 100/100: - running_loss: 0.5029 - running_reg: 0.000000 - running_acc: 0.7501 - lr: 0.00042 - epoch_loss: 0.5412 - epoch_reg: 0.000000 - epoch_acc: 0.7100 - valid_loss: 0.6869 - valid_reg: 0.000000 - valid_acc: 0.5866 - epoch_time: 141.5216 s\n",
      "Epoch 60\n",
      "[====================] 100/100: - running_loss: 0.5418 - running_reg: 0.000000 - running_acc: 0.7442 - lr: 0.00043 - epoch_loss: 0.5541 - epoch_reg: 0.000000 - epoch_acc: 0.7300 - valid_loss: 0.6630 - valid_reg: 0.000000 - valid_acc: 0.5780 - epoch_time: 141.2381 s\n",
      "Epoch 61\n",
      "[====================] 100/100: - running_loss: 0.5612 - running_reg: 0.000000 - running_acc: 0.7224 - lr: 0.00043 - epoch_loss: 0.5471 - epoch_reg: 0.000000 - epoch_acc: 0.7297 - valid_loss: 0.7230 - valid_reg: 0.000000 - valid_acc: 0.5854 - epoch_time: 140.8603 s\n",
      "Epoch 62\n",
      "[====================] 100/100: - running_loss: 0.5896 - running_reg: 0.000000 - running_acc: 0.6734 - lr: 0.00044 - epoch_loss: 0.5856 - epoch_reg: 0.000000 - epoch_acc: 0.6825 - valid_loss: 0.6836 - valid_reg: 0.000000 - valid_acc: 0.5935 - epoch_time: 140.0737 s\n",
      "Epoch 63\n",
      "[====================] 100/100: - running_loss: 0.6121 - running_reg: 0.000000 - running_acc: 0.6414 - lr: 0.00045 - epoch_loss: 0.5966 - epoch_reg: 0.000000 - epoch_acc: 0.6594 - valid_loss: 0.7135 - valid_reg: 0.000000 - valid_acc: 0.6008 - epoch_time: 145.6990 s\n",
      "Epoch 64\n",
      "[====================] 100/100: - running_loss: 0.6073 - running_reg: 0.000000 - running_acc: 0.6559 - lr: 0.00045 - epoch_loss: 0.6207 - epoch_reg: 0.000000 - epoch_acc: 0.6434 - valid_loss: 0.6942 - valid_reg: 0.000000 - valid_acc: 0.5929 - epoch_time: 145.4503 s\n",
      "Epoch 65\n",
      "[====================] 100/100: - running_loss: 0.5468 - running_reg: 0.000000 - running_acc: 0.7054 - lr: 0.00046 - epoch_loss: 0.5883 - epoch_reg: 0.000000 - epoch_acc: 0.6844 - valid_loss: 0.7810 - valid_reg: 0.000000 - valid_acc: 0.5782 - epoch_time: 140.5243 s\n",
      "Epoch 66\n",
      "[====================] 100/100: - running_loss: 0.5506 - running_reg: 0.000000 - running_acc: 0.7271 - lr: 0.00047 - epoch_loss: 0.5657 - epoch_reg: 0.000000 - epoch_acc: 0.7116 - valid_loss: 0.8043 - valid_reg: 0.000000 - valid_acc: 0.5937 - epoch_time: 140.7478 s\n",
      "Epoch 67\n",
      "[====================] 100/100: - running_loss: 0.5808 - running_reg: 0.000000 - running_acc: 0.6970 - lr: 0.00048 - epoch_loss: 0.5769 - epoch_reg: 0.000000 - epoch_acc: 0.7016 - valid_loss: 0.8058 - valid_reg: 0.000000 - valid_acc: 0.5730 - epoch_time: 140.9301 s\n",
      "Epoch 68\n",
      "[====================] 100/100: - running_loss: 0.5826 - running_reg: 0.000000 - running_acc: 0.6785 - lr: 0.00048 - epoch_loss: 0.5685 - epoch_reg: 0.000000 - epoch_acc: 0.7016 - valid_loss: 0.7325 - valid_reg: 0.000000 - valid_acc: 0.6153 - epoch_time: 141.1249 s\n",
      "Epoch 69\n",
      "[====================] 100/100: - running_loss: 0.5749 - running_reg: 0.000000 - running_acc: 0.6870 - lr: 0.00049 - epoch_loss: 0.5685 - epoch_reg: 0.000000 - epoch_acc: 0.6928 - valid_loss: 0.9623 - valid_reg: 0.000000 - valid_acc: 0.5932 - epoch_time: 141.3000 s\n",
      "Epoch 70\n",
      "[====================] 100/100: - running_loss: 0.5822 - running_reg: 0.000000 - running_acc: 0.6816 - lr: 0.00050 - epoch_loss: 0.5902 - epoch_reg: 0.000000 - epoch_acc: 0.6750 - valid_loss: 0.8589 - valid_reg: 0.000000 - valid_acc: 0.5834 - epoch_time: 140.8661 s\n",
      "Epoch 71\n",
      "[====================] 100/100: - running_loss: 0.5680 - running_reg: 0.000000 - running_acc: 0.6919 - lr: 0.00050 - epoch_loss: 0.5902 - epoch_reg: 0.000000 - epoch_acc: 0.6809 - valid_loss: 0.8376 - valid_reg: 0.000000 - valid_acc: 0.5908 - epoch_time: 140.5527 s\n",
      "Epoch 72\n",
      "[====================] 100/100: - running_loss: 0.6073 - running_reg: 0.000000 - running_acc: 0.6505 - lr: 0.00051 - epoch_loss: 0.6012 - epoch_reg: 0.000000 - epoch_acc: 0.6606 - valid_loss: 0.9754 - valid_reg: 0.000000 - valid_acc: 0.5443 - epoch_time: 140.8355 s\n",
      "Epoch 73\n",
      "[====================] 100/100: - running_loss: 0.5744 - running_reg: 0.000000 - running_acc: 0.6795 - lr: 0.00052 - epoch_loss: 0.5944 - epoch_reg: 0.000000 - epoch_acc: 0.6675 - valid_loss: 0.9746 - valid_reg: 0.000000 - valid_acc: 0.5615 - epoch_time: 139.8522 s\n",
      "Epoch 74\n",
      "[====================] 100/100: - running_loss: 0.6082 - running_reg: 0.000000 - running_acc: 0.6748 - lr: 0.00052 - epoch_loss: 0.6109 - epoch_reg: 0.000000 - epoch_acc: 0.6562 - valid_loss: 0.6968 - valid_reg: 0.000000 - valid_acc: 0.6065 - epoch_time: 140.7000 s\n",
      "Epoch 75\n",
      "[====================] 100/100: - running_loss: 0.6100 - running_reg: 0.000000 - running_acc: 0.6520 - lr: 0.00053 - epoch_loss: 0.6172 - epoch_reg: 0.000000 - epoch_acc: 0.6413 - valid_loss: 0.6266 - valid_reg: 0.000000 - valid_acc: 0.6315 - epoch_time: 140.3829 s\n",
      "Epoch 76\n",
      "[====================] 100/100: - running_loss: 0.5825 - running_reg: 0.000000 - running_acc: 0.6834 - lr: 0.00054 - epoch_loss: 0.5864 - epoch_reg: 0.000000 - epoch_acc: 0.6725 - valid_loss: 0.6344 - valid_reg: 0.000000 - valid_acc: 0.6268 - epoch_time: 140.5929 s\n",
      "Epoch 77\n",
      "[====================] 100/100: - running_loss: 0.5456 - running_reg: 0.000000 - running_acc: 0.7169 - lr: 0.00054 - epoch_loss: 0.5668 - epoch_reg: 0.000000 - epoch_acc: 0.6956 - valid_loss: 0.7343 - valid_reg: 0.000000 - valid_acc: 0.6016 - epoch_time: 141.7036 s\n",
      "Epoch 78\n",
      "[====================] 100/100: - running_loss: 0.5307 - running_reg: 0.000000 - running_acc: 0.7245 - lr: 0.00055 - epoch_loss: 0.5306 - epoch_reg: 0.000000 - epoch_acc: 0.7272 - valid_loss: 0.6659 - valid_reg: 0.000000 - valid_acc: 0.6232 - epoch_time: 140.2419 s\n",
      "Epoch 79\n",
      "[====================] 100/100: - running_loss: 0.5295 - running_reg: 0.000000 - running_acc: 0.7307 - lr: 0.00056 - epoch_loss: 0.5485 - epoch_reg: 0.000000 - epoch_acc: 0.7147 - valid_loss: 0.6999 - valid_reg: 0.000000 - valid_acc: 0.5945 - epoch_time: 140.3484 s\n",
      "Epoch 80\n",
      "[====================] 100/100: - running_loss: 0.5626 - running_reg: 0.000000 - running_acc: 0.7142 - lr: 0.00056 - epoch_loss: 0.5650 - epoch_reg: 0.000000 - epoch_acc: 0.7106 - valid_loss: 0.6407 - valid_reg: 0.000000 - valid_acc: 0.6453 - epoch_time: 140.4846 s\n",
      "Epoch 81\n",
      "[====================] 100/100: - running_loss: 0.6102 - running_reg: 0.000000 - running_acc: 0.6920 - lr: 0.00055 - epoch_loss: 0.6078 - epoch_reg: 0.000000 - epoch_acc: 0.6678 - valid_loss: 0.6671 - valid_reg: 0.000000 - valid_acc: 0.6019 - epoch_time: 140.0470 s\n",
      "Epoch 82\n",
      "[====================] 100/100: - running_loss: 0.6325 - running_reg: 0.000000 - running_acc: 0.6513 - lr: 0.00055 - epoch_loss: 0.6151 - epoch_reg: 0.000000 - epoch_acc: 0.6628 - valid_loss: 0.6278 - valid_reg: 0.000000 - valid_acc: 0.6332 - epoch_time: 142.2020 s\n",
      "Epoch 83\n",
      "[====================] 100/100: - running_loss: 0.6433 - running_reg: 0.000000 - running_acc: 0.6225 - lr: 0.00055 - epoch_loss: 0.6340 - epoch_reg: 0.000000 - epoch_acc: 0.6341 - valid_loss: 0.6289 - valid_reg: 0.000000 - valid_acc: 0.6368 - epoch_time: 140.3529 s\n",
      "Epoch 84\n",
      "[====================] 100/100: - running_loss: 0.6355 - running_reg: 0.000000 - running_acc: 0.6388 - lr: 0.00054 - epoch_loss: 0.6311 - epoch_reg: 0.000000 - epoch_acc: 0.6400 - valid_loss: 0.6972 - valid_reg: 0.000000 - valid_acc: 0.5946 - epoch_time: 140.0829 s\n",
      "Epoch 85\n",
      "[====================] 100/100: - running_loss: 0.6631 - running_reg: 0.000000 - running_acc: 0.5919 - lr: 0.00054 - epoch_loss: 0.6517 - epoch_reg: 0.000000 - epoch_acc: 0.6072 - valid_loss: 0.6419 - valid_reg: 0.000000 - valid_acc: 0.6252 - epoch_time: 140.7157 s\n",
      "Epoch 86\n",
      "[====================] 100/100: - running_loss: 0.6398 - running_reg: 0.000000 - running_acc: 0.6282 - lr: 0.00054 - epoch_loss: 0.6413 - epoch_reg: 0.000000 - epoch_acc: 0.6228 - valid_loss: 0.6740 - valid_reg: 0.000000 - valid_acc: 0.5932 - epoch_time: 139.7280 s\n",
      "Epoch 87\n",
      "[====================] 100/100: - running_loss: 0.6212 - running_reg: 0.000000 - running_acc: 0.6276 - lr: 0.00053 - epoch_loss: 0.6353 - epoch_reg: 0.000000 - epoch_acc: 0.6250 - valid_loss: 0.6264 - valid_reg: 0.000000 - valid_acc: 0.6368 - epoch_time: 140.3566 s\n",
      "Epoch 88\n",
      "[====================] 100/100: - running_loss: 0.5986 - running_reg: 0.000000 - running_acc: 0.6260 - lr: 0.00053 - epoch_loss: 0.6310 - epoch_reg: 0.000000 - epoch_acc: 0.6175 - valid_loss: 0.6510 - valid_reg: 0.000000 - valid_acc: 0.6266 - epoch_time: 139.5378 s\n",
      "Epoch 89\n",
      "[====================] 100/100: - running_loss: 0.5967 - running_reg: 0.000000 - running_acc: 0.6588 - lr: 0.00053 - epoch_loss: 0.6089 - epoch_reg: 0.000000 - epoch_acc: 0.6531 - valid_loss: 0.7211 - valid_reg: 0.000000 - valid_acc: 0.5869 - epoch_time: 139.3031 s\n",
      "Epoch 90\n",
      "[====================] 100/100: - running_loss: 0.5824 - running_reg: 0.000000 - running_acc: 0.6864 - lr: 0.00052 - epoch_loss: 0.6116 - epoch_reg: 0.000000 - epoch_acc: 0.6562 - valid_loss: 0.6561 - valid_reg: 0.000000 - valid_acc: 0.6186 - epoch_time: 139.8113 s\n",
      "Epoch 91\n",
      "[====================] 100/100: - running_loss: 0.5946 - running_reg: 0.000000 - running_acc: 0.6919 - lr: 0.00052 - epoch_loss: 0.5904 - epoch_reg: 0.000000 - epoch_acc: 0.6722 - valid_loss: 0.6583 - valid_reg: 0.000000 - valid_acc: 0.6078 - epoch_time: 147.8509 s\n",
      "Epoch 92\n",
      "[====================] 100/100: - running_loss: 0.5580 - running_reg: 0.000000 - running_acc: 0.7146 - lr: 0.00052 - epoch_loss: 0.5779 - epoch_reg: 0.000000 - epoch_acc: 0.6919 - valid_loss: 0.6476 - valid_reg: 0.000000 - valid_acc: 0.6069 - epoch_time: 140.7501 s\n",
      "Epoch 93\n",
      "[====================] 100/100: - running_loss: 0.5664 - running_reg: 0.000000 - running_acc: 0.6975 - lr: 0.00052 - epoch_loss: 0.5565 - epoch_reg: 0.000000 - epoch_acc: 0.7016 - valid_loss: 0.6318 - valid_reg: 0.000000 - valid_acc: 0.6294 - epoch_time: 140.8929 s\n",
      "Epoch 94\n",
      "[====================] 100/100: - running_loss: 0.5642 - running_reg: 0.000000 - running_acc: 0.7028 - lr: 0.00051 - epoch_loss: 0.5635 - epoch_reg: 0.000000 - epoch_acc: 0.6875 - valid_loss: 0.6387 - valid_reg: 0.000000 - valid_acc: 0.6375 - epoch_time: 140.6274 s\n",
      "Epoch 95\n",
      "[====================] 100/100: - running_loss: 0.5704 - running_reg: 0.000000 - running_acc: 0.6823 - lr: 0.00051 - epoch_loss: 0.5838 - epoch_reg: 0.000000 - epoch_acc: 0.6712 - valid_loss: 0.6734 - valid_reg: 0.000000 - valid_acc: 0.6160 - epoch_time: 140.2299 s\n",
      "Epoch 96\n",
      "[====================] 100/100: - running_loss: 0.6162 - running_reg: 0.000000 - running_acc: 0.6561 - lr: 0.00051 - epoch_loss: 0.5996 - epoch_reg: 0.000000 - epoch_acc: 0.6725 - valid_loss: 0.6460 - valid_reg: 0.000000 - valid_acc: 0.6223 - epoch_time: 140.3790 s\n",
      "Epoch 97\n",
      "[====================] 100/100: - running_loss: 0.6073 - running_reg: 0.000000 - running_acc: 0.6704 - lr: 0.00051 - epoch_loss: 0.6084 - epoch_reg: 0.000000 - epoch_acc: 0.6653 - valid_loss: 0.6286 - valid_reg: 0.000000 - valid_acc: 0.6377 - epoch_time: 140.0681 s\n",
      "Epoch 98\n",
      "[====================] 100/100: - running_loss: 0.6212 - running_reg: 0.000000 - running_acc: 0.6548 - lr: 0.00050 - epoch_loss: 0.6084 - epoch_reg: 0.000000 - epoch_acc: 0.6587 - valid_loss: 0.6188 - valid_reg: 0.000000 - valid_acc: 0.6503 - epoch_time: 141.3546 s\n",
      "Epoch 99\n",
      "[====================] 100/100: - running_loss: 0.6140 - running_reg: 0.000000 - running_acc: 0.6516 - lr: 0.00050 - epoch_loss: 0.6011 - epoch_reg: 0.000000 - epoch_acc: 0.6622 - valid_loss: 0.6289 - valid_reg: 0.000000 - valid_acc: 0.6306 - epoch_time: 140.7728 s\n",
      "Epoch 100\n",
      "[====================] 100/100: - running_loss: 0.6001 - running_reg: 0.000000 - running_acc: 0.6546 - lr: 0.00050 - epoch_loss: 0.5958 - epoch_reg: 0.000000 - epoch_acc: 0.6597 - valid_loss: 0.6266 - valid_reg: 0.000000 - valid_acc: 0.6379 - epoch_time: 140.4889 s\n",
      "Epoch 101\n",
      "[====================] 100/100: - running_loss: 0.5806 - running_reg: 0.000000 - running_acc: 0.6701 - lr: 0.00050 - epoch_loss: 0.5822 - epoch_reg: 0.000000 - epoch_acc: 0.6772 - valid_loss: 0.6121 - valid_reg: 0.000000 - valid_acc: 0.6574 - epoch_time: 140.4529 s\n",
      "Epoch 102\n",
      "[====================] 100/100: - running_loss: 0.6054 - running_reg: 0.000000 - running_acc: 0.6665 - lr: 0.00049 - epoch_loss: 0.5649 - epoch_reg: 0.000000 - epoch_acc: 0.6997 - valid_loss: 0.6728 - valid_reg: 0.000000 - valid_acc: 0.5843 - epoch_time: 139.8279 s\n",
      "Epoch 103\n",
      "[====================] 100/100: - running_loss: 0.5205 - running_reg: 0.000000 - running_acc: 0.7484 - lr: 0.00049 - epoch_loss: 0.5319 - epoch_reg: 0.000000 - epoch_acc: 0.7266 - valid_loss: 0.6419 - valid_reg: 0.000000 - valid_acc: 0.6394 - epoch_time: 140.9995 s\n",
      "Epoch 104\n",
      "[====================] 100/100: - running_loss: 0.4484 - running_reg: 0.000000 - running_acc: 0.7816 - lr: 0.00049 - epoch_loss: 0.4894 - epoch_reg: 0.000000 - epoch_acc: 0.7609 - valid_loss: 0.6775 - valid_reg: 0.000000 - valid_acc: 0.6106 - epoch_time: 140.3502 s\n",
      "Epoch 105\n",
      "[====================] 100/100: - running_loss: 0.4465 - running_reg: 0.000000 - running_acc: 0.7929 - lr: 0.00049 - epoch_loss: 0.4415 - epoch_reg: 0.000000 - epoch_acc: 0.7950 - valid_loss: 0.6874 - valid_reg: 0.000000 - valid_acc: 0.5944 - epoch_time: 141.7847 s\n",
      "Epoch 106\n",
      "[====================] 100/100: - running_loss: 0.4552 - running_reg: 0.000000 - running_acc: 0.8008 - lr: 0.00048 - epoch_loss: 0.4385 - epoch_reg: 0.000000 - epoch_acc: 0.7919 - valid_loss: 0.7182 - valid_reg: 0.000000 - valid_acc: 0.6133 - epoch_time: 144.9066 s\n",
      "Epoch 107\n",
      "[====================] 100/100: - running_loss: 0.5221 - running_reg: 0.000000 - running_acc: 0.7435 - lr: 0.00048 - epoch_loss: 0.4737 - epoch_reg: 0.000000 - epoch_acc: 0.7731 - valid_loss: 0.6607 - valid_reg: 0.000000 - valid_acc: 0.6285 - epoch_time: 142.2135 s\n",
      "Epoch 108\n",
      "[====================] 100/100: - running_loss: 0.5797 - running_reg: 0.000000 - running_acc: 0.6904 - lr: 0.00048 - epoch_loss: 0.5171 - epoch_reg: 0.000000 - epoch_acc: 0.7428 - valid_loss: 0.6251 - valid_reg: 0.000000 - valid_acc: 0.6457 - epoch_time: 140.0923 s\n",
      "Epoch 109\n",
      "[====================] 100/100: - running_loss: 0.5515 - running_reg: 0.000000 - running_acc: 0.7203 - lr: 0.00048 - epoch_loss: 0.5448 - epoch_reg: 0.000000 - epoch_acc: 0.7041 - valid_loss: 0.6093 - valid_reg: 0.000000 - valid_acc: 0.6591 - epoch_time: 140.7280 s\n",
      "Epoch 110\n",
      "[====================] 100/100: - running_loss: 0.5598 - running_reg: 0.000000 - running_acc: 0.7072 - lr: 0.00047 - epoch_loss: 0.5529 - epoch_reg: 0.000000 - epoch_acc: 0.7134 - valid_loss: 0.6590 - valid_reg: 0.000000 - valid_acc: 0.6312 - epoch_time: 139.8995 s\n",
      "Epoch 111\n",
      "[====================] 100/100: - running_loss: 0.4915 - running_reg: 0.000000 - running_acc: 0.7498 - lr: 0.00047 - epoch_loss: 0.5148 - epoch_reg: 0.000000 - epoch_acc: 0.7453 - valid_loss: 0.6795 - valid_reg: 0.000000 - valid_acc: 0.6310 - epoch_time: 140.9385 s\n",
      "Epoch 112\n",
      "[====================] 100/100: - running_loss: 0.4926 - running_reg: 0.000000 - running_acc: 0.7665 - lr: 0.00047 - epoch_loss: 0.4869 - epoch_reg: 0.000000 - epoch_acc: 0.7563 - valid_loss: 0.7044 - valid_reg: 0.000000 - valid_acc: 0.6391 - epoch_time: 140.1982 s\n",
      "Epoch 113\n",
      "[====================] 100/100: - running_loss: 0.4602 - running_reg: 0.000000 - running_acc: 0.7859 - lr: 0.00047 - epoch_loss: 0.4725 - epoch_reg: 0.000000 - epoch_acc: 0.7759 - valid_loss: 0.7637 - valid_reg: 0.000000 - valid_acc: 0.6403 - epoch_time: 140.4472 s\n",
      "Epoch 114\n",
      "[====================] 100/100: - running_loss: 0.4680 - running_reg: 0.000000 - running_acc: 0.7517 - lr: 0.00047 - epoch_loss: 0.4758 - epoch_reg: 0.000000 - epoch_acc: 0.7669 - valid_loss: 0.8634 - valid_reg: 0.000000 - valid_acc: 0.6231 - epoch_time: 140.6530 s\n",
      "Epoch 115\n",
      "[====================] 100/100: - running_loss: 0.4896 - running_reg: 0.000000 - running_acc: 0.7581 - lr: 0.00046 - epoch_loss: 0.4967 - epoch_reg: 0.000000 - epoch_acc: 0.7538 - valid_loss: 0.7535 - valid_reg: 0.000000 - valid_acc: 0.6384 - epoch_time: 140.4369 s\n",
      "Epoch 116\n",
      "[====================] 100/100: - running_loss: 0.4536 - running_reg: 0.000000 - running_acc: 0.7738 - lr: 0.00046 - epoch_loss: 0.5088 - epoch_reg: 0.000000 - epoch_acc: 0.7341 - valid_loss: 0.8461 - valid_reg: 0.000000 - valid_acc: 0.6299 - epoch_time: 140.3717 s\n",
      "Epoch 117\n",
      "[====================] 100/100: - running_loss: 0.5573 - running_reg: 0.000000 - running_acc: 0.7137 - lr: 0.00046 - epoch_loss: 0.5481 - epoch_reg: 0.000000 - epoch_acc: 0.7131 - valid_loss: 0.8106 - valid_reg: 0.000000 - valid_acc: 0.6205 - epoch_time: 140.5351 s\n",
      "Epoch 118\n",
      "[====================] 100/100: - running_loss: 0.5307 - running_reg: 0.000000 - running_acc: 0.7330 - lr: 0.00046 - epoch_loss: 0.5355 - epoch_reg: 0.000000 - epoch_acc: 0.7259 - valid_loss: 0.8512 - valid_reg: 0.000000 - valid_acc: 0.6145 - epoch_time: 140.1917 s\n",
      "Epoch 119\n",
      "[====================] 100/100: - running_loss: 0.5617 - running_reg: 0.000000 - running_acc: 0.7094 - lr: 0.00046 - epoch_loss: 0.5571 - epoch_reg: 0.000000 - epoch_acc: 0.7075 - valid_loss: 0.8426 - valid_reg: 0.000000 - valid_acc: 0.6212 - epoch_time: 139.9425 s\n",
      "Epoch 120\n",
      "[====================] 100/100: - running_loss: 0.5849 - running_reg: 0.000000 - running_acc: 0.6927 - lr: 0.00045 - epoch_loss: 0.5644 - epoch_reg: 0.000000 - epoch_acc: 0.6988 - valid_loss: 0.6330 - valid_reg: 0.000000 - valid_acc: 0.6431 - epoch_time: 139.9838 s\n",
      "Epoch 121\n",
      "[====================] 100/100: - running_loss: 0.5343 - running_reg: 0.000000 - running_acc: 0.7297 - lr: 0.00045 - epoch_loss: 0.5578 - epoch_reg: 0.000000 - epoch_acc: 0.7106 - valid_loss: 0.6164 - valid_reg: 0.000000 - valid_acc: 0.6569 - epoch_time: 139.4560 s\n",
      "Epoch 122\n",
      "[====================] 100/100: - running_loss: 0.5620 - running_reg: 0.000000 - running_acc: 0.7037 - lr: 0.00045 - epoch_loss: 0.5651 - epoch_reg: 0.000000 - epoch_acc: 0.7000 - valid_loss: 0.5893 - valid_reg: 0.000000 - valid_acc: 0.6859 - epoch_time: 141.2485 s\n",
      "Epoch 123\n",
      "[====================] 100/100: - running_loss: 0.5128 - running_reg: 0.000000 - running_acc: 0.7393 - lr: 0.00045 - epoch_loss: 0.5202 - epoch_reg: 0.000000 - epoch_acc: 0.7306 - valid_loss: 0.6099 - valid_reg: 0.000000 - valid_acc: 0.6681 - epoch_time: 139.5632 s\n",
      "Epoch 124\n",
      "[====================] 100/100: - running_loss: 0.5023 - running_reg: 0.000000 - running_acc: 0.7510 - lr: 0.00045 - epoch_loss: 0.4921 - epoch_reg: 0.000000 - epoch_acc: 0.7538 - valid_loss: 0.6173 - valid_reg: 0.000000 - valid_acc: 0.6680 - epoch_time: 140.2397 s\n",
      "Epoch 125\n",
      "[====================] 100/100: - running_loss: 0.5149 - running_reg: 0.000000 - running_acc: 0.7464 - lr: 0.00045 - epoch_loss: 0.4883 - epoch_reg: 0.000000 - epoch_acc: 0.7513 - valid_loss: 0.6167 - valid_reg: 0.000000 - valid_acc: 0.6702 - epoch_time: 140.1258 s\n",
      "Epoch 126\n",
      "[====================] 100/100: - running_loss: 0.5175 - running_reg: 0.000000 - running_acc: 0.7535 - lr: 0.00044 - epoch_loss: 0.5241 - epoch_reg: 0.000000 - epoch_acc: 0.7391 - valid_loss: 0.6147 - valid_reg: 0.000000 - valid_acc: 0.6574 - epoch_time: 139.5043 s\n",
      "Epoch 127\n",
      "[====================] 100/100: - running_loss: 0.5499 - running_reg: 0.000000 - running_acc: 0.7213 - lr: 0.00044 - epoch_loss: 0.5513 - epoch_reg: 0.000000 - epoch_acc: 0.7116 - valid_loss: 0.6117 - valid_reg: 0.000000 - valid_acc: 0.6624 - epoch_time: 140.2434 s\n",
      "Epoch 128\n",
      "[====================] 100/100: - running_loss: 0.5878 - running_reg: 0.000000 - running_acc: 0.6720 - lr: 0.00044 - epoch_loss: 0.5711 - epoch_reg: 0.000000 - epoch_acc: 0.6947 - valid_loss: 0.5967 - valid_reg: 0.000000 - valid_acc: 0.6733 - epoch_time: 139.5974 s\n",
      "Epoch 129\n",
      "[====================] 100/100: - running_loss: 0.5912 - running_reg: 0.000000 - running_acc: 0.6732 - lr: 0.00044 - epoch_loss: 0.5828 - epoch_reg: 0.000000 - epoch_acc: 0.6772 - valid_loss: 0.6381 - valid_reg: 0.000000 - valid_acc: 0.6463 - epoch_time: 139.5556 s\n",
      "Epoch 130\n",
      "[====================] 100/100: - running_loss: 0.5837 - running_reg: 0.000000 - running_acc: 0.6935 - lr: 0.00044 - epoch_loss: 0.5916 - epoch_reg: 0.000000 - epoch_acc: 0.6812 - valid_loss: 0.5997 - valid_reg: 0.000000 - valid_acc: 0.6764 - epoch_time: 139.6426 s\n",
      "Epoch 131\n",
      "[====================] 100/100: - running_loss: 0.5840 - running_reg: 0.000000 - running_acc: 0.6864 - lr: 0.00044 - epoch_loss: 0.5952 - epoch_reg: 0.000000 - epoch_acc: 0.6775 - valid_loss: 0.6714 - valid_reg: 0.000000 - valid_acc: 0.6491 - epoch_time: 139.5673 s\n",
      "Epoch 132\n",
      "[====================] 100/100: - running_loss: 0.5965 - running_reg: 0.000000 - running_acc: 0.6663 - lr: 0.00043 - epoch_loss: 0.5950 - epoch_reg: 0.000000 - epoch_acc: 0.6678 - valid_loss: 0.6896 - valid_reg: 0.000000 - valid_acc: 0.6099 - epoch_time: 139.9314 s\n",
      "Epoch 133\n",
      "[====================] 100/100: - running_loss: 0.6011 - running_reg: 0.000000 - running_acc: 0.6660 - lr: 0.00043 - epoch_loss: 0.6063 - epoch_reg: 0.000000 - epoch_acc: 0.6609 - valid_loss: 0.5903 - valid_reg: 0.000000 - valid_acc: 0.6810 - epoch_time: 140.0571 s\n",
      "Epoch 134\n",
      "[====================] 100/100: - running_loss: 0.5529 - running_reg: 0.000000 - running_acc: 0.6982 - lr: 0.00043 - epoch_loss: 0.5736 - epoch_reg: 0.000000 - epoch_acc: 0.6809 - valid_loss: 0.6086 - valid_reg: 0.000000 - valid_acc: 0.6577 - epoch_time: 139.3657 s\n",
      "Epoch 135\n",
      "[====================] 100/100: - running_loss: 0.5561 - running_reg: 0.000000 - running_acc: 0.7083 - lr: 0.00043 - epoch_loss: 0.5696 - epoch_reg: 0.000000 - epoch_acc: 0.6922 - valid_loss: 0.6201 - valid_reg: 0.000000 - valid_acc: 0.6525 - epoch_time: 140.0697 s\n",
      "Epoch 136\n",
      "[====================] 100/100: - running_loss: 0.5738 - running_reg: 0.000000 - running_acc: 0.6885 - lr: 0.00043 - epoch_loss: 0.5671 - epoch_reg: 0.000000 - epoch_acc: 0.6931 - valid_loss: 0.6136 - valid_reg: 0.000000 - valid_acc: 0.6494 - epoch_time: 139.4140 s\n",
      "Epoch 137\n",
      "[====================] 100/100: - running_loss: 0.5911 - running_reg: 0.000000 - running_acc: 0.6759 - lr: 0.00043 - epoch_loss: 0.5791 - epoch_reg: 0.000000 - epoch_acc: 0.6756 - valid_loss: 0.6149 - valid_reg: 0.000000 - valid_acc: 0.6493 - epoch_time: 171.9558 s\n",
      "Epoch 138\n",
      "[====================] 100/100: - running_loss: 0.5317 - running_reg: 0.000000 - running_acc: 0.7315 - lr: 0.00042 - epoch_loss: 0.5390 - epoch_reg: 0.000000 - epoch_acc: 0.7209 - valid_loss: 0.6410 - valid_reg: 0.000000 - valid_acc: 0.6446 - epoch_time: 139.6072 s\n",
      "Epoch 139\n",
      "[====================] 100/100: - running_loss: 0.5127 - running_reg: 0.000000 - running_acc: 0.7313 - lr: 0.00042 - epoch_loss: 0.5156 - epoch_reg: 0.000000 - epoch_acc: 0.7300 - valid_loss: 0.6071 - valid_reg: 0.000000 - valid_acc: 0.6662 - epoch_time: 139.7342 s\n",
      "Epoch 140\n",
      "[====================] 100/100: - running_loss: 0.5625 - running_reg: 0.000000 - running_acc: 0.7072 - lr: 0.00042 - epoch_loss: 0.5467 - epoch_reg: 0.000000 - epoch_acc: 0.7184 - valid_loss: 0.6207 - valid_reg: 0.000000 - valid_acc: 0.6549 - epoch_time: 139.4263 s\n",
      "Epoch 141\n",
      "[====================] 100/100: - running_loss: 0.5651 - running_reg: 0.000000 - running_acc: 0.7037 - lr: 0.00042 - epoch_loss: 0.5522 - epoch_reg: 0.000000 - epoch_acc: 0.7103 - valid_loss: 0.6129 - valid_reg: 0.000000 - valid_acc: 0.6608 - epoch_time: 139.8183 s\n",
      "Epoch 142\n",
      "[====================] 100/100: - running_loss: 0.5803 - running_reg: 0.000000 - running_acc: 0.6827 - lr: 0.00042 - epoch_loss: 0.5554 - epoch_reg: 0.000000 - epoch_acc: 0.7041 - valid_loss: 0.6083 - valid_reg: 0.000000 - valid_acc: 0.6601 - epoch_time: 139.2164 s\n",
      "Epoch 143\n",
      "[====================] 100/100: - running_loss: 0.5570 - running_reg: 0.000000 - running_acc: 0.7049 - lr: 0.00042 - epoch_loss: 0.5498 - epoch_reg: 0.000000 - epoch_acc: 0.7128 - valid_loss: 0.6185 - valid_reg: 0.000000 - valid_acc: 0.6511 - epoch_time: 139.5949 s\n",
      "Epoch 144\n",
      "[====================] 100/100: - running_loss: 0.5511 - running_reg: 0.000000 - running_acc: 0.6980 - lr: 0.00042 - epoch_loss: 0.5567 - epoch_reg: 0.000000 - epoch_acc: 0.7075 - valid_loss: 0.5996 - valid_reg: 0.000000 - valid_acc: 0.6620 - epoch_time: 139.5808 s\n",
      "Epoch 145\n",
      "[====================] 100/100: - running_loss: 0.5452 - running_reg: 0.000000 - running_acc: 0.7065 - lr: 0.00041 - epoch_loss: 0.5605 - epoch_reg: 0.000000 - epoch_acc: 0.7000 - valid_loss: 0.6066 - valid_reg: 0.000000 - valid_acc: 0.6625 - epoch_time: 140.5879 s\n",
      "Epoch 146\n",
      "[====================] 100/100: - running_loss: 0.5573 - running_reg: 0.000000 - running_acc: 0.6923 - lr: 0.00041 - epoch_loss: 0.5619 - epoch_reg: 0.000000 - epoch_acc: 0.6966 - valid_loss: 0.5989 - valid_reg: 0.000000 - valid_acc: 0.6676 - epoch_time: 140.9287 s\n",
      "Epoch 147\n",
      "[====================] 100/100: - running_loss: 0.5086 - running_reg: 0.000000 - running_acc: 0.7404 - lr: 0.00041 - epoch_loss: 0.5057 - epoch_reg: 0.000000 - epoch_acc: 0.7391 - valid_loss: 0.6233 - valid_reg: 0.000000 - valid_acc: 0.6589 - epoch_time: 140.6676 s\n",
      "Epoch 148\n",
      "[====================] 100/100: - running_loss: 0.4592 - running_reg: 0.000000 - running_acc: 0.7751 - lr: 0.00041 - epoch_loss: 0.4756 - epoch_reg: 0.000000 - epoch_acc: 0.7594 - valid_loss: 0.6911 - valid_reg: 0.000000 - valid_acc: 0.6101 - epoch_time: 145.3710 s\n",
      "Epoch 149\n",
      "[====================] 100/100: - running_loss: 0.4134 - running_reg: 0.000000 - running_acc: 0.8007 - lr: 0.00041 - epoch_loss: 0.4177 - epoch_reg: 0.000000 - epoch_acc: 0.8000 - valid_loss: 0.6822 - valid_reg: 0.000000 - valid_acc: 0.5900 - epoch_time: 144.6507 s\n",
      " - test_loss: 0.5969 - test_reg: 0.000000 - test_acc: 0.6718 - test_time: 95.3879 s\n",
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n",
      "Epoch 0\n",
      "[====================] 100/100: - running_loss: 1.0700 - running_reg: 0.000000 - running_acc: 0.5478 - lr: 0.00001 - epoch_loss: 1.2196 - epoch_reg: 0.000000 - epoch_acc: 0.5272 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 50.4160 s\n",
      "Epoch 1\n",
      "[====================] 100/100: - running_loss: 0.9424 - running_reg: 0.000000 - running_acc: 0.5158 - lr: 0.00001 - epoch_loss: 1.0136 - epoch_reg: 0.000000 - epoch_acc: 0.5184 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9403 s\n",
      "Epoch 2\n",
      "[====================] 100/100: - running_loss: 0.8604 - running_reg: 0.000000 - running_acc: 0.5143 - lr: 0.00002 - epoch_loss: 0.8799 - epoch_reg: 0.000000 - epoch_acc: 0.5312 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9762 s\n",
      "Epoch 3\n",
      "[====================] 100/100: - running_loss: 0.8093 - running_reg: 0.000000 - running_acc: 0.5499 - lr: 0.00003 - epoch_loss: 0.8414 - epoch_reg: 0.000000 - epoch_acc: 0.5203 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8983 s\n",
      "Epoch 4\n",
      "[====================] 100/100: - running_loss: 0.7703 - running_reg: 0.000000 - running_acc: 0.5369 - lr: 0.00003 - epoch_loss: 0.8063 - epoch_reg: 0.000000 - epoch_acc: 0.5181 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6640 s\n",
      "Epoch 5\n",
      "[====================] 100/100: - running_loss: 0.7751 - running_reg: 0.000000 - running_acc: 0.5199 - lr: 0.00004 - epoch_loss: 0.7857 - epoch_reg: 0.000000 - epoch_acc: 0.5181 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8867 s\n",
      "Epoch 6\n",
      "[====================] 100/100: - running_loss: 0.7529 - running_reg: 0.000000 - running_acc: 0.5195 - lr: 0.00005 - epoch_loss: 0.7745 - epoch_reg: 0.000000 - epoch_acc: 0.4963 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7338 s\n",
      "Epoch 7\n",
      "[====================] 100/100: - running_loss: 0.7438 - running_reg: 0.000000 - running_acc: 0.5247 - lr: 0.00006 - epoch_loss: 0.7650 - epoch_reg: 0.000000 - epoch_acc: 0.5094 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9714 s\n",
      "Epoch 8\n",
      "[====================] 100/100: - running_loss: 0.7766 - running_reg: 0.000000 - running_acc: 0.4904 - lr: 0.00006 - epoch_loss: 0.7601 - epoch_reg: 0.000000 - epoch_acc: 0.5150 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0347 s\n",
      "Epoch 9\n",
      "[====================] 100/100: - running_loss: 0.7786 - running_reg: 0.000000 - running_acc: 0.4927 - lr: 0.00007 - epoch_loss: 0.7664 - epoch_reg: 0.000000 - epoch_acc: 0.4966 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9972 s\n",
      "Epoch 10\n",
      "[====================] 100/100: - running_loss: 0.7531 - running_reg: 0.000000 - running_acc: 0.4681 - lr: 0.00008 - epoch_loss: 0.7545 - epoch_reg: 0.000000 - epoch_acc: 0.4953 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9729 s\n",
      "Epoch 11\n",
      "[====================] 100/100: - running_loss: 0.7051 - running_reg: 0.000000 - running_acc: 0.5441 - lr: 0.00008 - epoch_loss: 0.7212 - epoch_reg: 0.000000 - epoch_acc: 0.5322 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9765 s\n",
      "Epoch 12\n",
      "[====================] 100/100: - running_loss: 0.7278 - running_reg: 0.000000 - running_acc: 0.5212 - lr: 0.00009 - epoch_loss: 0.7288 - epoch_reg: 0.000000 - epoch_acc: 0.5344 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9928 s\n",
      "Epoch 13\n",
      "[====================] 100/100: - running_loss: 0.6978 - running_reg: 0.000000 - running_acc: 0.5983 - lr: 0.00010 - epoch_loss: 0.6993 - epoch_reg: 0.000000 - epoch_acc: 0.5675 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9003 s\n",
      "Epoch 14\n",
      "[====================] 100/100: - running_loss: 0.6966 - running_reg: 0.000000 - running_acc: 0.5703 - lr: 0.00010 - epoch_loss: 0.7056 - epoch_reg: 0.000000 - epoch_acc: 0.5688 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7679 s\n",
      "Epoch 15\n",
      "[====================] 100/100: - running_loss: 0.6921 - running_reg: 0.000000 - running_acc: 0.5820 - lr: 0.00011 - epoch_loss: 0.7010 - epoch_reg: 0.000000 - epoch_acc: 0.5697 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8579 s\n",
      "Epoch 16\n",
      "[====================] 100/100: - running_loss: 0.6913 - running_reg: 0.000000 - running_acc: 0.5737 - lr: 0.00012 - epoch_loss: 0.6923 - epoch_reg: 0.000000 - epoch_acc: 0.5691 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9224 s\n",
      "Epoch 17\n",
      "[====================] 100/100: - running_loss: 0.7138 - running_reg: 0.000000 - running_acc: 0.5022 - lr: 0.00013 - epoch_loss: 0.7072 - epoch_reg: 0.000000 - epoch_acc: 0.5366 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9028 s\n",
      "Epoch 18\n",
      "[====================] 100/100: - running_loss: 0.7055 - running_reg: 0.000000 - running_acc: 0.5553 - lr: 0.00013 - epoch_loss: 0.6984 - epoch_reg: 0.000000 - epoch_acc: 0.5534 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9790 s\n",
      "Epoch 19\n",
      "[====================] 100/100: - running_loss: 0.6813 - running_reg: 0.000000 - running_acc: 0.5662 - lr: 0.00014 - epoch_loss: 0.6950 - epoch_reg: 0.000000 - epoch_acc: 0.5522 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9718 s\n",
      "Epoch 20\n",
      "[====================] 100/100: - running_loss: 0.6801 - running_reg: 0.000000 - running_acc: 0.5466 - lr: 0.00015 - epoch_loss: 0.6930 - epoch_reg: 0.000000 - epoch_acc: 0.5422 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8921 s\n",
      "Epoch 21\n",
      "[====================] 100/100: - running_loss: 0.6768 - running_reg: 0.000000 - running_acc: 0.5479 - lr: 0.00015 - epoch_loss: 0.6802 - epoch_reg: 0.000000 - epoch_acc: 0.5459 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0296 s\n",
      "Epoch 22\n",
      "[====================] 100/100: - running_loss: 0.7042 - running_reg: 0.000000 - running_acc: 0.5421 - lr: 0.00016 - epoch_loss: 0.6857 - epoch_reg: 0.000000 - epoch_acc: 0.5453 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8607 s\n",
      "Epoch 23\n",
      "[====================] 100/100: - running_loss: 0.6815 - running_reg: 0.000000 - running_acc: 0.5770 - lr: 0.00017 - epoch_loss: 0.6706 - epoch_reg: 0.000000 - epoch_acc: 0.5709 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8590 s\n",
      "Epoch 24\n",
      "[====================] 100/100: - running_loss: 0.6927 - running_reg: 0.000000 - running_acc: 0.5561 - lr: 0.00017 - epoch_loss: 0.6762 - epoch_reg: 0.000000 - epoch_acc: 0.5703 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 43.0364 s\n",
      "Epoch 25\n",
      "[====================] 100/100: - running_loss: 0.6711 - running_reg: 0.000000 - running_acc: 0.5712 - lr: 0.00018 - epoch_loss: 0.6799 - epoch_reg: 0.000000 - epoch_acc: 0.5825 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8088 s\n",
      "Epoch 26\n",
      "[====================] 100/100: - running_loss: 0.6609 - running_reg: 0.000000 - running_acc: 0.6152 - lr: 0.00019 - epoch_loss: 0.6745 - epoch_reg: 0.000000 - epoch_acc: 0.5894 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5941 s\n",
      "Epoch 27\n",
      "[====================] 100/100: - running_loss: 0.6554 - running_reg: 0.000000 - running_acc: 0.5983 - lr: 0.00020 - epoch_loss: 0.6604 - epoch_reg: 0.000000 - epoch_acc: 0.6025 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4408 s\n",
      "Epoch 28\n",
      "[====================] 100/100: - running_loss: 0.6933 - running_reg: 0.000000 - running_acc: 0.5713 - lr: 0.00020 - epoch_loss: 0.6884 - epoch_reg: 0.000000 - epoch_acc: 0.5725 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.3830 s\n",
      "Epoch 29\n",
      "[====================] 100/100: - running_loss: 0.7063 - running_reg: 0.000000 - running_acc: 0.4915 - lr: 0.00021 - epoch_loss: 0.6971 - epoch_reg: 0.000000 - epoch_acc: 0.5256 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.3308 s\n",
      "Epoch 30\n",
      "[====================] 100/100: - running_loss: 0.6879 - running_reg: 0.000000 - running_acc: 0.5532 - lr: 0.00022 - epoch_loss: 0.6914 - epoch_reg: 0.000000 - epoch_acc: 0.5487 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4343 s\n",
      "Epoch 31\n",
      "[====================] 100/100: - running_loss: 0.6595 - running_reg: 0.000000 - running_acc: 0.5963 - lr: 0.00022 - epoch_loss: 0.6791 - epoch_reg: 0.000000 - epoch_acc: 0.5663 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.3991 s\n",
      "Epoch 32\n",
      "[====================] 100/100: - running_loss: 0.6454 - running_reg: 0.000000 - running_acc: 0.6390 - lr: 0.00023 - epoch_loss: 0.6503 - epoch_reg: 0.000000 - epoch_acc: 0.6356 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4809 s\n",
      "Epoch 33\n",
      "[====================] 100/100: - running_loss: 0.6182 - running_reg: 0.000000 - running_acc: 0.6615 - lr: 0.00024 - epoch_loss: 0.6405 - epoch_reg: 0.000000 - epoch_acc: 0.6494 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.2128 s\n",
      "Epoch 34\n",
      "[====================] 100/100: - running_loss: 0.6830 - running_reg: 0.000000 - running_acc: 0.5833 - lr: 0.00024 - epoch_loss: 0.6428 - epoch_reg: 0.000000 - epoch_acc: 0.6391 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4344 s\n",
      "Epoch 35\n",
      "[====================] 100/100: - running_loss: 0.6851 - running_reg: 0.000000 - running_acc: 0.5715 - lr: 0.00025 - epoch_loss: 0.6689 - epoch_reg: 0.000000 - epoch_acc: 0.5934 - valid_loss: 0.6816 - valid_reg: 0.000000 - valid_acc: 0.5585 - epoch_time: 138.7961 s\n",
      "Epoch 36\n",
      "[====================] 100/100: - running_loss: 0.6760 - running_reg: 0.000000 - running_acc: 0.5681 - lr: 0.00026 - epoch_loss: 0.6715 - epoch_reg: 0.000000 - epoch_acc: 0.5966 - valid_loss: 0.7062 - valid_reg: 0.000000 - valid_acc: 0.5385 - epoch_time: 138.5004 s\n",
      "Epoch 37\n",
      "[====================] 100/100: - running_loss: 0.6915 - running_reg: 0.000000 - running_acc: 0.5168 - lr: 0.00027 - epoch_loss: 0.6874 - epoch_reg: 0.000000 - epoch_acc: 0.5462 - valid_loss: 0.6838 - valid_reg: 0.000000 - valid_acc: 0.5563 - epoch_time: 138.5537 s\n",
      "Epoch 38\n",
      "[====================] 100/100: - running_loss: 0.7042 - running_reg: 0.000000 - running_acc: 0.5282 - lr: 0.00027 - epoch_loss: 0.6910 - epoch_reg: 0.000000 - epoch_acc: 0.5500 - valid_loss: 0.7011 - valid_reg: 0.000000 - valid_acc: 0.5123 - epoch_time: 138.2099 s\n",
      "Epoch 39\n",
      "[====================] 100/100: - running_loss: 0.6939 - running_reg: 0.000000 - running_acc: 0.5196 - lr: 0.00028 - epoch_loss: 0.6954 - epoch_reg: 0.000000 - epoch_acc: 0.5184 - valid_loss: 0.7000 - valid_reg: 0.000000 - valid_acc: 0.4997 - epoch_time: 137.7099 s\n",
      "Epoch 40\n",
      "[====================] 100/100: - running_loss: 0.6864 - running_reg: 0.000000 - running_acc: 0.5430 - lr: 0.00029 - epoch_loss: 0.6866 - epoch_reg: 0.000000 - epoch_acc: 0.5494 - valid_loss: 0.7092 - valid_reg: 0.000000 - valid_acc: 0.5050 - epoch_time: 138.6528 s\n",
      "Epoch 41\n",
      "[====================] 100/100: - running_loss: 0.6846 - running_reg: 0.000000 - running_acc: 0.5489 - lr: 0.00029 - epoch_loss: 0.6875 - epoch_reg: 0.000000 - epoch_acc: 0.5434 - valid_loss: 0.6885 - valid_reg: 0.000000 - valid_acc: 0.5396 - epoch_time: 138.5586 s\n",
      "Epoch 42\n",
      "[====================] 100/100: - running_loss: 0.6928 - running_reg: 0.000000 - running_acc: 0.5397 - lr: 0.00030 - epoch_loss: 0.6989 - epoch_reg: 0.000000 - epoch_acc: 0.5163 - valid_loss: 0.6817 - valid_reg: 0.000000 - valid_acc: 0.5647 - epoch_time: 138.7012 s\n",
      "Epoch 43\n",
      "[====================] 100/100: - running_loss: 0.6835 - running_reg: 0.000000 - running_acc: 0.5463 - lr: 0.00031 - epoch_loss: 0.6893 - epoch_reg: 0.000000 - epoch_acc: 0.5359 - valid_loss: 0.6802 - valid_reg: 0.000000 - valid_acc: 0.5581 - epoch_time: 137.8163 s\n",
      "Epoch 44\n",
      "[====================] 100/100: - running_loss: 0.6794 - running_reg: 0.000000 - running_acc: 0.5604 - lr: 0.00031 - epoch_loss: 0.6816 - epoch_reg: 0.000000 - epoch_acc: 0.5472 - valid_loss: 0.7134 - valid_reg: 0.000000 - valid_acc: 0.5177 - epoch_time: 137.2746 s\n",
      "Epoch 45\n",
      "[====================] 100/100: - running_loss: 0.6722 - running_reg: 0.000000 - running_acc: 0.5751 - lr: 0.00032 - epoch_loss: 0.6844 - epoch_reg: 0.000000 - epoch_acc: 0.5444 - valid_loss: 0.6898 - valid_reg: 0.000000 - valid_acc: 0.5446 - epoch_time: 140.8711 s\n",
      "Epoch 46\n",
      "[====================] 100/100: - running_loss: 0.6076 - running_reg: 0.000000 - running_acc: 0.6788 - lr: 0.00033 - epoch_loss: 0.6317 - epoch_reg: 0.000000 - epoch_acc: 0.6438 - valid_loss: 0.6908 - valid_reg: 0.000000 - valid_acc: 0.5520 - epoch_time: 137.6985 s\n",
      "Epoch 47\n",
      "[====================] 100/100: - running_loss: 0.6390 - running_reg: 0.000000 - running_acc: 0.6408 - lr: 0.00034 - epoch_loss: 0.6239 - epoch_reg: 0.000000 - epoch_acc: 0.6522 - valid_loss: 0.7334 - valid_reg: 0.000000 - valid_acc: 0.5156 - epoch_time: 138.2383 s\n",
      "Epoch 48\n",
      "[====================] 100/100: - running_loss: 0.6501 - running_reg: 0.000000 - running_acc: 0.6065 - lr: 0.00034 - epoch_loss: 0.6373 - epoch_reg: 0.000000 - epoch_acc: 0.6153 - valid_loss: 0.6812 - valid_reg: 0.000000 - valid_acc: 0.5757 - epoch_time: 138.1100 s\n",
      "Epoch 49\n",
      "[====================] 100/100: - running_loss: 0.6548 - running_reg: 0.000000 - running_acc: 0.6038 - lr: 0.00035 - epoch_loss: 0.6688 - epoch_reg: 0.000000 - epoch_acc: 0.5691 - valid_loss: 0.6921 - valid_reg: 0.000000 - valid_acc: 0.5604 - epoch_time: 138.4681 s\n",
      "Epoch 50\n",
      "[====================] 100/100: - running_loss: 0.6818 - running_reg: 0.000000 - running_acc: 0.5511 - lr: 0.00036 - epoch_loss: 0.6691 - epoch_reg: 0.000000 - epoch_acc: 0.5741 - valid_loss: 0.6840 - valid_reg: 0.000000 - valid_acc: 0.5494 - epoch_time: 138.0073 s\n",
      "Epoch 51\n",
      "[====================] 100/100: - running_loss: 0.6715 - running_reg: 0.000000 - running_acc: 0.5683 - lr: 0.00036 - epoch_loss: 0.6689 - epoch_reg: 0.000000 - epoch_acc: 0.5850 - valid_loss: 0.6673 - valid_reg: 0.000000 - valid_acc: 0.5721 - epoch_time: 138.4285 s\n",
      "Epoch 52\n",
      "[====================] 100/100: - running_loss: 0.6467 - running_reg: 0.000000 - running_acc: 0.6334 - lr: 0.00037 - epoch_loss: 0.6614 - epoch_reg: 0.000000 - epoch_acc: 0.5881 - valid_loss: 0.6655 - valid_reg: 0.000000 - valid_acc: 0.5750 - epoch_time: 137.5000 s\n",
      "Epoch 53\n",
      "[====================] 100/100: - running_loss: 0.6355 - running_reg: 0.000000 - running_acc: 0.6118 - lr: 0.00038 - epoch_loss: 0.6472 - epoch_reg: 0.000000 - epoch_acc: 0.6050 - valid_loss: 0.6497 - valid_reg: 0.000000 - valid_acc: 0.6073 - epoch_time: 138.2583 s\n",
      "Epoch 54\n",
      "[====================] 100/100: - running_loss: 0.6475 - running_reg: 0.000000 - running_acc: 0.6092 - lr: 0.00038 - epoch_loss: 0.6439 - epoch_reg: 0.000000 - epoch_acc: 0.6081 - valid_loss: 0.6384 - valid_reg: 0.000000 - valid_acc: 0.6194 - epoch_time: 138.6318 s\n",
      "Epoch 55\n",
      "[====================] 100/100: - running_loss: 0.6288 - running_reg: 0.000000 - running_acc: 0.6441 - lr: 0.00039 - epoch_loss: 0.6371 - epoch_reg: 0.000000 - epoch_acc: 0.6281 - valid_loss: 0.6899 - valid_reg: 0.000000 - valid_acc: 0.5952 - epoch_time: 138.1498 s\n",
      "Epoch 56\n",
      "[====================] 100/100: - running_loss: 0.6106 - running_reg: 0.000000 - running_acc: 0.6500 - lr: 0.00040 - epoch_loss: 0.6217 - epoch_reg: 0.000000 - epoch_acc: 0.6484 - valid_loss: 0.6340 - valid_reg: 0.000000 - valid_acc: 0.6264 - epoch_time: 138.4151 s\n",
      "Epoch 57\n",
      "[====================] 100/100: - running_loss: 0.5833 - running_reg: 0.000000 - running_acc: 0.6922 - lr: 0.00041 - epoch_loss: 0.6086 - epoch_reg: 0.000000 - epoch_acc: 0.6650 - valid_loss: 0.6974 - valid_reg: 0.000000 - valid_acc: 0.5929 - epoch_time: 138.2379 s\n",
      "Epoch 58\n",
      "[====================] 100/100: - running_loss: 0.5474 - running_reg: 0.000000 - running_acc: 0.7303 - lr: 0.00041 - epoch_loss: 0.5524 - epoch_reg: 0.000000 - epoch_acc: 0.7128 - valid_loss: 0.6925 - valid_reg: 0.000000 - valid_acc: 0.5885 - epoch_time: 138.0533 s\n",
      "Epoch 59\n",
      "[====================] 100/100: - running_loss: 0.5039 - running_reg: 0.000000 - running_acc: 0.7626 - lr: 0.00042 - epoch_loss: 0.5087 - epoch_reg: 0.000000 - epoch_acc: 0.7547 - valid_loss: 0.6887 - valid_reg: 0.000000 - valid_acc: 0.5940 - epoch_time: 138.9225 s\n",
      "Epoch 60\n",
      "[====================] 100/100: - running_loss: 0.4988 - running_reg: 0.000000 - running_acc: 0.7593 - lr: 0.00043 - epoch_loss: 0.4917 - epoch_reg: 0.000000 - epoch_acc: 0.7631 - valid_loss: 0.6795 - valid_reg: 0.000000 - valid_acc: 0.5854 - epoch_time: 140.1234 s\n",
      "Epoch 61\n",
      "[====================] 100/100: - running_loss: 0.5166 - running_reg: 0.000000 - running_acc: 0.7533 - lr: 0.00043 - epoch_loss: 0.5023 - epoch_reg: 0.000000 - epoch_acc: 0.7628 - valid_loss: 0.6821 - valid_reg: 0.000000 - valid_acc: 0.5822 - epoch_time: 139.6108 s\n",
      "Epoch 62\n",
      "[====================] 100/100: - running_loss: 0.5801 - running_reg: 0.000000 - running_acc: 0.6857 - lr: 0.00044 - epoch_loss: 0.5616 - epoch_reg: 0.000000 - epoch_acc: 0.7091 - valid_loss: 0.6478 - valid_reg: 0.000000 - valid_acc: 0.6064 - epoch_time: 138.8231 s\n",
      "Epoch 63\n",
      "[====================] 100/100: - running_loss: 0.6083 - running_reg: 0.000000 - running_acc: 0.6339 - lr: 0.00045 - epoch_loss: 0.5953 - epoch_reg: 0.000000 - epoch_acc: 0.6616 - valid_loss: 0.6400 - valid_reg: 0.000000 - valid_acc: 0.6086 - epoch_time: 139.4855 s\n",
      "Epoch 64\n",
      "[====================] 100/100: - running_loss: 0.5839 - running_reg: 0.000000 - running_acc: 0.6949 - lr: 0.00045 - epoch_loss: 0.5868 - epoch_reg: 0.000000 - epoch_acc: 0.6781 - valid_loss: 0.7011 - valid_reg: 0.000000 - valid_acc: 0.5894 - epoch_time: 144.2269 s\n",
      "Epoch 65\n",
      "[====================] 100/100: - running_loss: 0.5228 - running_reg: 0.000000 - running_acc: 0.7328 - lr: 0.00046 - epoch_loss: 0.5516 - epoch_reg: 0.000000 - epoch_acc: 0.7150 - valid_loss: 0.7191 - valid_reg: 0.000000 - valid_acc: 0.6065 - epoch_time: 142.6499 s\n",
      "Epoch 66\n",
      "[====================] 100/100: - running_loss: 0.5620 - running_reg: 0.000000 - running_acc: 0.6804 - lr: 0.00047 - epoch_loss: 0.5496 - epoch_reg: 0.000000 - epoch_acc: 0.7028 - valid_loss: 0.7422 - valid_reg: 0.000000 - valid_acc: 0.5629 - epoch_time: 138.2866 s\n",
      "Epoch 67\n",
      "[====================] 100/100: - running_loss: 0.5333 - running_reg: 0.000000 - running_acc: 0.6941 - lr: 0.00048 - epoch_loss: 0.5448 - epoch_reg: 0.000000 - epoch_acc: 0.7031 - valid_loss: 0.7041 - valid_reg: 0.000000 - valid_acc: 0.6027 - epoch_time: 138.8705 s\n",
      "Epoch 68\n",
      "[====================] 100/100: - running_loss: 0.5779 - running_reg: 0.000000 - running_acc: 0.7084 - lr: 0.00048 - epoch_loss: 0.5676 - epoch_reg: 0.000000 - epoch_acc: 0.6972 - valid_loss: 0.8122 - valid_reg: 0.000000 - valid_acc: 0.5994 - epoch_time: 138.7559 s\n",
      "Epoch 69\n",
      "[====================] 100/100: - running_loss: 0.5632 - running_reg: 0.000000 - running_acc: 0.7100 - lr: 0.00049 - epoch_loss: 0.5332 - epoch_reg: 0.000000 - epoch_acc: 0.7275 - valid_loss: 0.7094 - valid_reg: 0.000000 - valid_acc: 0.6121 - epoch_time: 138.5598 s\n",
      "Epoch 70\n",
      "[====================] 100/100: - running_loss: 0.5763 - running_reg: 0.000000 - running_acc: 0.6912 - lr: 0.00050 - epoch_loss: 0.5700 - epoch_reg: 0.000000 - epoch_acc: 0.6888 - valid_loss: 0.7942 - valid_reg: 0.000000 - valid_acc: 0.5865 - epoch_time: 138.4062 s\n",
      "Epoch 71\n",
      "[====================] 100/100: - running_loss: 0.5818 - running_reg: 0.000000 - running_acc: 0.6690 - lr: 0.00050 - epoch_loss: 0.5939 - epoch_reg: 0.000000 - epoch_acc: 0.6669 - valid_loss: 1.0406 - valid_reg: 0.000000 - valid_acc: 0.5968 - epoch_time: 138.2288 s\n",
      "Epoch 72\n",
      "[====================] 100/100: - running_loss: 0.5955 - running_reg: 0.000000 - running_acc: 0.6558 - lr: 0.00051 - epoch_loss: 0.5826 - epoch_reg: 0.000000 - epoch_acc: 0.6728 - valid_loss: 0.7066 - valid_reg: 0.000000 - valid_acc: 0.6063 - epoch_time: 138.4595 s\n",
      "Epoch 73\n",
      "[====================] 100/100: - running_loss: 0.5751 - running_reg: 0.000000 - running_acc: 0.7033 - lr: 0.00052 - epoch_loss: 0.5786 - epoch_reg: 0.000000 - epoch_acc: 0.6856 - valid_loss: 0.9435 - valid_reg: 0.000000 - valid_acc: 0.5875 - epoch_time: 138.4821 s\n",
      "Epoch 74\n",
      "[====================] 100/100: - running_loss: 0.6069 - running_reg: 0.000000 - running_acc: 0.6750 - lr: 0.00052 - epoch_loss: 0.5867 - epoch_reg: 0.000000 - epoch_acc: 0.6844 - valid_loss: 0.7143 - valid_reg: 0.000000 - valid_acc: 0.6167 - epoch_time: 138.2945 s\n",
      "Epoch 75\n",
      "[====================] 100/100: - running_loss: 0.5827 - running_reg: 0.000000 - running_acc: 0.6852 - lr: 0.00053 - epoch_loss: 0.6051 - epoch_reg: 0.000000 - epoch_acc: 0.6697 - valid_loss: 0.6282 - valid_reg: 0.000000 - valid_acc: 0.6484 - epoch_time: 137.5530 s\n",
      "Epoch 76\n",
      "[====================] 100/100: - running_loss: 0.5589 - running_reg: 0.000000 - running_acc: 0.6937 - lr: 0.00054 - epoch_loss: 0.5742 - epoch_reg: 0.000000 - epoch_acc: 0.6816 - valid_loss: 0.6145 - valid_reg: 0.000000 - valid_acc: 0.6574 - epoch_time: 138.0705 s\n",
      "Epoch 77\n",
      "[====================] 100/100: - running_loss: 0.5410 - running_reg: 0.000000 - running_acc: 0.7069 - lr: 0.00054 - epoch_loss: 0.5552 - epoch_reg: 0.000000 - epoch_acc: 0.6875 - valid_loss: 0.6382 - valid_reg: 0.000000 - valid_acc: 0.6327 - epoch_time: 138.1929 s\n",
      "Epoch 78\n",
      "[====================] 100/100: - running_loss: 0.5298 - running_reg: 0.000000 - running_acc: 0.7141 - lr: 0.00055 - epoch_loss: 0.5356 - epoch_reg: 0.000000 - epoch_acc: 0.7184 - valid_loss: 0.6874 - valid_reg: 0.000000 - valid_acc: 0.6082 - epoch_time: 138.3692 s\n",
      "Epoch 79\n",
      "[====================] 100/100: - running_loss: 0.5556 - running_reg: 0.000000 - running_acc: 0.6958 - lr: 0.00056 - epoch_loss: 0.5331 - epoch_reg: 0.000000 - epoch_acc: 0.7169 - valid_loss: 0.6628 - valid_reg: 0.000000 - valid_acc: 0.6113 - epoch_time: 138.0853 s\n",
      "Epoch 80\n",
      "[====================] 100/100: - running_loss: 0.5947 - running_reg: 0.000000 - running_acc: 0.6737 - lr: 0.00056 - epoch_loss: 0.5635 - epoch_reg: 0.000000 - epoch_acc: 0.7003 - valid_loss: 0.6295 - valid_reg: 0.000000 - valid_acc: 0.6333 - epoch_time: 138.1266 s\n",
      "Epoch 81\n",
      "[====================] 100/100: - running_loss: 0.5824 - running_reg: 0.000000 - running_acc: 0.6902 - lr: 0.00055 - epoch_loss: 0.5813 - epoch_reg: 0.000000 - epoch_acc: 0.6909 - valid_loss: 0.6303 - valid_reg: 0.000000 - valid_acc: 0.6363 - epoch_time: 138.2438 s\n",
      "Epoch 82\n",
      "[====================] 100/100: - running_loss: 0.6124 - running_reg: 0.000000 - running_acc: 0.6652 - lr: 0.00055 - epoch_loss: 0.6112 - epoch_reg: 0.000000 - epoch_acc: 0.6591 - valid_loss: 0.6655 - valid_reg: 0.000000 - valid_acc: 0.6103 - epoch_time: 138.3285 s\n",
      "Epoch 83\n",
      "[====================] 100/100: - running_loss: 0.6184 - running_reg: 0.000000 - running_acc: 0.6447 - lr: 0.00055 - epoch_loss: 0.6250 - epoch_reg: 0.000000 - epoch_acc: 0.6481 - valid_loss: 0.6496 - valid_reg: 0.000000 - valid_acc: 0.6286 - epoch_time: 138.6114 s\n",
      "Epoch 84\n",
      "[====================] 100/100: - running_loss: 0.6345 - running_reg: 0.000000 - running_acc: 0.6145 - lr: 0.00054 - epoch_loss: 0.6391 - epoch_reg: 0.000000 - epoch_acc: 0.6263 - valid_loss: 0.6311 - valid_reg: 0.000000 - valid_acc: 0.6364 - epoch_time: 138.1526 s\n",
      "Epoch 85\n",
      "[====================] 100/100: - running_loss: 0.6348 - running_reg: 0.000000 - running_acc: 0.6264 - lr: 0.00054 - epoch_loss: 0.6420 - epoch_reg: 0.000000 - epoch_acc: 0.6212 - valid_loss: 0.7349 - valid_reg: 0.000000 - valid_acc: 0.5917 - epoch_time: 138.7641 s\n",
      "Epoch 86\n",
      "[====================] 100/100: - running_loss: 0.6349 - running_reg: 0.000000 - running_acc: 0.6226 - lr: 0.00054 - epoch_loss: 0.6339 - epoch_reg: 0.000000 - epoch_acc: 0.6291 - valid_loss: 0.6874 - valid_reg: 0.000000 - valid_acc: 0.5895 - epoch_time: 139.1924 s\n",
      "Epoch 87\n",
      "[====================] 100/100: - running_loss: 0.6305 - running_reg: 0.000000 - running_acc: 0.6436 - lr: 0.00053 - epoch_loss: 0.6406 - epoch_reg: 0.000000 - epoch_acc: 0.6284 - valid_loss: 0.6600 - valid_reg: 0.000000 - valid_acc: 0.6026 - epoch_time: 138.6073 s\n",
      "Epoch 88\n",
      "[====================] 100/100: - running_loss: 0.6040 - running_reg: 0.000000 - running_acc: 0.6442 - lr: 0.00053 - epoch_loss: 0.6236 - epoch_reg: 0.000000 - epoch_acc: 0.6319 - valid_loss: 0.6387 - valid_reg: 0.000000 - valid_acc: 0.6189 - epoch_time: 137.5244 s\n",
      "Epoch 89\n",
      "[====================] 100/100: - running_loss: 0.6223 - running_reg: 0.000000 - running_acc: 0.6436 - lr: 0.00053 - epoch_loss: 0.6059 - epoch_reg: 0.000000 - epoch_acc: 0.6584 - valid_loss: 0.6414 - valid_reg: 0.000000 - valid_acc: 0.6090 - epoch_time: 137.6114 s\n",
      "Epoch 90\n",
      "[====================] 100/100: - running_loss: 0.6064 - running_reg: 0.000000 - running_acc: 0.6603 - lr: 0.00052 - epoch_loss: 0.6113 - epoch_reg: 0.000000 - epoch_acc: 0.6559 - valid_loss: 0.6428 - valid_reg: 0.000000 - valid_acc: 0.6232 - epoch_time: 137.4796 s\n",
      "Epoch 91\n",
      "[====================] 100/100: - running_loss: 0.6049 - running_reg: 0.000000 - running_acc: 0.6508 - lr: 0.00052 - epoch_loss: 0.5940 - epoch_reg: 0.000000 - epoch_acc: 0.6647 - valid_loss: 0.6459 - valid_reg: 0.000000 - valid_acc: 0.6051 - epoch_time: 141.0813 s\n",
      "Epoch 92\n",
      "[====================] 100/100: - running_loss: 0.5330 - running_reg: 0.000000 - running_acc: 0.7262 - lr: 0.00052 - epoch_loss: 0.5489 - epoch_reg: 0.000000 - epoch_acc: 0.7038 - valid_loss: 0.6470 - valid_reg: 0.000000 - valid_acc: 0.6235 - epoch_time: 138.1895 s\n",
      "Epoch 93\n",
      "[====================] 100/100: - running_loss: 0.5495 - running_reg: 0.000000 - running_acc: 0.6942 - lr: 0.00052 - epoch_loss: 0.5356 - epoch_reg: 0.000000 - epoch_acc: 0.7156 - valid_loss: 0.6780 - valid_reg: 0.000000 - valid_acc: 0.6039 - epoch_time: 137.8741 s\n",
      "Epoch 94\n",
      "[====================] 100/100: - running_loss: 0.5782 - running_reg: 0.000000 - running_acc: 0.6915 - lr: 0.00051 - epoch_loss: 0.5740 - epoch_reg: 0.000000 - epoch_acc: 0.6853 - valid_loss: 0.6424 - valid_reg: 0.000000 - valid_acc: 0.6159 - epoch_time: 138.8760 s\n",
      "Epoch 95\n",
      "[====================] 100/100: - running_loss: 0.5953 - running_reg: 0.000000 - running_acc: 0.6636 - lr: 0.00051 - epoch_loss: 0.5935 - epoch_reg: 0.000000 - epoch_acc: 0.6625 - valid_loss: 0.6385 - valid_reg: 0.000000 - valid_acc: 0.6237 - epoch_time: 138.8958 s\n",
      "Epoch 96\n",
      "[====================] 100/100: - running_loss: 0.6058 - running_reg: 0.000000 - running_acc: 0.6771 - lr: 0.00051 - epoch_loss: 0.6069 - epoch_reg: 0.000000 - epoch_acc: 0.6744 - valid_loss: 0.6562 - valid_reg: 0.000000 - valid_acc: 0.6212 - epoch_time: 138.6911 s\n",
      "Epoch 97\n",
      "[====================] 100/100: - running_loss: 0.5833 - running_reg: 0.000000 - running_acc: 0.6797 - lr: 0.00051 - epoch_loss: 0.5878 - epoch_reg: 0.000000 - epoch_acc: 0.6888 - valid_loss: 0.6618 - valid_reg: 0.000000 - valid_acc: 0.6111 - epoch_time: 138.6433 s\n",
      "Epoch 98\n",
      "[====================] 100/100: - running_loss: 0.6004 - running_reg: 0.000000 - running_acc: 0.6679 - lr: 0.00050 - epoch_loss: 0.5913 - epoch_reg: 0.000000 - epoch_acc: 0.6719 - valid_loss: 0.6495 - valid_reg: 0.000000 - valid_acc: 0.6210 - epoch_time: 138.7278 s\n",
      "Epoch 99\n",
      "[====================] 100/100: - running_loss: 0.6140 - running_reg: 0.000000 - running_acc: 0.6374 - lr: 0.00050 - epoch_loss: 0.6124 - epoch_reg: 0.000000 - epoch_acc: 0.6562 - valid_loss: 0.6415 - valid_reg: 0.000000 - valid_acc: 0.6099 - epoch_time: 138.7417 s\n",
      "Epoch 100\n",
      "[====================] 100/100: - running_loss: 0.5858 - running_reg: 0.000000 - running_acc: 0.6773 - lr: 0.00050 - epoch_loss: 0.6039 - epoch_reg: 0.000000 - epoch_acc: 0.6584 - valid_loss: 0.6081 - valid_reg: 0.000000 - valid_acc: 0.6634 - epoch_time: 138.9936 s\n",
      "Epoch 101\n",
      "[====================] 100/100: - running_loss: 0.5538 - running_reg: 0.000000 - running_acc: 0.7149 - lr: 0.00050 - epoch_loss: 0.5705 - epoch_reg: 0.000000 - epoch_acc: 0.6959 - valid_loss: 0.6238 - valid_reg: 0.000000 - valid_acc: 0.6472 - epoch_time: 138.6278 s\n",
      "Epoch 102\n",
      "[====================] 100/100: - running_loss: 0.5122 - running_reg: 0.000000 - running_acc: 0.7570 - lr: 0.00049 - epoch_loss: 0.5437 - epoch_reg: 0.000000 - epoch_acc: 0.7191 - valid_loss: 0.6532 - valid_reg: 0.000000 - valid_acc: 0.6209 - epoch_time: 137.8971 s\n",
      "Epoch 103\n",
      "[====================] 100/100: - running_loss: 0.4879 - running_reg: 0.000000 - running_acc: 0.7711 - lr: 0.00049 - epoch_loss: 0.4788 - epoch_reg: 0.000000 - epoch_acc: 0.7728 - valid_loss: 0.6668 - valid_reg: 0.000000 - valid_acc: 0.6218 - epoch_time: 138.9614 s\n",
      "Epoch 104\n",
      "[====================] 100/100: - running_loss: 0.4194 - running_reg: 0.000000 - running_acc: 0.8098 - lr: 0.00049 - epoch_loss: 0.4303 - epoch_reg: 0.000000 - epoch_acc: 0.7994 - valid_loss: 0.6694 - valid_reg: 0.000000 - valid_acc: 0.6199 - epoch_time: 138.9169 s\n",
      "Epoch 105\n",
      "[====================] 100/100: - running_loss: 0.3938 - running_reg: 0.000000 - running_acc: 0.8137 - lr: 0.00049 - epoch_loss: 0.3971 - epoch_reg: 0.000000 - epoch_acc: 0.8128 - valid_loss: 0.7700 - valid_reg: 0.000000 - valid_acc: 0.6203 - epoch_time: 138.9347 s\n",
      "Epoch 106\n",
      "[====================] 100/100: - running_loss: 0.4147 - running_reg: 0.000000 - running_acc: 0.8062 - lr: 0.00048 - epoch_loss: 0.4049 - epoch_reg: 0.000000 - epoch_acc: 0.8247 - valid_loss: 0.6646 - valid_reg: 0.000000 - valid_acc: 0.6362 - epoch_time: 142.3210 s\n",
      "Epoch 107\n",
      "[====================] 100/100: - running_loss: 0.4393 - running_reg: 0.000000 - running_acc: 0.8018 - lr: 0.00048 - epoch_loss: 0.4137 - epoch_reg: 0.000000 - epoch_acc: 0.8081 - valid_loss: 0.7396 - valid_reg: 0.000000 - valid_acc: 0.6032 - epoch_time: 144.7126 s\n",
      "Epoch 108\n",
      "[====================] 100/100: - running_loss: 0.4595 - running_reg: 0.000000 - running_acc: 0.7777 - lr: 0.00048 - epoch_loss: 0.4644 - epoch_reg: 0.000000 - epoch_acc: 0.7734 - valid_loss: 0.6502 - valid_reg: 0.000000 - valid_acc: 0.6372 - epoch_time: 138.6534 s\n",
      "Epoch 109\n",
      "[====================] 100/100: - running_loss: 0.5360 - running_reg: 0.000000 - running_acc: 0.7177 - lr: 0.00048 - epoch_loss: 0.5178 - epoch_reg: 0.000000 - epoch_acc: 0.7356 - valid_loss: 0.6550 - valid_reg: 0.000000 - valid_acc: 0.6514 - epoch_time: 138.3062 s\n",
      "Epoch 110\n",
      "[====================] 100/100: - running_loss: 0.5073 - running_reg: 0.000000 - running_acc: 0.7464 - lr: 0.00047 - epoch_loss: 0.5045 - epoch_reg: 0.000000 - epoch_acc: 0.7403 - valid_loss: 0.6969 - valid_reg: 0.000000 - valid_acc: 0.6410 - epoch_time: 138.4907 s\n",
      "Epoch 111\n",
      "[====================] 100/100: - running_loss: 0.4556 - running_reg: 0.000000 - running_acc: 0.7745 - lr: 0.00047 - epoch_loss: 0.4723 - epoch_reg: 0.000000 - epoch_acc: 0.7600 - valid_loss: 0.7390 - valid_reg: 0.000000 - valid_acc: 0.6524 - epoch_time: 138.5097 s\n",
      "Epoch 112\n",
      "[====================] 100/100: - running_loss: 0.4705 - running_reg: 0.000000 - running_acc: 0.7846 - lr: 0.00047 - epoch_loss: 0.4591 - epoch_reg: 0.000000 - epoch_acc: 0.7766 - valid_loss: 0.7450 - valid_reg: 0.000000 - valid_acc: 0.6583 - epoch_time: 138.5471 s\n",
      "Epoch 113\n",
      "[====================] 100/100: - running_loss: 0.4505 - running_reg: 0.000000 - running_acc: 0.7893 - lr: 0.00047 - epoch_loss: 0.4587 - epoch_reg: 0.000000 - epoch_acc: 0.7806 - valid_loss: 0.7195 - valid_reg: 0.000000 - valid_acc: 0.6317 - epoch_time: 138.8835 s\n",
      "Epoch 114\n",
      "[====================] 100/100: - running_loss: 0.4317 - running_reg: 0.000000 - running_acc: 0.7871 - lr: 0.00047 - epoch_loss: 0.4464 - epoch_reg: 0.000000 - epoch_acc: 0.7887 - valid_loss: 0.7623 - valid_reg: 0.000000 - valid_acc: 0.6430 - epoch_time: 138.7034 s\n",
      "Epoch 115\n",
      "[====================] 100/100: - running_loss: 0.4811 - running_reg: 0.000000 - running_acc: 0.7685 - lr: 0.00046 - epoch_loss: 0.4741 - epoch_reg: 0.000000 - epoch_acc: 0.7625 - valid_loss: 0.8422 - valid_reg: 0.000000 - valid_acc: 0.6222 - epoch_time: 139.1081 s\n",
      "Epoch 116\n",
      "[====================] 100/100: - running_loss: 0.4929 - running_reg: 0.000000 - running_acc: 0.7443 - lr: 0.00046 - epoch_loss: 0.5000 - epoch_reg: 0.000000 - epoch_acc: 0.7394 - valid_loss: 0.7354 - valid_reg: 0.000000 - valid_acc: 0.6520 - epoch_time: 139.1249 s\n",
      "Epoch 117\n",
      "[====================] 100/100: - running_loss: 0.5228 - running_reg: 0.000000 - running_acc: 0.7433 - lr: 0.00046 - epoch_loss: 0.5024 - epoch_reg: 0.000000 - epoch_acc: 0.7466 - valid_loss: 0.9080 - valid_reg: 0.000000 - valid_acc: 0.6408 - epoch_time: 138.9377 s\n",
      "Epoch 118\n",
      "[====================] 100/100: - running_loss: 0.5259 - running_reg: 0.000000 - running_acc: 0.7299 - lr: 0.00046 - epoch_loss: 0.5068 - epoch_reg: 0.000000 - epoch_acc: 0.7397 - valid_loss: 0.8326 - valid_reg: 0.000000 - valid_acc: 0.6455 - epoch_time: 139.0047 s\n",
      "Epoch 119\n",
      "[====================] 100/100: - running_loss: 0.5128 - running_reg: 0.000000 - running_acc: 0.7283 - lr: 0.00046 - epoch_loss: 0.5234 - epoch_reg: 0.000000 - epoch_acc: 0.7406 - valid_loss: 0.7943 - valid_reg: 0.000000 - valid_acc: 0.6401 - epoch_time: 139.0937 s\n",
      "Epoch 120\n",
      "[====================] 100/100: - running_loss: 0.5573 - running_reg: 0.000000 - running_acc: 0.6972 - lr: 0.00045 - epoch_loss: 0.5448 - epoch_reg: 0.000000 - epoch_acc: 0.7159 - valid_loss: 0.6508 - valid_reg: 0.000000 - valid_acc: 0.6628 - epoch_time: 139.0307 s\n",
      "Epoch 121\n",
      "[====================] 100/100: - running_loss: 0.5136 - running_reg: 0.000000 - running_acc: 0.7391 - lr: 0.00045 - epoch_loss: 0.5417 - epoch_reg: 0.000000 - epoch_acc: 0.7225 - valid_loss: 0.6246 - valid_reg: 0.000000 - valid_acc: 0.6669 - epoch_time: 139.1359 s\n",
      "Epoch 122\n",
      "[====================] 100/100: - running_loss: 0.5250 - running_reg: 0.000000 - running_acc: 0.7187 - lr: 0.00045 - epoch_loss: 0.5218 - epoch_reg: 0.000000 - epoch_acc: 0.7278 - valid_loss: 0.5922 - valid_reg: 0.000000 - valid_acc: 0.6778 - epoch_time: 139.0447 s\n",
      "Epoch 123\n",
      "[====================] 100/100: - running_loss: 0.5188 - running_reg: 0.000000 - running_acc: 0.7329 - lr: 0.00045 - epoch_loss: 0.5107 - epoch_reg: 0.000000 - epoch_acc: 0.7403 - valid_loss: 0.6477 - valid_reg: 0.000000 - valid_acc: 0.6408 - epoch_time: 139.4594 s\n",
      "Epoch 124\n",
      "[====================] 100/100: - running_loss: 0.4504 - running_reg: 0.000000 - running_acc: 0.7815 - lr: 0.00045 - epoch_loss: 0.4805 - epoch_reg: 0.000000 - epoch_acc: 0.7700 - valid_loss: 0.6572 - valid_reg: 0.000000 - valid_acc: 0.6539 - epoch_time: 138.7255 s\n",
      "Epoch 125\n",
      "[====================] 100/100: - running_loss: 0.4968 - running_reg: 0.000000 - running_acc: 0.7436 - lr: 0.00045 - epoch_loss: 0.4915 - epoch_reg: 0.000000 - epoch_acc: 0.7509 - valid_loss: 0.6109 - valid_reg: 0.000000 - valid_acc: 0.6692 - epoch_time: 138.8467 s\n",
      "Epoch 126\n",
      "[====================] 100/100: - running_loss: 0.5205 - running_reg: 0.000000 - running_acc: 0.7346 - lr: 0.00044 - epoch_loss: 0.5191 - epoch_reg: 0.000000 - epoch_acc: 0.7378 - valid_loss: 0.6326 - valid_reg: 0.000000 - valid_acc: 0.6466 - epoch_time: 138.9498 s\n",
      "Epoch 127\n",
      "[====================] 100/100: - running_loss: 0.5467 - running_reg: 0.000000 - running_acc: 0.7393 - lr: 0.00044 - epoch_loss: 0.5500 - epoch_reg: 0.000000 - epoch_acc: 0.7194 - valid_loss: 0.6075 - valid_reg: 0.000000 - valid_acc: 0.6548 - epoch_time: 138.6871 s\n",
      "Epoch 128\n",
      "[====================] 100/100: - running_loss: 0.5610 - running_reg: 0.000000 - running_acc: 0.6854 - lr: 0.00044 - epoch_loss: 0.5603 - epoch_reg: 0.000000 - epoch_acc: 0.6969 - valid_loss: 0.5844 - valid_reg: 0.000000 - valid_acc: 0.6755 - epoch_time: 138.6134 s\n",
      "Epoch 129\n",
      "[====================] 100/100: - running_loss: 0.5406 - running_reg: 0.000000 - running_acc: 0.7134 - lr: 0.00044 - epoch_loss: 0.5576 - epoch_reg: 0.000000 - epoch_acc: 0.7056 - valid_loss: 0.6148 - valid_reg: 0.000000 - valid_acc: 0.6586 - epoch_time: 139.0987 s\n",
      "Epoch 130\n",
      "[====================] 100/100: - running_loss: 0.5834 - running_reg: 0.000000 - running_acc: 0.6857 - lr: 0.00044 - epoch_loss: 0.5667 - epoch_reg: 0.000000 - epoch_acc: 0.6928 - valid_loss: 0.6101 - valid_reg: 0.000000 - valid_acc: 0.6577 - epoch_time: 138.6152 s\n",
      "Epoch 131\n",
      "[====================] 100/100: - running_loss: 0.5487 - running_reg: 0.000000 - running_acc: 0.7202 - lr: 0.00044 - epoch_loss: 0.5844 - epoch_reg: 0.000000 - epoch_acc: 0.6872 - valid_loss: 0.6903 - valid_reg: 0.000000 - valid_acc: 0.6329 - epoch_time: 139.1457 s\n",
      "Epoch 132\n",
      "[====================] 100/100: - running_loss: 0.6106 - running_reg: 0.000000 - running_acc: 0.6470 - lr: 0.00043 - epoch_loss: 0.5903 - epoch_reg: 0.000000 - epoch_acc: 0.6644 - valid_loss: 0.6346 - valid_reg: 0.000000 - valid_acc: 0.6408 - epoch_time: 138.9014 s\n",
      "Epoch 133\n",
      "[====================] 100/100: - running_loss: 0.5972 - running_reg: 0.000000 - running_acc: 0.6735 - lr: 0.00043 - epoch_loss: 0.5947 - epoch_reg: 0.000000 - epoch_acc: 0.6556 - valid_loss: 0.6119 - valid_reg: 0.000000 - valid_acc: 0.6562 - epoch_time: 138.7577 s\n",
      "Epoch 134\n",
      "[====================] 100/100: - running_loss: 0.5424 - running_reg: 0.000000 - running_acc: 0.7104 - lr: 0.00043 - epoch_loss: 0.5636 - epoch_reg: 0.000000 - epoch_acc: 0.6906 - valid_loss: 0.6667 - valid_reg: 0.000000 - valid_acc: 0.6405 - epoch_time: 138.2028 s\n",
      "Epoch 135\n",
      "[====================] 100/100: - running_loss: 0.5207 - running_reg: 0.000000 - running_acc: 0.7198 - lr: 0.00043 - epoch_loss: 0.5543 - epoch_reg: 0.000000 - epoch_acc: 0.6988 - valid_loss: 0.6504 - valid_reg: 0.000000 - valid_acc: 0.6357 - epoch_time: 138.5073 s\n",
      "Epoch 136\n",
      "[====================] 100/100: - running_loss: 0.5098 - running_reg: 0.000000 - running_acc: 0.7426 - lr: 0.00043 - epoch_loss: 0.5396 - epoch_reg: 0.000000 - epoch_acc: 0.7134 - valid_loss: 0.6488 - valid_reg: 0.000000 - valid_acc: 0.6456 - epoch_time: 138.4641 s\n",
      "Epoch 137\n",
      "[====================] 100/100: - running_loss: 0.5835 - running_reg: 0.000000 - running_acc: 0.6805 - lr: 0.00043 - epoch_loss: 0.5651 - epoch_reg: 0.000000 - epoch_acc: 0.6931 - valid_loss: 0.6456 - valid_reg: 0.000000 - valid_acc: 0.6182 - epoch_time: 182.2298 s\n",
      "Epoch 138\n",
      "[====================] 100/100: - running_loss: 0.5466 - running_reg: 0.000000 - running_acc: 0.7060 - lr: 0.00042 - epoch_loss: 0.5411 - epoch_reg: 0.000000 - epoch_acc: 0.7069 - valid_loss: 0.6289 - valid_reg: 0.000000 - valid_acc: 0.6335 - epoch_time: 138.2527 s\n",
      "Epoch 139\n",
      "[====================] 100/100: - running_loss: 0.4929 - running_reg: 0.000000 - running_acc: 0.7629 - lr: 0.00042 - epoch_loss: 0.5123 - epoch_reg: 0.000000 - epoch_acc: 0.7341 - valid_loss: 0.6474 - valid_reg: 0.000000 - valid_acc: 0.6627 - epoch_time: 139.2332 s\n",
      "Epoch 140\n",
      "[====================] 100/100: - running_loss: 0.5309 - running_reg: 0.000000 - running_acc: 0.7292 - lr: 0.00042 - epoch_loss: 0.5265 - epoch_reg: 0.000000 - epoch_acc: 0.7206 - valid_loss: 0.6108 - valid_reg: 0.000000 - valid_acc: 0.6648 - epoch_time: 138.3311 s\n",
      "Epoch 141\n",
      "[====================] 100/100: - running_loss: 0.5497 - running_reg: 0.000000 - running_acc: 0.7173 - lr: 0.00042 - epoch_loss: 0.5281 - epoch_reg: 0.000000 - epoch_acc: 0.7262 - valid_loss: 0.6146 - valid_reg: 0.000000 - valid_acc: 0.6541 - epoch_time: 138.6206 s\n",
      "Epoch 142\n",
      "[====================] 100/100: - running_loss: 0.5330 - running_reg: 0.000000 - running_acc: 0.7290 - lr: 0.00042 - epoch_loss: 0.5487 - epoch_reg: 0.000000 - epoch_acc: 0.7150 - valid_loss: 0.6599 - valid_reg: 0.000000 - valid_acc: 0.6448 - epoch_time: 138.6233 s\n",
      "Epoch 143\n",
      "[====================] 100/100: - running_loss: 0.5564 - running_reg: 0.000000 - running_acc: 0.7115 - lr: 0.00042 - epoch_loss: 0.5539 - epoch_reg: 0.000000 - epoch_acc: 0.7016 - valid_loss: 0.6343 - valid_reg: 0.000000 - valid_acc: 0.6486 - epoch_time: 138.6620 s\n",
      "Epoch 144\n",
      "[====================] 100/100: - running_loss: 0.5571 - running_reg: 0.000000 - running_acc: 0.7045 - lr: 0.00042 - epoch_loss: 0.5391 - epoch_reg: 0.000000 - epoch_acc: 0.7203 - valid_loss: 0.6473 - valid_reg: 0.000000 - valid_acc: 0.6560 - epoch_time: 138.4990 s\n",
      "Epoch 145\n",
      "[====================] 100/100: - running_loss: 0.5393 - running_reg: 0.000000 - running_acc: 0.7068 - lr: 0.00041 - epoch_loss: 0.5495 - epoch_reg: 0.000000 - epoch_acc: 0.7056 - valid_loss: 0.6068 - valid_reg: 0.000000 - valid_acc: 0.6634 - epoch_time: 139.0077 s\n",
      "Epoch 146\n",
      "[====================] 100/100: - running_loss: 0.5251 - running_reg: 0.000000 - running_acc: 0.7343 - lr: 0.00041 - epoch_loss: 0.5324 - epoch_reg: 0.000000 - epoch_acc: 0.7197 - valid_loss: 0.5963 - valid_reg: 0.000000 - valid_acc: 0.6746 - epoch_time: 138.5039 s\n",
      "Epoch 147\n",
      "[====================] 100/100: - running_loss: 0.4453 - running_reg: 0.000000 - running_acc: 0.7715 - lr: 0.00041 - epoch_loss: 0.4691 - epoch_reg: 0.000000 - epoch_acc: 0.7550 - valid_loss: 0.6394 - valid_reg: 0.000000 - valid_acc: 0.6718 - epoch_time: 139.1479 s\n",
      "Epoch 148\n",
      "[====================] 100/100: - running_loss: 0.4129 - running_reg: 0.000000 - running_acc: 0.8134 - lr: 0.00041 - epoch_loss: 0.4385 - epoch_reg: 0.000000 - epoch_acc: 0.7909 - valid_loss: 0.6463 - valid_reg: 0.000000 - valid_acc: 0.6643 - epoch_time: 141.5035 s\n",
      "Epoch 149\n",
      "[====================] 100/100: - running_loss: 0.3406 - running_reg: 0.000000 - running_acc: 0.8451 - lr: 0.00041 - epoch_loss: 0.3683 - epoch_reg: 0.000000 - epoch_acc: 0.8288 - valid_loss: 0.6979 - valid_reg: 0.000000 - valid_acc: 0.6360 - epoch_time: 144.1109 s\n",
      " - test_loss: 0.5946 - test_reg: 0.000000 - test_acc: 0.6671 - test_time: 96.1151 s\n",
      "Original model 1601538 params, new model 1535490 params, ratio 0.959\n",
      "Epoch 0\n",
      "[====================] 100/100: - running_loss: 1.0409 - running_reg: 0.000000 - running_acc: 0.5236 - lr: 0.00001 - epoch_loss: 1.1314 - epoch_reg: 0.000000 - epoch_acc: 0.5391 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 50.2105 s\n",
      "Epoch 1\n",
      "[====================] 100/100: - running_loss: 0.9810 - running_reg: 0.000000 - running_acc: 0.5298 - lr: 0.00001 - epoch_loss: 0.9802 - epoch_reg: 0.000000 - epoch_acc: 0.5522 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6854 s\n",
      "Epoch 2\n",
      "[====================] 100/100: - running_loss: 0.9140 - running_reg: 0.000000 - running_acc: 0.5261 - lr: 0.00002 - epoch_loss: 0.9283 - epoch_reg: 0.000000 - epoch_acc: 0.5322 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7369 s\n",
      "Epoch 3\n",
      "[====================] 100/100: - running_loss: 0.8375 - running_reg: 0.000000 - running_acc: 0.5175 - lr: 0.00003 - epoch_loss: 0.8430 - epoch_reg: 0.000000 - epoch_acc: 0.5266 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8032 s\n",
      "Epoch 4\n",
      "[====================] 100/100: - running_loss: 0.8149 - running_reg: 0.000000 - running_acc: 0.5004 - lr: 0.00003 - epoch_loss: 0.8203 - epoch_reg: 0.000000 - epoch_acc: 0.5131 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7159 s\n",
      "Epoch 5\n",
      "[====================] 100/100: - running_loss: 0.7934 - running_reg: 0.000000 - running_acc: 0.5054 - lr: 0.00004 - epoch_loss: 0.8308 - epoch_reg: 0.000000 - epoch_acc: 0.4984 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6264 s\n",
      "Epoch 6\n",
      "[====================] 100/100: - running_loss: 0.7797 - running_reg: 0.000000 - running_acc: 0.5045 - lr: 0.00005 - epoch_loss: 0.8019 - epoch_reg: 0.000000 - epoch_acc: 0.4925 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7121 s\n",
      "Epoch 7\n",
      "[====================] 100/100: - running_loss: 0.7687 - running_reg: 0.000000 - running_acc: 0.4917 - lr: 0.00006 - epoch_loss: 0.7713 - epoch_reg: 0.000000 - epoch_acc: 0.5203 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7418 s\n",
      "Epoch 8\n",
      "[====================] 100/100: - running_loss: 0.7633 - running_reg: 0.000000 - running_acc: 0.5030 - lr: 0.00006 - epoch_loss: 0.7654 - epoch_reg: 0.000000 - epoch_acc: 0.5097 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.9158 s\n",
      "Epoch 9\n",
      "[====================] 100/100: - running_loss: 0.7577 - running_reg: 0.000000 - running_acc: 0.5094 - lr: 0.00007 - epoch_loss: 0.7546 - epoch_reg: 0.000000 - epoch_acc: 0.5053 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8580 s\n",
      "Epoch 10\n",
      "[====================] 100/100: - running_loss: 0.7298 - running_reg: 0.000000 - running_acc: 0.5101 - lr: 0.00008 - epoch_loss: 0.7399 - epoch_reg: 0.000000 - epoch_acc: 0.5050 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6663 s\n",
      "Epoch 11\n",
      "[====================] 100/100: - running_loss: 0.7404 - running_reg: 0.000000 - running_acc: 0.5102 - lr: 0.00008 - epoch_loss: 0.7339 - epoch_reg: 0.000000 - epoch_acc: 0.5163 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8967 s\n",
      "Epoch 12\n",
      "[====================] 100/100: - running_loss: 0.7010 - running_reg: 0.000000 - running_acc: 0.5683 - lr: 0.00009 - epoch_loss: 0.7124 - epoch_reg: 0.000000 - epoch_acc: 0.5503 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8795 s\n",
      "Epoch 13\n",
      "[====================] 100/100: - running_loss: 0.6747 - running_reg: 0.000000 - running_acc: 0.6107 - lr: 0.00010 - epoch_loss: 0.6906 - epoch_reg: 0.000000 - epoch_acc: 0.5753 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6443 s\n",
      "Epoch 14\n",
      "[====================] 100/100: - running_loss: 0.6754 - running_reg: 0.000000 - running_acc: 0.5933 - lr: 0.00010 - epoch_loss: 0.6765 - epoch_reg: 0.000000 - epoch_acc: 0.5984 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5041 s\n",
      "Epoch 15\n",
      "[====================] 100/100: - running_loss: 0.6857 - running_reg: 0.000000 - running_acc: 0.6148 - lr: 0.00011 - epoch_loss: 0.6778 - epoch_reg: 0.000000 - epoch_acc: 0.6084 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5726 s\n",
      "Epoch 16\n",
      "[====================] 100/100: - running_loss: 0.6811 - running_reg: 0.000000 - running_acc: 0.5697 - lr: 0.00012 - epoch_loss: 0.6879 - epoch_reg: 0.000000 - epoch_acc: 0.5734 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6252 s\n",
      "Epoch 17\n",
      "[====================] 100/100: - running_loss: 0.6907 - running_reg: 0.000000 - running_acc: 0.5285 - lr: 0.00013 - epoch_loss: 0.6895 - epoch_reg: 0.000000 - epoch_acc: 0.5525 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5938 s\n",
      "Epoch 18\n",
      "[====================] 100/100: - running_loss: 0.6944 - running_reg: 0.000000 - running_acc: 0.5337 - lr: 0.00013 - epoch_loss: 0.6854 - epoch_reg: 0.000000 - epoch_acc: 0.5625 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4654 s\n",
      "Epoch 19\n",
      "[====================] 100/100: - running_loss: 0.6947 - running_reg: 0.000000 - running_acc: 0.5544 - lr: 0.00014 - epoch_loss: 0.7044 - epoch_reg: 0.000000 - epoch_acc: 0.5516 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6511 s\n",
      "Epoch 20\n",
      "[====================] 100/100: - running_loss: 0.6565 - running_reg: 0.000000 - running_acc: 0.5958 - lr: 0.00015 - epoch_loss: 0.6674 - epoch_reg: 0.000000 - epoch_acc: 0.5788 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5159 s\n",
      "Epoch 21\n",
      "[====================] 100/100: - running_loss: 0.6538 - running_reg: 0.000000 - running_acc: 0.5714 - lr: 0.00015 - epoch_loss: 0.6632 - epoch_reg: 0.000000 - epoch_acc: 0.5644 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6271 s\n",
      "Epoch 22\n",
      "[====================] 100/100: - running_loss: 0.6429 - running_reg: 0.000000 - running_acc: 0.5893 - lr: 0.00016 - epoch_loss: 0.6664 - epoch_reg: 0.000000 - epoch_acc: 0.5788 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7038 s\n",
      "Epoch 23\n",
      "[====================] 100/100: - running_loss: 0.6625 - running_reg: 0.000000 - running_acc: 0.5826 - lr: 0.00017 - epoch_loss: 0.6611 - epoch_reg: 0.000000 - epoch_acc: 0.5925 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.4517 s\n",
      "Epoch 24\n",
      "[====================] 100/100: - running_loss: 0.6660 - running_reg: 0.000000 - running_acc: 0.6016 - lr: 0.00017 - epoch_loss: 0.6590 - epoch_reg: 0.000000 - epoch_acc: 0.6022 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6150 s\n",
      "Epoch 25\n",
      "[====================] 100/100: - running_loss: 0.6786 - running_reg: 0.000000 - running_acc: 0.5748 - lr: 0.00018 - epoch_loss: 0.6740 - epoch_reg: 0.000000 - epoch_acc: 0.5725 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6599 s\n",
      "Epoch 26\n",
      "[====================] 100/100: - running_loss: 0.6384 - running_reg: 0.000000 - running_acc: 0.6039 - lr: 0.00019 - epoch_loss: 0.6632 - epoch_reg: 0.000000 - epoch_acc: 0.5913 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8686 s\n",
      "Epoch 27\n",
      "[====================] 100/100: - running_loss: 0.6571 - running_reg: 0.000000 - running_acc: 0.6190 - lr: 0.00020 - epoch_loss: 0.6657 - epoch_reg: 0.000000 - epoch_acc: 0.5991 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6049 s\n",
      "Epoch 28\n",
      "[====================] 100/100: - running_loss: 0.6666 - running_reg: 0.000000 - running_acc: 0.5841 - lr: 0.00020 - epoch_loss: 0.6706 - epoch_reg: 0.000000 - epoch_acc: 0.5856 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8607 s\n",
      "Epoch 29\n",
      "[====================] 100/100: - running_loss: 0.6932 - running_reg: 0.000000 - running_acc: 0.5591 - lr: 0.00021 - epoch_loss: 0.6853 - epoch_reg: 0.000000 - epoch_acc: 0.5566 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.7221 s\n",
      "Epoch 30\n",
      "[====================] 100/100: - running_loss: 0.6904 - running_reg: 0.000000 - running_acc: 0.5536 - lr: 0.00022 - epoch_loss: 0.7036 - epoch_reg: 0.000000 - epoch_acc: 0.5250 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5378 s\n",
      "Epoch 31\n",
      "[====================] 100/100: - running_loss: 0.6505 - running_reg: 0.000000 - running_acc: 0.6319 - lr: 0.00022 - epoch_loss: 0.6747 - epoch_reg: 0.000000 - epoch_acc: 0.5788 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.5374 s\n",
      "Epoch 32\n",
      "[====================] 100/100: - running_loss: 0.6223 - running_reg: 0.000000 - running_acc: 0.6515 - lr: 0.00023 - epoch_loss: 0.6438 - epoch_reg: 0.000000 - epoch_acc: 0.6259 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.8205 s\n",
      "Epoch 33\n",
      "[====================] 100/100: - running_loss: 0.6269 - running_reg: 0.000000 - running_acc: 0.6632 - lr: 0.00024 - epoch_loss: 0.6410 - epoch_reg: 0.000000 - epoch_acc: 0.6397 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6870 s\n",
      "Epoch 34\n",
      "[====================] 100/100: - running_loss: 0.6674 - running_reg: 0.000000 - running_acc: 0.5765 - lr: 0.00024 - epoch_loss: 0.6572 - epoch_reg: 0.000000 - epoch_acc: 0.6053 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 42.6328 s\n",
      "Epoch 35\n",
      "[====================] 100/100: - running_loss: 0.6656 - running_reg: 0.000000 - running_acc: 0.5795 - lr: 0.00025 - epoch_loss: 0.6616 - epoch_reg: 0.000000 - epoch_acc: 0.5981 - valid_loss: 0.6896 - valid_reg: 0.000000 - valid_acc: 0.5658 - epoch_time: 139.4425 s\n",
      "Epoch 36\n",
      "[====================] 100/100: - running_loss: 0.6836 - running_reg: 0.000000 - running_acc: 0.5466 - lr: 0.00026 - epoch_loss: 0.6741 - epoch_reg: 0.000000 - epoch_acc: 0.5716 - valid_loss: 0.6867 - valid_reg: 0.000000 - valid_acc: 0.5435 - epoch_time: 138.7293 s\n",
      "Epoch 37\n",
      "[====================] 100/100: - running_loss: 0.6963 - running_reg: 0.000000 - running_acc: 0.5405 - lr: 0.00027 - epoch_loss: 0.6896 - epoch_reg: 0.000000 - epoch_acc: 0.5459 - valid_loss: 0.6870 - valid_reg: 0.000000 - valid_acc: 0.5551 - epoch_time: 138.4555 s\n",
      "Epoch 38\n",
      "[====================] 100/100: - running_loss: 0.6882 - running_reg: 0.000000 - running_acc: 0.5650 - lr: 0.00027 - epoch_loss: 0.6828 - epoch_reg: 0.000000 - epoch_acc: 0.5659 - valid_loss: 0.6972 - valid_reg: 0.000000 - valid_acc: 0.5152 - epoch_time: 138.6079 s\n",
      "Epoch 39\n",
      "[====================] 100/100: - running_loss: 0.6670 - running_reg: 0.000000 - running_acc: 0.5959 - lr: 0.00028 - epoch_loss: 0.6886 - epoch_reg: 0.000000 - epoch_acc: 0.5487 - valid_loss: 0.6987 - valid_reg: 0.000000 - valid_acc: 0.5421 - epoch_time: 138.4325 s\n",
      "Epoch 40\n",
      "[====================] 100/100: - running_loss: 0.6735 - running_reg: 0.000000 - running_acc: 0.5884 - lr: 0.00029 - epoch_loss: 0.6787 - epoch_reg: 0.000000 - epoch_acc: 0.5766 - valid_loss: 0.7272 - valid_reg: 0.000000 - valid_acc: 0.5296 - epoch_time: 138.1675 s\n",
      "Epoch 41\n",
      "[====================] 100/100: - running_loss: 0.6823 - running_reg: 0.000000 - running_acc: 0.5601 - lr: 0.00029 - epoch_loss: 0.6854 - epoch_reg: 0.000000 - epoch_acc: 0.5547 - valid_loss: 0.6883 - valid_reg: 0.000000 - valid_acc: 0.5474 - epoch_time: 138.1778 s\n",
      "Epoch 42\n",
      "[====================] 100/100: - running_loss: 0.6689 - running_reg: 0.000000 - running_acc: 0.5884 - lr: 0.00030 - epoch_loss: 0.6745 - epoch_reg: 0.000000 - epoch_acc: 0.5688 - valid_loss: 0.6827 - valid_reg: 0.000000 - valid_acc: 0.5664 - epoch_time: 137.9427 s\n",
      "Epoch 43\n",
      "[====================] 100/100: - running_loss: 0.6783 - running_reg: 0.000000 - running_acc: 0.5566 - lr: 0.00031 - epoch_loss: 0.6779 - epoch_reg: 0.000000 - epoch_acc: 0.5691 - valid_loss: 0.6599 - valid_reg: 0.000000 - valid_acc: 0.5993 - epoch_time: 138.1718 s\n",
      "Epoch 44\n",
      "[====================] 100/100: - running_loss: 0.6677 - running_reg: 0.000000 - running_acc: 0.5704 - lr: 0.00031 - epoch_loss: 0.6710 - epoch_reg: 0.000000 - epoch_acc: 0.5612 - valid_loss: 0.6784 - valid_reg: 0.000000 - valid_acc: 0.5499 - epoch_time: 137.5138 s\n",
      "Epoch 45\n",
      "[====================] 100/100: - running_loss: 0.6749 - running_reg: 0.000000 - running_acc: 0.5789 - lr: 0.00032 - epoch_loss: 0.6661 - epoch_reg: 0.000000 - epoch_acc: 0.5619 - valid_loss: 0.6700 - valid_reg: 0.000000 - valid_acc: 0.5689 - epoch_time: 174.6494 s\n",
      "Epoch 46\n",
      "[====================] 100/100: - running_loss: 0.5740 - running_reg: 0.000000 - running_acc: 0.6884 - lr: 0.00033 - epoch_loss: 0.6104 - epoch_reg: 0.000000 - epoch_acc: 0.6581 - valid_loss: 0.7064 - valid_reg: 0.000000 - valid_acc: 0.5301 - epoch_time: 138.7443 s\n",
      "Epoch 47\n",
      "[====================] 100/100: - running_loss: 0.6307 - running_reg: 0.000000 - running_acc: 0.6410 - lr: 0.00034 - epoch_loss: 0.6156 - epoch_reg: 0.000000 - epoch_acc: 0.6600 - valid_loss: 0.6873 - valid_reg: 0.000000 - valid_acc: 0.5384 - epoch_time: 139.0500 s\n",
      "Epoch 48\n",
      "[====================] 100/100: - running_loss: 0.6613 - running_reg: 0.000000 - running_acc: 0.5914 - lr: 0.00034 - epoch_loss: 0.6314 - epoch_reg: 0.000000 - epoch_acc: 0.6166 - valid_loss: 0.6769 - valid_reg: 0.000000 - valid_acc: 0.5729 - epoch_time: 138.1832 s\n",
      "Epoch 49\n",
      "[====================] 100/100: - running_loss: 0.6879 - running_reg: 0.000000 - running_acc: 0.5599 - lr: 0.00035 - epoch_loss: 0.6584 - epoch_reg: 0.000000 - epoch_acc: 0.5984 - valid_loss: 0.6863 - valid_reg: 0.000000 - valid_acc: 0.5518 - epoch_time: 138.1792 s\n",
      "Epoch 50\n",
      "[====================] 100/100: - running_loss: 0.6620 - running_reg: 0.000000 - running_acc: 0.5906 - lr: 0.00036 - epoch_loss: 0.6627 - epoch_reg: 0.000000 - epoch_acc: 0.5903"
     ]
    }
   ],
   "source": [
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(5): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup()\n",
    "\n",
    "  checkpoint = train_model(model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, 75, 200)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = test(model, criterion, test_dataset)\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "096O0p87v1tL"
   },
   "outputs": [],
   "source": [
    "matching simple len norm: 6775, 6581, 6718, 6671, 6792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDRtrE7DmQ2L"
   },
   "outputs": [],
   "source": [
    "lops Simple len norm: 3710, 3730, 3715, 3745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "195OBZ0KV40u"
   },
   "outputs": [],
   "source": [
    "lops Simple len norm: 2040, 1975, 1970, 3215, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11l3-Q0xOfFH"
   },
   "outputs": [],
   "source": [
    "lops Simple: 0.1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzhAXdelDO3K"
   },
   "outputs": [],
   "source": [
    "lops 1 x OGLU: 0.1835, 0.1830, 0.1835, 0.1820, 0.1815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74SAO5c66OPS"
   },
   "outputs": [],
   "source": [
    "3 x AOGLU l=0.0: 0.6610, 0.6571, 0.6601, 0.6568, 0.6622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmO4BN8-gn7T"
   },
   "outputs": [],
   "source": [
    "FFN l=0.005: 0.6585, 0.6530, 0.6589, 0.6601, 0.6594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEIV04heCzdU"
   },
   "outputs": [],
   "source": [
    "FFN noorth: 0.6582, 0.6456, 0.6605, 0.6591, 0.5521, | 0.6580, 0.6530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGJ6X9biR032"
   },
   "outputs": [],
   "source": [
    "2 x OGLU l=0.1: 0.6596, 0.6591, 0.6578, 0.6635, 0.6601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZsyktpj_Ayo"
   },
   "outputs": [],
   "source": [
    "2 x OGLU l=0.01:0.6639, 0.6594, 0.6591, 0.6586, 0.6625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7_yUbfTdrCR",
    "outputId": "19835d4c-a559-424b-b274-cb1dea6d1ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fc6193882d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "process_inputs = lambda x: torch.Tensor(x.numpy()).to(torch.int64)\n",
    "\n",
    "list(model.blocks[-1].attention.lka.modules())[0][0].register_forward_hook(get_activation('1'))\n",
    "#list(model.blocks[-1].attention.lka.modules())[0][1].register_forward_hook(get_activation('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhQjEjjecyMN",
    "outputId": "e12c6dfc-e241-4711-c5f2-b54807d891e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': tensor([[[[0.4846, 0.6129, 1.0817,  ..., 0.8458, 0.8182, 0.6113],\n",
       "           [0.6741, 1.0226, 0.9306,  ..., 0.6382, 0.4864, 0.4956],\n",
       "           [0.7144, 0.7925, 0.9776,  ..., 0.8392, 0.8342, 0.6923],\n",
       "           ...,\n",
       "           [0.6351, 0.4956, 0.8323,  ..., 1.1306, 0.8587, 0.7959],\n",
       "           [0.6259, 1.0617, 0.9905,  ..., 0.7249, 0.8088, 0.8153],\n",
       "           [0.7734, 0.8578, 0.5455,  ..., 0.5648, 0.7239, 0.6971]],\n",
       " \n",
       "          [[1.1219, 0.8068, 0.7288,  ..., 0.5271, 1.1042, 0.6128],\n",
       "           [0.8955, 0.9000, 1.3224,  ..., 0.5096, 0.5674, 1.1289],\n",
       "           [0.7283, 0.8557, 0.4822,  ..., 0.8176, 0.3683, 0.6196],\n",
       "           ...,\n",
       "           [0.6962, 0.6160, 0.4413,  ..., 1.0298, 0.8417, 0.8641],\n",
       "           [1.0189, 0.9670, 0.5587,  ..., 0.9078, 0.7291, 0.7901],\n",
       "           [0.6431, 0.5184, 0.5831,  ..., 0.6299, 0.6459, 0.6050]],\n",
       " \n",
       "          [[0.6520, 0.8644, 0.8144,  ..., 0.5583, 0.4932, 0.5764],\n",
       "           [0.3789, 0.7886, 0.5084,  ..., 0.7604, 0.5583, 0.4504],\n",
       "           [0.8306, 0.9530, 0.6154,  ..., 0.7198, 0.6716, 0.8316],\n",
       "           ...,\n",
       "           [0.7072, 0.7885, 0.6645,  ..., 0.5373, 0.8313, 0.7544],\n",
       "           [0.9306, 0.6810, 0.7918,  ..., 0.8676, 0.8027, 0.7283],\n",
       "           [0.6329, 0.6154, 0.7098,  ..., 0.4776, 0.7722, 0.6611]],\n",
       " \n",
       "          [[0.7786, 0.9671, 0.7944,  ..., 0.6249, 0.8022, 0.5712],\n",
       "           [0.5801, 0.6983, 0.5575,  ..., 0.6784, 0.7260, 0.7423],\n",
       "           [0.7165, 0.7591, 0.9826,  ..., 0.4811, 0.4956, 0.8089],\n",
       "           ...,\n",
       "           [0.9886, 0.6557, 0.4287,  ..., 1.0515, 0.5590, 1.2194],\n",
       "           [0.8846, 0.6401, 0.7460,  ..., 0.5371, 0.7053, 0.6377],\n",
       "           [0.9957, 0.2716, 0.6007,  ..., 0.9580, 0.3327, 0.6476]]],\n",
       " \n",
       " \n",
       "         [[[0.8930, 0.6364, 0.6370,  ..., 0.6555, 0.5743, 0.8378],\n",
       "           [0.8831, 0.9794, 0.8412,  ..., 0.5675, 0.6064, 0.7537],\n",
       "           [0.8718, 0.6853, 0.8128,  ..., 0.8434, 0.6892, 0.5453],\n",
       "           ...,\n",
       "           [0.7026, 0.5422, 0.3716,  ..., 0.4875, 0.7247, 0.8934],\n",
       "           [1.2645, 0.7219, 0.6805,  ..., 0.7243, 1.0154, 0.7983],\n",
       "           [0.5913, 0.8728, 0.8055,  ..., 0.9002, 0.7161, 0.8851]],\n",
       " \n",
       "          [[0.4333, 0.6424, 0.4917,  ..., 0.6138, 0.8224, 1.0296],\n",
       "           [0.5902, 1.0217, 0.7909,  ..., 0.6172, 0.5229, 0.6886],\n",
       "           [0.9553, 0.6320, 0.3309,  ..., 1.1288, 0.4941, 0.7927],\n",
       "           ...,\n",
       "           [0.5305, 0.5709, 1.0517,  ..., 0.5401, 0.4635, 1.2611],\n",
       "           [0.5408, 0.6843, 1.0863,  ..., 0.7544, 0.3629, 0.8321],\n",
       "           [0.7382, 0.7683, 0.7612,  ..., 0.7868, 0.5918, 0.5935]],\n",
       " \n",
       "          [[0.7341, 0.9329, 1.0449,  ..., 0.8102, 1.0817, 0.8769],\n",
       "           [0.6250, 0.6260, 0.9342,  ..., 0.7469, 0.5003, 0.5282],\n",
       "           [0.6004, 0.5281, 1.0101,  ..., 0.8523, 0.6920, 0.7553],\n",
       "           ...,\n",
       "           [0.9517, 0.9641, 0.9220,  ..., 0.4221, 0.4426, 0.8048],\n",
       "           [0.4548, 0.5333, 0.5736,  ..., 1.1812, 0.5742, 0.6966],\n",
       "           [0.7830, 0.4640, 0.5448,  ..., 0.6196, 0.5784, 0.7986]],\n",
       " \n",
       "          [[0.7263, 0.8433, 0.6435,  ..., 0.6081, 0.9357, 1.0626],\n",
       "           [0.3649, 0.7983, 0.5728,  ..., 0.4686, 0.9862, 0.7960],\n",
       "           [0.6301, 0.7797, 0.4217,  ..., 0.6837, 0.6317, 0.9112],\n",
       "           ...,\n",
       "           [0.5928, 0.6314, 0.7262,  ..., 0.6301, 0.5901, 1.0862],\n",
       "           [0.5278, 0.4373, 0.4281,  ..., 0.7741, 0.5059, 1.1810],\n",
       "           [0.5299, 0.4793, 0.6697,  ..., 0.5519, 0.4068, 0.5940]]],\n",
       " \n",
       " \n",
       "         [[[0.5173, 0.4609, 0.3646,  ..., 0.7049, 0.8529, 1.0608],\n",
       "           [0.8809, 0.4967, 0.6903,  ..., 0.6765, 0.4130, 0.8474],\n",
       "           [0.4907, 0.7993, 0.4250,  ..., 0.7400, 0.7169, 0.8319],\n",
       "           ...,\n",
       "           [0.7427, 0.6648, 0.7337,  ..., 0.6867, 0.7303, 0.6022],\n",
       "           [0.9273, 0.7987, 1.1405,  ..., 0.6633, 0.4618, 0.4035],\n",
       "           [0.7829, 0.7052, 0.7513,  ..., 0.7967, 0.3077, 0.5792]],\n",
       " \n",
       "          [[0.5744, 0.5170, 0.5111,  ..., 0.6387, 1.4359, 0.6881],\n",
       "           [0.5406, 0.7437, 0.6796,  ..., 0.6085, 0.3997, 0.6651],\n",
       "           [0.9269, 0.7365, 0.6759,  ..., 0.4442, 0.9492, 0.7859],\n",
       "           ...,\n",
       "           [0.5625, 1.0477, 0.6989,  ..., 0.3193, 0.9648, 0.9948],\n",
       "           [0.8559, 0.5630, 0.6819,  ..., 0.7938, 1.0081, 0.7846],\n",
       "           [0.7721, 0.6051, 0.9171,  ..., 0.8199, 0.5124, 0.6793]],\n",
       " \n",
       "          [[0.5939, 0.7135, 0.6993,  ..., 0.8693, 0.7109, 0.4790],\n",
       "           [1.2267, 0.5138, 0.8688,  ..., 0.6919, 0.4456, 1.1771],\n",
       "           [0.8001, 0.5119, 0.4499,  ..., 0.7845, 1.0466, 0.6150],\n",
       "           ...,\n",
       "           [0.9662, 0.5447, 0.5725,  ..., 0.7900, 0.4642, 0.8714],\n",
       "           [0.6128, 1.4435, 1.0496,  ..., 0.4937, 0.8764, 0.7703],\n",
       "           [1.1477, 0.4474, 1.1052,  ..., 0.4511, 0.7057, 1.1471]],\n",
       " \n",
       "          [[0.5751, 0.7363, 0.5543,  ..., 1.2802, 1.0292, 0.9101],\n",
       "           [0.8339, 0.7821, 0.4958,  ..., 0.6689, 0.7094, 1.2240],\n",
       "           [0.6334, 0.6162, 1.0532,  ..., 0.5831, 0.9784, 0.4457],\n",
       "           ...,\n",
       "           [0.9673, 0.5089, 0.5119,  ..., 0.7646, 0.6643, 0.6362],\n",
       "           [0.6229, 0.8128, 0.6808,  ..., 0.8241, 0.7474, 0.5344],\n",
       "           [0.5732, 0.8781, 0.8293,  ..., 0.5295, 0.3167, 0.6894]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.5139, 0.9585, 0.7048,  ..., 0.4706, 1.1845, 0.8306],\n",
       "           [0.6485, 0.6921, 0.7455,  ..., 0.8412, 0.9490, 0.7054],\n",
       "           [0.8574, 0.5853, 0.8126,  ..., 0.8271, 0.9612, 0.7024],\n",
       "           ...,\n",
       "           [0.8571, 0.9179, 1.1562,  ..., 1.0475, 0.6699, 0.6514],\n",
       "           [0.5395, 0.8354, 0.7111,  ..., 0.8484, 0.9584, 0.6190],\n",
       "           [0.8390, 0.5624, 0.5619,  ..., 0.7656, 0.6843, 0.4733]],\n",
       " \n",
       "          [[1.1947, 0.8580, 0.8976,  ..., 0.7886, 0.7540, 0.7705],\n",
       "           [0.8955, 0.8698, 0.7398,  ..., 0.6024, 0.6055, 0.7405],\n",
       "           [0.5969, 0.4527, 0.7469,  ..., 0.5325, 0.7581, 0.8009],\n",
       "           ...,\n",
       "           [0.6167, 0.6102, 0.5931,  ..., 0.9055, 1.1287, 0.8764],\n",
       "           [0.8777, 0.9808, 0.7232,  ..., 0.9431, 0.2721, 0.6570],\n",
       "           [0.5581, 0.4597, 0.7226,  ..., 0.7046, 0.5034, 0.6325]],\n",
       " \n",
       "          [[0.6878, 0.8854, 0.5886,  ..., 0.6195, 0.8855, 0.6604],\n",
       "           [0.7996, 0.5236, 0.8830,  ..., 0.6311, 0.6650, 0.7740],\n",
       "           [0.5857, 0.6802, 0.6618,  ..., 0.4279, 0.5291, 0.7272],\n",
       "           ...,\n",
       "           [0.6958, 0.6722, 0.4040,  ..., 0.7566, 0.5490, 0.2878],\n",
       "           [0.6755, 0.7320, 0.6415,  ..., 0.5381, 0.8886, 1.0171],\n",
       "           [0.7361, 0.7721, 0.8607,  ..., 0.8243, 0.6769, 0.7289]],\n",
       " \n",
       "          [[0.5134, 1.0933, 0.5616,  ..., 0.5353, 0.6832, 0.6531],\n",
       "           [0.7765, 0.6428, 0.7305,  ..., 0.3585, 0.7072, 0.5546],\n",
       "           [0.8771, 0.5484, 0.7344,  ..., 0.6258, 0.7448, 0.3164],\n",
       "           ...,\n",
       "           [0.6185, 0.7809, 1.2525,  ..., 0.9899, 0.4716, 0.6864],\n",
       "           [0.8044, 0.7140, 0.3929,  ..., 0.5716, 0.2625, 0.5923],\n",
       "           [0.7273, 0.9700, 0.7583,  ..., 0.4546, 0.6063, 0.9399]]],\n",
       " \n",
       " \n",
       "         [[[0.4228, 0.8486, 0.9001,  ..., 0.6750, 0.6145, 0.3459],\n",
       "           [0.9708, 0.7545, 0.9327,  ..., 0.6346, 0.7672, 0.7432],\n",
       "           [0.7026, 0.8030, 0.7853,  ..., 0.5845, 0.6818, 0.5152],\n",
       "           ...,\n",
       "           [0.8206, 0.4788, 1.2461,  ..., 0.7114, 0.4759, 0.6254],\n",
       "           [0.6418, 0.6923, 0.8943,  ..., 0.7203, 0.6995, 0.7107],\n",
       "           [0.6397, 0.5745, 1.0160,  ..., 0.8132, 0.7279, 0.5532]],\n",
       " \n",
       "          [[0.7658, 0.6374, 0.7984,  ..., 0.7095, 0.7758, 0.7840],\n",
       "           [0.7832, 0.4628, 0.3681,  ..., 0.7452, 0.7778, 0.7669],\n",
       "           [0.7413, 0.6951, 0.5761,  ..., 1.0948, 0.4968, 0.4787],\n",
       "           ...,\n",
       "           [0.9395, 1.0545, 0.6344,  ..., 0.7220, 0.4989, 0.7187],\n",
       "           [0.7035, 0.8188, 0.5433,  ..., 0.7804, 0.5496, 0.5223],\n",
       "           [0.8402, 0.7453, 0.3474,  ..., 0.6197, 0.7948, 0.6134]],\n",
       " \n",
       "          [[0.3603, 1.1036, 0.5891,  ..., 0.8252, 0.4258, 0.3955],\n",
       "           [0.7111, 0.9473, 0.4409,  ..., 0.8261, 0.5765, 0.4974],\n",
       "           [0.6300, 0.8217, 1.0144,  ..., 0.9546, 1.1750, 1.1056],\n",
       "           ...,\n",
       "           [0.8961, 0.4505, 0.7297,  ..., 0.8524, 0.4372, 1.0410],\n",
       "           [0.7747, 0.5040, 0.6784,  ..., 0.5566, 1.1498, 0.7962],\n",
       "           [0.6596, 1.1634, 0.4957,  ..., 0.7880, 0.5380, 0.6310]],\n",
       " \n",
       "          [[0.5279, 0.7320, 0.9941,  ..., 0.8691, 1.0518, 0.7016],\n",
       "           [0.7898, 0.6883, 0.5457,  ..., 0.3695, 0.5490, 0.7430],\n",
       "           [0.5119, 0.8078, 0.5855,  ..., 0.5621, 0.9829, 0.7496],\n",
       "           ...,\n",
       "           [0.5684, 1.1142, 0.7967,  ..., 0.5090, 0.4609, 0.7501],\n",
       "           [0.4333, 0.6514, 0.8165,  ..., 0.9520, 0.8970, 1.1366],\n",
       "           [0.4308, 0.3284, 0.8361,  ..., 0.8206, 1.0035, 0.4980]]],\n",
       " \n",
       " \n",
       "         [[[0.7467, 0.6446, 0.5154,  ..., 0.5798, 0.6406, 1.1936],\n",
       "           [0.4474, 0.9590, 0.5592,  ..., 0.7921, 0.7791, 0.6336],\n",
       "           [0.9450, 0.5910, 0.7239,  ..., 0.7865, 0.7471, 0.5572],\n",
       "           ...,\n",
       "           [0.5536, 0.6727, 1.0070,  ..., 0.6674, 1.2189, 0.7011],\n",
       "           [0.4842, 0.5871, 0.6954,  ..., 0.7043, 0.9860, 0.7895],\n",
       "           [0.7020, 0.7433, 0.8664,  ..., 0.5529, 0.7889, 0.8005]],\n",
       " \n",
       "          [[0.7196, 0.3207, 0.9218,  ..., 0.6925, 0.9509, 0.4740],\n",
       "           [0.9858, 1.0358, 0.5459,  ..., 0.9464, 0.4016, 0.5775],\n",
       "           [0.7281, 0.9938, 0.8871,  ..., 0.6001, 0.8402, 1.0374],\n",
       "           ...,\n",
       "           [0.8533, 1.0131, 0.5425,  ..., 0.8832, 0.4754, 0.7555],\n",
       "           [0.7653, 1.0432, 0.6744,  ..., 0.5842, 0.7185, 0.8080],\n",
       "           [0.4853, 0.7610, 0.5558,  ..., 0.8416, 0.6044, 0.9784]],\n",
       " \n",
       "          [[0.6224, 1.0267, 0.9031,  ..., 0.6286, 0.7636, 0.6316],\n",
       "           [0.9949, 0.5400, 0.3923,  ..., 0.7494, 0.4017, 0.5003],\n",
       "           [1.2642, 0.4963, 0.8992,  ..., 0.8460, 1.0868, 1.3053],\n",
       "           ...,\n",
       "           [0.6211, 0.5373, 0.8102,  ..., 0.8368, 0.7892, 1.0315],\n",
       "           [0.5378, 0.6785, 0.8107,  ..., 0.6532, 0.7171, 0.5774],\n",
       "           [0.8034, 0.6444, 0.9854,  ..., 0.5444, 0.5273, 0.7480]],\n",
       " \n",
       "          [[0.6030, 0.6670, 0.5706,  ..., 0.5578, 0.6974, 0.9863],\n",
       "           [0.8439, 0.4847, 0.7106,  ..., 0.5610, 0.7778, 0.4506],\n",
       "           [0.7859, 0.3478, 1.0372,  ..., 0.7525, 1.0591, 0.2940],\n",
       "           ...,\n",
       "           [0.6795, 0.5807, 0.8654,  ..., 0.8432, 0.8197, 0.6898],\n",
       "           [0.9770, 0.5094, 0.6678,  ..., 0.7466, 0.6382, 0.5085],\n",
       "           [0.5039, 0.6764, 0.6206,  ..., 0.7895, 1.3537, 0.8089]]]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(process_inputs(next(iter(train_dataset))['inputs']).cuda())\n",
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wE_DENScSGHL",
    "outputId": "f1b8fb1d-a8a5-45a4-eb9b-07bdd2c8f3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 3464194 params, new model 3663874 params, ratio 1.06\n"
     ]
    }
   ],
   "source": [
    "model, criterion, _, _, _ = training_setup()\n",
    "tmp = next(iter(train_dataset))\n",
    "outputs, aux_losses = model(process_inputs(tmp['inputs']).cuda())\n",
    "\n",
    "aux_losses = sum(aux_losses)\n",
    "(criterion(outputs, process_inputs(tmp['targets']).cuda()) + aux_losses).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_XSqOYYTsDT",
    "outputId": "c9a66ce8-a2e3-4f96-f423-7240192ad3e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-2.6187e-03, -5.7948e-04, -3.2907e-04,  6.2941e-04, -7.1119e-04,\n",
       "           -4.3961e-04,  2.6415e-03,  9.3061e-04,  2.9606e-03, -2.6636e-04,\n",
       "           -1.7387e-03,  1.6021e-03,  9.3624e-04,  1.1273e-03, -3.3982e-04,\n",
       "           -4.0739e-04, -2.0149e-03,  9.0991e-04, -1.0498e-03, -2.7959e-03,\n",
       "            2.5112e-04, -9.3633e-04,  6.2485e-04, -1.3612e-03, -2.9829e-04,\n",
       "           -2.0080e-04,  7.8189e-04,  7.8589e-04, -5.3443e-03, -3.7092e-03,\n",
       "           -2.3028e-04,  3.1588e-03, -2.2930e-04,  3.9736e-03,  4.0218e-04,\n",
       "            1.0651e-03,  7.7839e-03,  1.8654e-04, -3.1373e-03,  1.4372e-03,\n",
       "            4.1014e-03, -1.0334e-03, -8.9334e-04, -2.3530e-04, -1.0687e-03,\n",
       "           -2.1504e-03, -1.1092e-03,  1.7172e-05,  1.2050e-03, -1.5283e-03,\n",
       "            1.4103e-04, -2.1979e-03, -5.9292e-05,  2.5531e-03, -4.6291e-03,\n",
       "            8.9993e-04,  5.3557e-05, -1.8944e-03,  6.1842e-04, -3.0434e-03,\n",
       "           -2.6042e-03, -2.7910e-03,  1.9914e-03,  3.3585e-03]],\n",
       "\n",
       "         [[ 2.7830e-03,  6.5157e-04,  1.3587e-03,  2.6377e-03,  2.6050e-03,\n",
       "            1.3299e-04, -1.4192e-03,  4.3132e-04,  1.1622e-03,  1.8455e-03,\n",
       "           -6.5035e-03,  3.9105e-03,  3.6151e-03, -3.1340e-04, -1.1248e-03,\n",
       "           -9.3471e-03, -1.1168e-03, -1.2783e-03,  1.4718e-03, -1.7144e-03,\n",
       "           -1.5742e-03, -2.5472e-03, -3.9025e-04, -7.1958e-03,  2.0620e-03,\n",
       "            1.1221e-03,  4.0981e-03, -3.0099e-03, -2.8092e-03,  1.3933e-03,\n",
       "            1.2233e-03, -2.4611e-03, -7.4985e-03,  2.3598e-03,  1.5210e-04,\n",
       "            2.4839e-03, -1.8429e-03, -2.0700e-05,  2.3278e-03,  1.8919e-03,\n",
       "           -1.5871e-03, -5.1121e-03, -2.0640e-03, -5.9370e-03, -4.9204e-03,\n",
       "           -9.9108e-03, -1.5696e-03, -8.8422e-04, -2.8757e-03, -1.3572e-03,\n",
       "            3.9639e-04,  1.5128e-03, -8.5317e-04, -2.9370e-03, -1.1195e-03,\n",
       "            2.7233e-03, -4.3108e-03, -3.5303e-03,  2.7051e-03,  2.5042e-03,\n",
       "            7.5812e-04,  6.9706e-03, -1.0707e-03,  1.2404e-03]],\n",
       "\n",
       "         [[-3.8659e-03,  1.0261e-02,  2.7044e-03,  1.9696e-03, -1.4937e-04,\n",
       "           -5.3674e-03,  2.8987e-04,  5.6101e-04,  2.4013e-03,  1.1758e-03,\n",
       "           -3.7829e-03, -3.6720e-03,  5.8277e-04, -1.9636e-03,  3.7169e-03,\n",
       "            2.5876e-04, -5.9365e-03, -1.8047e-03,  3.1761e-03, -3.4872e-03,\n",
       "            2.8748e-03, -2.8431e-03,  6.1902e-03,  5.2007e-03,  6.6551e-03,\n",
       "            4.4296e-04,  3.4092e-04,  1.0645e-03,  8.4146e-03,  3.3517e-03,\n",
       "            4.8221e-03,  3.3170e-03, -3.9772e-05, -5.3822e-03, -1.1954e-03,\n",
       "           -2.6741e-05, -3.7010e-03,  4.8294e-03, -1.1520e-04, -1.9767e-04,\n",
       "           -6.4628e-03, -5.5500e-04,  3.8438e-03, -1.9857e-03,  3.4086e-03,\n",
       "            1.0389e-04,  3.8679e-03, -5.5254e-03, -1.2043e-03,  2.0952e-03,\n",
       "           -2.3705e-03,  5.6132e-03,  3.6401e-03, -5.2342e-03, -3.7908e-04,\n",
       "            1.2614e-03, -2.6454e-03, -4.1037e-03,  4.6147e-04,  3.8222e-03,\n",
       "            3.9316e-03,  1.1161e-03, -1.8010e-03, -9.9954e-03]],\n",
       "\n",
       "         [[ 8.1668e-04,  1.3635e-03,  4.4353e-04, -2.8064e-03,  2.3828e-04,\n",
       "            1.7759e-03,  2.0466e-04, -1.8902e-03,  2.3943e-04, -1.3520e-03,\n",
       "            2.3867e-03, -1.2658e-03, -1.5047e-03,  1.0777e-03, -4.2223e-03,\n",
       "            1.9186e-03, -2.0456e-03,  7.1799e-04,  5.4871e-04,  1.6659e-04,\n",
       "           -2.3044e-03, -3.2187e-03,  1.3099e-03, -1.5698e-03, -1.4281e-03,\n",
       "            2.3084e-03, -3.8172e-04, -1.0892e-03,  1.9725e-04, -1.0847e-03,\n",
       "            7.4281e-05, -9.6833e-04, -2.6583e-03, -1.4236e-03, -4.5038e-03,\n",
       "           -4.5519e-06, -1.1274e-03,  4.4086e-04,  8.0243e-05,  2.8444e-03,\n",
       "            1.6535e-03,  5.1128e-04,  1.4300e-03,  4.1248e-03, -3.1418e-03,\n",
       "           -4.7238e-03,  1.9891e-03,  2.6389e-03, -1.0230e-03, -1.4871e-03,\n",
       "            3.6018e-03,  1.1650e-03,  3.4906e-04,  1.1271e-04,  9.0374e-04,\n",
       "           -1.7273e-03,  3.5433e-05, -3.7748e-05, -1.9616e-03, -1.0358e-03,\n",
       "           -2.2366e-03, -3.8164e-04, -2.1304e-04,  7.8375e-04]]]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.blocks[-1].attention.lka.modules())[0][0].output_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJI-xf2xaLqc"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bpe_matching_setup_simple_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
