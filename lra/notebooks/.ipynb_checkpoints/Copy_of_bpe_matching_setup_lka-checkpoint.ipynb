{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0_XMgEPOh7c",
    "outputId": "c950e7a3-986c-4235-a191-c529c223ece0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 26 20:31:25 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    44W / 350W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGGnygXCDXLf",
    "outputId": "4b259c3e-a4ca-4cfd-8f73-32264eeddc46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'long-range-arena'...\n",
      "remote: Enumerating objects: 474, done.\u001b[K\n",
      "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 474 (delta 145), reused 137 (delta 137), pack-reused 316\u001b[K\n",
      "Receiving objects: 100% (474/474), 145.27 KiB | 6.32 MiB/s, done.\n",
      "Resolving deltas: 100% (328/328), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/long-range-arena.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrMqZQQmd-vh",
    "outputId": "af34b2be-c105-4c70-f626-e8f5e27d8bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:45tcmalloc: large alloc 1147494400 bytes == 0x39fb0000 @  0x7fa71fd9f615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:26tcmalloc: large alloc 1434370048 bytes == 0x7e606000 @  0x7fa71fd9f615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:31tcmalloc: large alloc 1792966656 bytes == 0x3438000 @  0x7fa71fd9f615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:45tcmalloc: large alloc 2241208320 bytes == 0x6e220000 @  0x7fa71fd9f615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf3b82000 @  0x7fa71fd9e1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
      "tcmalloc: large alloc 2551644160 bytes == 0x1e1ac6000 @  0x7fa71fd9f615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
      "\u001b[K     |████████████████████████████████| 2041.3 MB 8.0 kB/s \n",
      "\u001b[?25hCollecting torchvision==0.10.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 1.0 MB/s \n",
      "\u001b[?25hCollecting torchaudio==0.9.1\n",
      "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1+cu111) (4.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (1.21.6)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1+cu111) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.11.0+cu113\n",
      "    Uninstalling torchaudio-0.11.0+cu113:\n",
      "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1+cu111 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.1+cu111 torchaudio-0.9.1 torchvision-0.10.1+cu111\n"
     ]
    }
   ],
   "source": [
    "#Execute if A100 is the current GPU\n",
    "\n",
    "!pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24NuIzxvRyHo",
    "outputId": "62aa9dd2-872d-4877-b4a3-31cffc356b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-26 20:34:34--  https://storage.googleapis.com/long-range-arena/lra_release.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 108.177.13.128, 74.125.31.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8288700910 (7.7G) [application/octet-stream]\n",
      "Saving to: ‘lra_release.gz’\n",
      "\n",
      "lra_release.gz      100%[===================>]   7.72G   151MB/s    in 58s     \n",
      "\n",
      "2022-04-26 20:35:33 (136 MB/s) - ‘lra_release.gz’ saved [8288700910/8288700910]\n",
      "\n",
      "Collecting tensorflow_text\n",
      "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.44.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.24.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.14.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 76.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n",
      "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
      "Successfully installed tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/long-range-arena/lra_release.gz\n",
    "!gzip -d lra_release.gz\n",
    "!tar -xf lra_release\n",
    "\n",
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATXw-aRr0sg-",
    "outputId": "c0091a54-50ab-40e7-ac1e-c0bbf07048a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/long-range-arena\n",
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.train.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.eval.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.eval.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.test.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/lra_release/lra_release/tsv_data/new_aan_pairs.test.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    }
   ],
   "source": [
    "%cd /content/long-range-arena\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lra_benchmarks.matching.input_pipeline import get_matching_datasets\n",
    "\n",
    "batch_size=4\n",
    "accumulation_steps=32 // batch_size\n",
    "max_length=4000\n",
    "\n",
    "LAMBDA = 0.0\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset, encoder = get_matching_datasets(1, None, tokenizer='char', data_dir='/content/lra_release/lra_release/tsv_data', batch_size=batch_size, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Ec_MO12HhV",
    "outputId": "7034eaff-89ec-4a60-fd1b-77f5d617835a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1 Introduction  Part-of-speech (POS) tagging aims to assign each  word in a sentence with a proper tag indicating its  POS category. While a number of successful POS  tagging systems have been available for English  and many other languages, it is still a challenge to  develop a practical POS tagger for Chinese due to  its language-specific issues. Firstly, Chinese words  do not have a strict one-to-one correspondence between their POS categories and functions in a sentence. Secondly, an ambiguous Chinese word can  act as different POS categories in different contexts without changing its form. Thirdly, there are  many out-of-vocabulary (OOV) words in real Chinese text whose POS categories are not defined in  the dictionary used. All these factors make it much  more difficult to achieve a high-performance POS  tagger for Chinese.  Recent studies in Chinese POS tagging focus on  statistical or machine learning approaches with  either characters or words as basic units for tagging  (Ng and Low, 2004; Fu and Luke, 2006). Very  little research has been devoted to resolving Chinese POS tagging problems based on morphemes.  In our system, we prefer morphemes to characters  or words as tagging units for three reasons. First,  words are made of morphemes instead of characters (Wu and Tseng, 1995; Packard, 2000). Second, most morphemes are productive in word formation (Baayen, 1989; Sproat and Shih, 2002; Nishimoto, 2003), particularly in the formation of  morphologically-derived words (MDWs) and  proper nouns, which are the major source of OOV  words in Chinese texts. Third, Packard (2000) indicates that Chinese do have morphology. Moreover, morphology proves to be a very informative  cue for predicting POS categories of Chinese OOV  words (Tseng et al 2005).  Therefore, we believe  that a morpheme-based framework would be more  effective than the character- or word-based ones in  capturing both word-internal morphological features and word-external contextual information for  Chinese POS disambiguation and unknown word  guessing (UWG) as well.  Thus we present a morpheme-based POS tagger  for Chinese in this paper. It consists of two main  components, namely a morpheme segmentation  component for segmenting each word in a sentence  into a sequence of morphemes, based on the forward maximum matching (FMM) technique, and a  lexical tagging component for labeling each segmented morpheme with a proper tag indicating its  position pattern in forming a word of a specific  type, based on lexicalized hidden Markov models  (HMMs). Lack of a large morphological knowl124 Sixth SIGHAN Workshop on Chinese Language Processing edge base is a major obstacle to Chinese morphological analysis (Tseng and Chen, 2002). To overcome this problem and to facilitate morphemebased POS tagging as well, we have also developed a statistically-based technique for automatically extracting morphemes from POS-tagged corpora. We participated in four closed tracks for POS  tagging at the Fourth International Chinese Language Processing Bakeoff sponsored by the ACLSIGHAN and tested our system on different testing corpora. In this paper, we also made a summary of  this work and give some brief analysis on the results.  The rest of this paper is organized as follows:  Section 2 is a brief description of our system. Section 3 details the settings of our system for different testing tracks and presents the scored results of  our system at this bakeoff. Finally, we give our  conclusions in Section 4.  2 System Description  2.1 Chinese Morphemes  In brief, Chinese morphemes can be classified  into free morphemes and bound morphemes. A  free morpheme can stand by itself as a word (viz. a  basic word), whereas a bound morpheme can show  up if and only if being attached to other  morphemes to form a word. Free morphemes can  be subdivided into true free morphemes and  pseudo free morphemes. A pseudo free morpheme  ??such as  ran2-er2 ?however? can only stand  alone, while a tr\n",
      "b'1 Introduction Parallel corpora?texts and their translations? have become essential in the development of machine translation (MT) systems. Alignment quality is crucial to these corpora; as Tiedemann (2003) states, ?[t]he most important feature of texts and their translations is the correspondence between source and target segments? (p. 2). While being useful for translation studies and foreign language pedagogy (see, e.g., Botley et al, 2000; McEnery and Wilson, 1996), PARALLEL TREEBANKS?syntactically-annotated parallel corpora?offer additional useful information for machine translation, cross-language information retrieval, and word-sense disambiguation (see, e.g., Tiedemann, 2003), While high-quality alignments are desirable, even gold standard annotation can contain annotation errors. For other forms of linguistic annotation, the presence of errors has been shown to create various problems, from unreliable training and evaluation of NLP technology (e.g., Padro and Marquez, 1998) to low precision and recall of queries for already rare linguistic phenomena (e.g., Meurers and Mu?ller, 2008). Even a small number of errors can have a significant impact on the uses of linguistic annotation, e.g., changing the assessment of parsers (e.g., Habash et al, 2007). One could remove potentially unfavorable sentence pairs when training a statistical MT system, to avoid incorrect word alignments (Okita, 2009), but this removes all relevant data from those sentences and does not help evaluation. We thus focus on detecting errors in the annotation of alignments. Annotation error detection has been explored for part-of-speech (POS) annotation (e.g., Loftsson, 2009) and syntactic annotation (e.g., Ule and Simov, 2004; Dickinson and Meurers, 2005), but there have been few, if any, attempts to develop general approaches to error detection for aligned corpora. Alignments are different in nature, as the annotation does not introduce abstract categories such as POS, but relies upon defining translation units with equivalent meanings. We use the idea that variation in annotation can indicate errors (section 2), for consistency checking of alignments, as detailed in section 3. In section 4, we outline language-independent heuristics to sort true ambiguities from errors, and evaluate them on a parallel treebank in section 5. In section 6 we turn to a complementary method, exploiting compositional properties of aligned treebanks, to align more nodes. The methods are simple, effective, and applicable to any aligned treebank. As far as we know, this is the first attempt to thoroughly investigate and empirically verify error detection methods for aligned corpora. 38 2 Background 2.1 Variation N -gram Method As a starting point for an error detection method for aligned corpora, we use the variation n-gram approach for syntactic annotation (Dickinson and Meurers, 2003, 2005). The approach is based on detecting strings which occur multiple times in the corpus with varying annotation, the so-called VARIATION NUCLEI. The nucleus with repeated surrounding context is referred to as a VARIATION n-GRAM. The basic heuristic for detecting annotation errors requires one word of recurring context on each side of the nucleus, which is sufficient for detecting errors in grammatical annotation with high precision (Dickinson, 2008). The approach detects bracketing and labeling errors in constituency annotation. For example, the variation nucleus last month occurs once in the Penn Treebank (Tayloret al, 2003) with the label NP and once as a non-constituent, handled through a special label NIL. As a labeling error example, next Tuesday occurs three times, twice as NP and once as PP (Dickinson and Meurers, 2003). The method works for discontinuous constituency annotation (Dickinson and Meurers, 2005), allowing one to apply it to alignments, which may span over several words. 2.2 Parallel Treebank Consistency Checking For the experiments in this paper we will use the SMULT\n",
      "\n",
      "b'1 Introduction Supervised classification is the task of assigning category labels, taken from a predefined set of categories (classes), to instances in a data set. Within the classical supervised learning paradigm, the task is approached by providing a learning algorithm with a training data set of manually labeled examples. In practice it is not always easy to apply this schema to NLP tasks. For example supervised systems for Text Categorization (TC) require a large amount of hand labeled texts, while in many applicative cases it is quite difficult to collect the required amounts of hand labeled data. Unlabeled text collections, on the other hand, are in general easily available. An alternative approach is to provide the necessary supervision by means of sets of ?seeds? of intuitively relevant features. Adopting terminology from computability theory, we refer to the standard example-based supervision mode as Extensional Learning (EL), as classes are being specified by means of examples of their elements (their extension). Feature-based supervision is referred to as Intensional Learning (IL), as features may often be perceived as describing the intension of a category, such as providing the name or prominent key terms for a category in text categorization. The IL approach reflects on classical rule-based classification methods, where the user is expected to specify exact classification rules that operate in the feature space. Within the machine learning paradigm, IL has been incorporated as a technique for bootstrapping an extensional learning algorithm, as in (Yarowsky, 1995; Collins and Singer, 1999; Liu et al, 2004). This way the user does not need to specify exact classification rules (and feature weights), but rather perform a somewhat simpler task of specifying few typical seed features for the category. Given the list of seed features, the bootstrapping scheme consists of (i) preliminary unsupervised categorization of the unlabeled data set based on the seed features, and (ii) training an (extensional) supervised classifier using the automatic classification labels of step (i) as the training data (the second step is possibly reiterated, such as by an Expectation-Maximization schema). The core part of IL bootstrapping is step (i), i.e. the initial unsupervised classification of the unlabeled dataset. This step was often approached by relatively simple methods, which are doomed to obtain mediocre quality. Even so, it is hoped that the second step of supervised training would be robust enough to the noise in the initial training set. 129 The goal of this paper is to investigate additional principled unsupervised mechanisms within the initial classification step, applied to the text categorization. In particular, (a) utilizing a Latent Semantic Space to obtain better similarity assessments between seeds and examples, and (b) applying a Gaussian Mixture (GM) algorithm, which provides a principled unsupervised estimation of classification probability. As shown in our experiments, incorporating these steps consistently improved the accuracy of the initial categorization step, which in turn yielded a better final classifier thanks to the more accurate training set. Most importantly, we obtained comparable or better performance than previous IL methods using only the category names as the seed features; other IL methods required collecting alarger number of seed terms, which turns out to be a somewhat tricky task. Interesting results were revealed when comparing our IL method to a state-of-the-art extensional classifier, trained on manually labeled documents. The EL classifier required 70 (Reuters dataset) or 160 (Newsgroup dataset) documents per category to achieve the same performance that IL obtained using only the category names. These results suggest that IL may provide an appealing cost-effective alternative when sub-optimal accuracy suffices, or when it is too costly or impractical to obtain sufficient labeled training\n",
      "b'Introduction  With the rapid growth of the internet, the  availability of on-line text information has been  considerably increased. As a result, text  categorization has become one of the key  techniques fox handling and organizing text data.  Automatic text categorization in the previous  works is a supervised learning task, defined as  assigning category labels (pro-defined) to text  documents based on the likelihood suggested by  a training set of labeled doculnents. However,  the previous learning algorithms have some  problems. One of them is that they require a  large, often prohibitive, number of labeled  training documents for the accurate learning.  Since the application area of automatic text  categorization has diversified froln newswire  articles and web pages to electronic mails and  newsgroup postings, it is a difficult task to  create training data for each application area  (Nigam K. et al, 1998).  In this paper, we propose a new automatic text  categorization lnethod based on unsupervised  learning. Without creating training documents  by hand, it automatically creates training  sentence sets using keyword lists of each  category. And then, it uses them for training and  classifies text documents. The proposed method  can provide basic data fox\" creating training  doculnents from collected documents, and can  be used in an application area to classify text  documents in low cost. We use the 2 / statistic  (Yang Y. et al, 1998) as a feature selection  method and the naive Bayes classifier  (McCailum A. et al, 1998) as a statistical text  classifier. The naive Bayes classifier is one of  the statistical text classifiers that use word  frequencies as features. Other examples include  k-nearest-neighbor (Yang Y. et al, 1994),  TFIDF/Roccio (Lewis D.D. et al, 1996),  support vector machines (Joachilns T. et al,  1998) and decision tree (Lewis D.D. et al,  1994).  1 Proposal: A text categorization scheme  The proposed system consists of three modules  as shown in Figure 1; a module to preprocess  collected ocuments, a module to create training  sentence sets, and a module to extract features  and to classify text doculnents.  453  ............. 1\\\\]  i  J  Text (~  /  / \"  ,L\\',.~g,,r}  i, I )  .1  .l&ll ego 13\\',  Ax~J~llJll~ \\', /,  I( \",\\'11 ello I\\'1\\\\]  Figurel : Architecture for the proposed system  1.1 Preprocessing  First, the html tags and special characters in the  collected ocuments are removed. And then, the  contents of the documents are segmented into  sentences. We extract content words for each  sentence using only nouns. In Korean, there are  active-predicative common nouns which become  verbs when they am combined with verb-  derivational suffixes (e.g., ha-ta \\'do\\', toy-la  \\'become\\', etc.). There are also stative-  predicative common nouns which become  adjectives when they are combined with adjective-derivational suffixes such as ha. These  derived verbs and adjectives are productive in  Korean, and they are classified as nouns  according to the Korean POS tagger. Other  verbs and adjectives are not informative in many  cases.  1.2 Creating training sentence sets  Because the proposed system does not have  training documents, training sentence sets for  each category corresponding to the training  documents have to be created. We define  keywords for each category by hand, which  contain special features of each category  sufficiently. To choose these keywords, we first  regard category names and their synonyms as  keywords. And we include several words that  have a definite meaning of each category. The  average number of keywords for each category  is 3. (Total 141 keywords for 47 categories)  Table 1 lists the examples of keywords for  each category.  Table 1: Examples of keywords for each category  Category Keywords  ye-hayng (trip),  kwan-kwang  (sightseeing)  Um-ak(music)  Cong-kyo  (religion)  Pang-song  (broadcasting)  ye-hayng (trip),  kwan-kwang (sightseeing)  Um-ak (music)  Cong-\n",
      "\n",
      "b'4 Acknowledgements The authors are grateful to David Ahn for contributing ideas and for extensive help in preparing and processing Brown corpus files, conducting some of the reported experiments, and performing some differential analyses of results. We also benefited from the discussions and ideas contributed by Greg Carlson and Henry Kyburg in the context of our ?Knowledge Mining? group, and we appreciate the participation of group members and outside recruits in the judging experiments. As well, we thank Peter Clark and Phil Harrison (at Boeing Company) for their interest and suggestions. This work was supported by the National Science Foundation under Grant No. IIS0082928.'\n",
      "b'1 Introduction  Two text processing problems rely heavily on co-  occurrence patterns-  the way that words appear to-  gether, possibly idiosyncraticly. First, statistically  weighted co-occurrence information can assist in the  \"bracketing\" of noun groups, which can otherwise  lead to a eombinatoric explosion of parse trees \\\\[1\\\\].  Second, co-occurrence r lations can provide evidence  of semantic information for thematic-role assignment,  an important ask that is otherwise fraught with in-  accuracy.  Only co-occurrence patterns collected over a corpus  can help to determine which is .object and which is  recipient in PAID DIVIDEND (IS SECURE) vs. PAID  SHAREHOLDERS (ARE SATISFIED). A sufficiently  rich lexicon would include the semantic preferences  for distinguishing these thematic roles, but such a  lexicon does not yet exist.  Co-occurrence patterns are a means of probing a  global corpus for clues that help resolve ambiguity at  the local sentence level. Patterns such as PAID TO  SHAREHOLDERS and PAID THEM THE DIVIDEND  are detected in the corpus at large. Through these  latter examples, in which the distinction between re-  cipient and object relative to the dative verb PAY is  made explicit, the former cases in which tile relation  is implicit can be resolved.  In contrast o previous work which addressed the  identification of surface relations, i.e., SVO triples \\\\[2\\\\],  in our work we address the acquisition of semantic re-  lations, focussing at the assigment of thematic roles.  This task (i.e. tagging for acquisition) requires high  reliability and so it relies less on statistical properties  and more on deterministic local marking.  In this paper we discuss a technique for parsing  and semanticly analyzing complex sentences with the  aid of co-occurrence relations, and show how these  relations are acquired from tagged corpus.  1.1 The  Phenomenon  Consider, for example, the sentence below, taken  from the Dow-Jones newswire:  THE LARGEST CO~iPANY ON THE LIST,  WHICH LAST PAID SHAREHOLDERS IN JANUARY,  SAID THE 5 PC STOCK DIVIDEND WOULD BE  PAYABLE FOLLOWING THE PAYMENT OF THE  CASH DIVIDEND. (DJ, October 27, 1988)  For this sentence, which is not exotic or unusual  in its complexity, there are 24 non-trivial different  parse trees. Human readers, in contrast to most  programs, can quickly identify groups of words that  \"hang together\" such as COMPANY PAID A DIVI-  DEND, STOCK DIVIDEND, and CASH DIVIDEND,  and use these clusters to understand the sentence  unambiguously. Moreover, a human reader can eas-  ily recognize SHAREHOLDERS as recipient and DIV-  IDEND as the object of PAY. Along these lines, our  program develops the capability to identify such pat-  terns by training on a large corpus of examples.  1.2 The  Tra in ing  Corpus   The training corpus, from which our lexical infor-  mation is extracted, consists of more than ten rail-  34 i lion words from the Dow Jones newswire (10 months  worth of stories). For the root PAY, for instance, we  collected more than 6000 examples, 20 of which are  given below.  To exploit this data, a system must transform com-  mon patterns into operational templates, encoding a core relation between the words. The sections that  follow describe the evolution and implementation of this acquisition technique.  2 Co-occur rence :  P rev ious  Work   Garside \\\\[4\\\\] and Church et al \\\\[1\\\\] provided a major  impetus for this line of work. In Church\\'s work, a  collection of English collocations bootstrapped from a  tagged corpus facilitated the construction of an adap-  tive \"tagger\", a program that annotates a text with  part-of-speech information.  Frank Smadja \\\\[7\\\\] continued Church\\'s effort by  collecting operational pairs such as verb-noun and  adjective-noun pairs. Smadja used these pairs to con-  strain \\\\]\\\\[exical choice in a language generator; for ex-  ample, the system prefers \"deposit a check\" to \"place  a check\" based on the frequency of co-occurrence of de\n",
      "\n",
      "b'1 Introduction  This paper discusses the formalization of relative  clauses in Japanese based on JPSG (Japanese Phrase  Structure Grammar)\\\\[I, 2\\\\], which is a constraint-  based grammar formalism like tlPSG(Head-driven  Phrase Structure Grammar)\\\\[7, 8\\\\]. We have worked  on JPSG with Prof. Gunji, and also have developed  a parser based on an efficient mechanism for dealing  with constraints\\\\[3, 4, 10\\\\] to show that JPSG is effec-  tive even for the computational processing of natural  language.  In the next section, we briefly introduce JPSG the-  ory. Following a simple characterization f relative  clauses in Japanese language in section 3, we disscuss  the variety of acceptability in secton 4, and describe  its formalization in terms of constraints among the  grammatical features in section 5. And in section 6  we will claim that there is a constraint on tile number  of slash elements and show tile supporting facts.  2 Bas ics  of  J PSG  This section describes a brief introduction to JPSG,  which is a grammar formalism originally for the  Japanese language. As with IIPSG, JPSG is feature  based and constraint based grammar.  2.1 Features  Grammatical categories are represented assets of fea-  tures. We list the features used in this paper.  (1) Features used in this paper  pos (part of speech) same ms in IIPSG.  gr (grammatical relation) takes either subj, obj, or  iobj as the value.  subcat  (subcategorization) designates the set of cat-  egories (complements) that a particular category  (head) requires. Though we have to distingush  two types of complements (is., agglutinated or not) in Japanese, for simplicity, we assume that  subeat  designates tile both types of comple-  ments.  dep (dependent) designates the category that a par-  ticular category (adjunct) modifies.  core roughly corresponds to CAT feature in tlPSG  \\\\[8\\\\]. Tim value is a set of features including sub-  cat feature and so-called head features uch as  pos, gr and dep.  s lash designates a syntactic gap within the gram-  matical category involved.  sere (semantics) designates the semantic representa-  tion of the grammatical category involved.  In this paper, categories are designated by a left  square bracket (\"\\\\[\\') followed by an indefinite num-  ber of feature specifications (a feature name followed  by its value) separated by commas(\",\") followed by  a right square bracket (\"1\"). When the value is null  or not relevant, the entire feature specification can be  omitted. The sharing structure is indicated by vari-  ables such as X, Y,..., which is distinguished by an  initial capital etter as in programming language Pro-  log. Finally, a category of the form \\\\[core {pos c,  ... } . . . . .  sere s\\\\] is often abbreviated as el...\\\\]:s.  Because grammatical relations play no role in or-  dering complements in Japanese, we assume onlya  binary-branching phrase structure schema s seeu in  the next subsection.  2.2 The Phrase  S t ruc ture  Schema and Gram-   mat lca l  P r inc ip les   We are assuming three basic phrase structure schema  for Japanese: complementation, adjunclion, and co-  ACTES DE COLING.92, NANTES. 23-28 AO~\\'r 1992 1 1 0 0 PROC. OF COLING-92, NANTES, AUG. 23-28, 1992  ordination:  (2) a. G\\'omplementation M--~ C If  b. Adjure(ion M --* A tl  c. Coordination M ~ tit II2  where M stands for an arbitrary mother category, C  a complement,  lI a tread category, and A an adjunct.  Each category is construed as complex symbols, or  features, with internal structures. The above struc-  tures are uniquely characterized by the features. For  example, the head in the complements( ion structure  should have subeat  feature one of whose value is uni-  tied with the complement, C.  Furthermore, we assume the following grammart i -   cal principles, which are applied to every structures:  Head Feature  P r inc ip le :  same as in III)SG. We  assume that  pos,  dep,  and other several features  are head features.  Subcat  Feature  P r inc i\n",
      "b'1 Introduction Open-domain question answering (QA), which fulfills a user?s information need by outputting direct answers to natural language queries, is a challenging but important problem (Etzioni, 2011). State-of-the-art QA systems often implement a complicated pipeline architecture, consisting of question analysis, document or passage retrieval, answer selection and verification (Ferrucci, 2012; Moldovan et al, 2003). In this paper, we focus on one of the key subtasks ? answer sentence selection. Given a question and a set of candidate sentences, the task is to choose the correct sentence that contains the exact answer and can sufficiently support the answer choice. For instance, although both of the following sentences contain the answer ?Jack Lemmon? to the question ?Who won the best actor Oscar in 1973?? only the first sentence is correct. A1: Jack Lemmon won the Academy Award for Best Actor for Save the Tiger (1973). A2: Oscar winner Kevin Spacey said that Jack Lemmon is remembered as always making time for other people. One of the benefits of answer sentence selection is that the output can be provided directly to the user. Instead of outputting only the answer, returning the whole sentence often adds more value as the user can easily verify the correctness without reading a lengthy document. Answer sentence selection can be naturally reduced to a semantic text matching problem. Conceptually, we would like to measure how close the question and sentence can be matched semantically. Due to the variety of word choices and inherent ambiguities in natural languages, bag-ofwords approaches with simple surface-form word matching tend to produce brittle results with poor prediction accuracy (Bilotti et al, 2007). As a result, researchers put more emphasis on exploiting both the syntactic and semantic structure in questions/sentences. Representative examples include methods based on deeper semantic analysis (Shen and Lapata, 2007; Moldovan et al, 2007) and on tree edit-distance (Punyakanok et al., 2004; Heilman and Smith, 2010) and quasisynchronous grammar (Wang et al, 2007) that match the dependency parse trees of questions and sentences. However, such approaches often require more computational resources. In addition to applying a syntactic or semantic parser during run-time, finding the best matching between structured representations of sentences is not trivial. For example, the computational complexity of tree matching is O(V 2L4), where V is the number of nodes and L is the maximum depth (Tai, 1979). Instead of focusing on the high-level semantic representation, we turn our attention in this work to improving the shallow semantic compo1744 nent, lexical semantics. We formulate answer selection as a semantic matching problem with a latent word-alignment structure as in (Chang et al, 2010) and conduct a series of experimental studies on leveraging recently proposed lexical semantic models. Our main contributions in this work are two key findings. First, by incorporating the abundant information from a variety of lexical semantic models, the answer selection system can be enhanced substantially, regardless of the choice of learning algorithms and settings. Compared to the previous work, our latent alignment model improves the result on a benchmark dataset by a wide margin ? the mean averageprecision (MAP) and mean reciprocal rank (MRR) scores are increased by 25.6% and 18.8%, respectively. Second, while the latent alignment model performs better than unstructured models, the difference diminishes after adding the enhanced lexical semantics information. This may suggest that compared to introducing complex structured constraints, incorporating shallow semantic information is both more effective and computationally inexpensive in improving the performance, at least for the specific word alignment model tested in this work. The rest of the paper is structured as follows. We first survey the related work in Sec. 2. Sec. 3 def\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample1 = next(iter(train_dataset))\n",
    "sample1, sample2 = sample1['inputs1'], sample1['inputs2']\n",
    "\n",
    "for i in range(min(4, batch_size)):\n",
    "  print(encoder.decode(sample1[i]))\n",
    "  print(encoder.decode(sample2[i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4ZHtbE300dO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TEmbedding(nn.Module):\n",
    "  def __init__(self, num_embeddings, hidden_dim, seq_length=1024, padding_idx=0):\n",
    "    super(TEmbedding, self).__init__()\n",
    "    \n",
    "    self.num_embeddings = num_embeddings\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.seq_length = seq_length\n",
    "    self.padding_idx = padding_idx\n",
    "\n",
    "    self.embedding = nn.Embedding(num_embeddings, hidden_dim, padding_idx)\n",
    "    self.pos_embeds  = nn.Parameter(torch.zeros(1, self.seq_length, self.hidden_dim))\n",
    "\n",
    "    self.cls = nn.Parameter(torch.zeros(1, 1, self.hidden_dim)) #!!!!!!! INIT WITH ANOTHER VALUE IF REQUIRED\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size, seq_len = input.shape\n",
    "    \n",
    "    embed = self.embedding(input)\n",
    "    embed = embed + self.pos_embeds\n",
    "    embed = torch.cat([ self.cls.expand(batch_size, 1, -1), embed ], axis=1)\n",
    "\n",
    "    return embed\n",
    "    \n",
    "class TAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(TAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "    \n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "\n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    q = torch.mul(q, 1. / torch.sqrt(torch.tensor(self.qkv_dim)))\n",
    "\n",
    "    qk = torch.matmul(q, k.transpose(-1, -2))\n",
    "    qk = nn.Softmax(dim=-1)(qk)\n",
    "\n",
    "    def assertion_function(tsr):\n",
    "      tsr = torch.sum(tsr, axis=-1)\n",
    "      tsr = tsr - torch.ones_like(tsr)\n",
    "      return torch.max(torch.abs(tsr)) < 1e-5\n",
    "\n",
    "    assert assertion_function(qk)\n",
    "\n",
    "    qk = self.dropout(qk) #Like in TF implementation; could be done before Softmax by random -inf addition\n",
    "\n",
    "    out = torch.matmul(qk, v)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "\n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class HWLinear(nn.Module):\n",
    "  def __init__(self, num_heads, input_dim, output_dim, use_bias):\n",
    "    super(HWLinear, self).__init__()\n",
    "    \n",
    "    self.use_bias = use_bias\n",
    "    if use_bias:\n",
    "      self.bias   = nn.Parameter(torch.zeros( (1, num_heads, 1, output_dim)))\n",
    "\n",
    "    self.weight = nn.Parameter(torch.empty( (num_heads, input_dim, output_dim)))\n",
    "\n",
    "    def he_init(m):\n",
    "      s =  np.sqrt( 2. / input_dim )\n",
    "      m.data.normal_(0, s)\n",
    "\n",
    "    he_init(self.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.matmul(x, self.weight)\n",
    "    if self.use_bias:\n",
    "      x += self.bias\n",
    "    return x\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "  def __init__(self, lambda_, objects=None):\n",
    "      super(Lambda, self).__init__()\n",
    "      self.lambda_ = lambda_\n",
    "      self.objects = objects\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.objects is not None:\n",
    "      return self.lambda_(self.objects, x)\n",
    "    return self.lambda_(x)\n",
    "\n",
    "class LKAAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(LKAAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   = qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    #self.lka = nn.Sequential(\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.GELU(),\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.Softplus(beta=2.5),\n",
    "    #)\n",
    "\n",
    "    #256, 4, 16, 1024\n",
    "    #256, 64, 1, 1024\n",
    "    class AMGOLU(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, gate_rank, dropout_rate, gate_nonlinearity, kernel_nonlinearity, use_bias=False):\n",
    "        super(AMGOLU, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads= num_heads\n",
    "        \n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "\n",
    "        self.gate_weight_a = HWLinear(num_heads, self.head_dim, gate_rank, use_bias)\n",
    "        self.gate_weight_b = HWLinear(num_heads, gate_rank, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        forward_info = self.orth_weight(x)\n",
    "        forward_info = self.kernel_nonlinearity(forward_info)\n",
    "\n",
    "        gate_info = self.gate_weight_a(x)\n",
    "        gate_info = self.gate_weight_b(gate_info)\n",
    "        gate_info = self.gate_nonlinearity(gate_info)\n",
    "\n",
    "        x = forward_info * gate_info\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    class GatedOrthoKernel(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, dropout_rate=0.1, gate_nonlinearity=nn.Sigmoid(), kernel_nonlinearity=nn.Identity(), use_bias=False):\n",
    "        super(GatedOrthoKernel, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "        self.gate_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.kernel_nonlinearity(self.orth_weight(x)) * self.gate_nonlinearity(self.gate_weight(x))\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    self.lka = nn.Sequential(\n",
    "        \n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False),\n",
    "        \n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False)\n",
    "\n",
    "        #Lambda(lambda o, x: (o['act'](x[0]), x[1]), { 'act' : nn.Identity() })\n",
    "        \n",
    "    )\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    #BS x HEADS x SEQ x HEAD_DIM\n",
    "    \n",
    "    q, _ = self.lka((q, losses))\n",
    "    k, _ = self.lka((k, losses)) #Use this for var kernel\n",
    "\n",
    "    q = q / math.sqrt(self.head_dim)\n",
    "    k = k / math.sqrt(self.head_dim)\n",
    "\n",
    "    numerator = torch.matmul(k.unsqueeze(-1), v.unsqueeze(-2))\n",
    "    numerator = numerator.sum(axis=2)\n",
    "    numerator = torch.matmul(q, numerator)\n",
    "    \n",
    "    denominator = k.sum(axis=2).unsqueeze(-1)\n",
    "    denominator = q.matmul(denominator)\n",
    "\n",
    "    out = numerator / denominator\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    #TODO: INSERT DROPOUT\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(SimpleAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    #self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v) #BS x HEADS x SEQ x HEAD_DIM\n",
    "\n",
    "    _, _, seq_len, _ = q.shape\n",
    "\n",
    "    kv = torch.matmul(k.transpose(-1, -2), v)\n",
    "    kv *= 1 / math.sqrt(seq_len)\n",
    "    kv = self.dropout(kv)\n",
    "\n",
    "    out = torch.matmul(q, kv)\n",
    "    #out *= 1 / math.sqrt(self.head_dim)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    #out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, mlp_dim, num_heads, dropout_rate):\n",
    "    super(TBlock, self).__init__()\n",
    "\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.qkv_dim  = qkv_dim\n",
    "    self.mlp_dim  = mlp_dim\n",
    "\n",
    "    self.layernorm_input = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "    self.layernorm_inter = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "    self.attention = TAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, mlp_dim), nn.GELU(), nn.Dropout(dropout_rate),\n",
    "        nn.Linear(mlp_dim, hidden_dim), nn.Dropout(dropout_rate),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input, losses=[]):\n",
    "    x = self.layernorm_input(input)\n",
    "    x = self.attention(x, losses)\n",
    "\n",
    "    x = input + x\n",
    "\n",
    "    y = self.layernorm_inter(x)\n",
    "    x = self.ffn(y) + x\n",
    "\n",
    "    return x\n",
    "\n",
    "class DualClassifier(nn.Module):\n",
    "  def __init__(self, classes, hidden_dim, inter_dim):\n",
    "    super(DualClassifier, self).__init__()\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim * 2, inter_dim), nn.ReLU(),\n",
    "        nn.Linear(inter_dim, inter_dim // 2), nn.ReLU(),\n",
    "    )\n",
    "    self.output    = nn.Linear(inter_dim // 2, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    emb_1, emb_2 = x\n",
    "    x = torch.cat([ emb_1, emb_2 ], dim=-1)\n",
    "    x = x[:, 0, :]\n",
    "    x = self.ffn(x)\n",
    "    logits = self.output(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, classes, num_embeddings, seq_len, hidden_dim, qkv_dim, mlp_dim, num_heads, num_blocks, internal_dropout_rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "    \n",
    "    self.embed_layer = TEmbedding(num_embeddings, hidden_dim, seq_len)\n",
    "    self.blocks      = nn.ModuleList([ TBlock(hidden_dim, qkv_dim, mlp_dim, num_heads, internal_dropout_rate) for _ in range(num_blocks) ])\n",
    "    self.classifier  = DualClassifier(classes, hidden_dim, mlp_dim)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    additional_losses = []\n",
    "\n",
    "    emb_1 = self.embed_layer(inputs[0])\n",
    "    emb_2 = self.embed_layer(inputs[1])\n",
    "\n",
    "    for block in self.blocks:\n",
    "      emb_1 = block(emb_1, additional_losses)\n",
    "      emb_2 = block(emb_2, additional_losses)\n",
    "    \n",
    "    x = self.classifier((emb_1, emb_2))\n",
    "\n",
    "    return x, additional_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKl9SMDoCJeK"
   },
   "outputs": [],
   "source": [
    "def num_parameters(model):\n",
    "  return sum(list(map(\n",
    "      lambda x: np.prod(x[1].shape), model.named_parameters()\n",
    "  )))\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "def model_factory():\n",
    "  model = Transformer(\n",
    "    classes   =n_classes,\n",
    "    num_embeddings=encoder.vocab_size,\n",
    "    seq_len=max_length,\n",
    "    hidden_dim=128,\n",
    "    qkv_dim=128,\n",
    "    num_heads =4,\n",
    "    num_blocks=4,\n",
    "    mlp_dim=512,\n",
    "    internal_dropout_rate=0.1,\n",
    "  ).cuda()\n",
    "  \n",
    "  orig_count = num_parameters(model)\n",
    "\n",
    "  for block in model.blocks:\n",
    "    #block.attention = FtAttention()\n",
    "    block.attention = LKAAttention(128, 128, 8, 0.1).cuda()\n",
    "    \n",
    "  new_count = num_parameters(model)\n",
    "  print(f'Original model {orig_count} params, new model {new_count} params, ratio {new_count / orig_count:.3}')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "l0P77jbqTEqK",
    "outputId": "3cef9410-e725-4c61-af88-676fd12c52ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1634306 params, ratio 1.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9112fcdc10>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_schedule(warmup_steps):\n",
    "  def lr_schedule(step):\n",
    "    return 1.0 * np.minimum(1.0, step / warmup_steps) / np.sqrt(np.maximum(step, warmup_steps))\n",
    "\n",
    "  return lr_schedule\n",
    "\n",
    "lr=0.05\n",
    "weight_decay=0.1\n",
    "warmup=8000\n",
    "\n",
    "\n",
    "def const_schedule(lr):\n",
    "  def lr_schedule(step):\n",
    "    return lr\n",
    "  return lr_schedule\n",
    "\n",
    "def training_setup():\n",
    "  model = model_factory()\n",
    "  criterion = nn.CrossEntropyLoss().cuda()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  schedule_func = get_schedule(warmup)\n",
    "  #schedule_func = const_schedule(1.0) #<--------- TEMPORARY\n",
    "  scheduler = LambdaLR(optimizer, schedule_func)\n",
    "\n",
    "  return model, criterion, optimizer, schedule_func, scheduler\n",
    "\n",
    "_, _, _, schedule_func, _ = training_setup()\n",
    "\n",
    "plt.plot([ lr * schedule_func(i) for i in range(15000) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_B6ohTx7wgH"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def save_model(model, optimizer, name='/content/drive/MyDrive/Work/Misc/lka-mini-base.tar'):\n",
    "  torch.save({\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              }, name)\n",
    "\n",
    "def progress_bar(len, total, current):\n",
    "  current_scaled = int(round(len * current / total))\n",
    "\n",
    "  s = '[' + '=' * (current_scaled - 1)\n",
    "  s += '>' if current != total else '='\n",
    "  s += '-' * (len - current_scaled) + ']'\n",
    "\n",
    "  return s\n",
    "\n",
    "def accuracy(model_output, labels):\n",
    "  model_output = model_output.argmax(dim=-1)\n",
    "\n",
    "  return (labels == model_output).float().mean().cpu().numpy()\n",
    "\n",
    "def train_model(model, name, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, epochs, epoch_len=64, eps = 1e-5, skip_eval=0):\n",
    "  \n",
    "  best_acc = 0.0\n",
    "  train_datagen = iter(train_dataset)\n",
    "      \n",
    "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "      \n",
    "      #epoch start timestamp\n",
    "      t = time.time()\n",
    "\n",
    "      running_loss = 0.0\n",
    "      running_reg  = 0.0\n",
    "      running_acc  = 0.0\n",
    "\n",
    "      running_momentum = 0.99\n",
    "\n",
    "      epoch_loss = [  ]\n",
    "      epoch_reg  = [  ]\n",
    "      epoch_acc  = [  ]\n",
    "\n",
    "      model.train()\n",
    "\n",
    "      print(f'Epoch {epoch}')\n",
    "\n",
    "      process_inputs = lambda x: torch.Tensor(x.numpy()).to(torch.int64)\n",
    "\n",
    "      for i in range(epoch_len):\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          #accumulate gradients for a certain amount of steps\n",
    "          for k in range(accumulation_steps):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "            try:\n",
    "              data = next(train_datagen)\n",
    "            except StopIteration:\n",
    "              train_datagen = iter(train_dataset)\n",
    "              data = next(train_datagen)\n",
    "            except:\n",
    "              break\n",
    "            inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "            inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "            inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, additional_losses = model((inputs1, inputs2))\n",
    "            loss = criterion(outputs + eps, labels)\n",
    "\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "              print(loss)\n",
    "              return None\n",
    "\n",
    "            additional_losses = sum(additional_losses) if additional_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "            ((loss + additional_losses / 2) / accumulation_steps).backward() #multiply by 1/2 since we have a double input\n",
    "\n",
    "            acc = accuracy(outputs, labels)\n",
    "\n",
    "            running_loss = running_loss * running_momentum + (1 - running_momentum) * loss.item()\n",
    "            running_loss_unb = running_loss / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            running_acc  = running_acc  * running_momentum + (1 - running_momentum) * acc\n",
    "            running_acc_unb = running_acc / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            running_reg  = running_reg  * running_momentum + (1 - running_momentum) * additional_losses.item()\n",
    "            running_reg_unb = running_reg / (1 - running_momentum ** (i * accumulation_steps + k + 1))\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "            epoch_reg.append(additional_losses.item())\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "          pbar = progress_bar(20, epoch_len, i + 1)\n",
    "\n",
    "          print(f'\\r{pbar} {i + 1}/{epoch_len}:', end='')\n",
    "          print(f' - running_loss: {running_loss_unb:.4f} - running_reg: {running_reg_unb:.6f} - running_acc: {running_acc_unb:.4f} - lr: {scheduler.get_last_lr()[0]:.5f}', end='')\n",
    "\n",
    "          scheduler.step()\n",
    "      \n",
    "      epoch_loss = np.mean(epoch_loss)\n",
    "      epoch_acc  = np.mean(epoch_acc)\n",
    "      epoch_reg  = np.mean(epoch_reg)\n",
    "      \n",
    "      print(f' - epoch_loss: {epoch_loss:.4f} - epoch_reg: {epoch_reg:.6f} - epoch_acc: {epoch_acc:.4f}', end='')\n",
    "\n",
    "      epoch_loss, epoch_acc, epoch_reg = [], [], []\n",
    "\n",
    "      \n",
    "      if epoch >= skip_eval:\n",
    "        model.eval()\n",
    "        valid_dataset.repeat()\n",
    "        valid_datagen = iter(valid_dataset)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for i, data in enumerate(valid_datagen):\n",
    "\n",
    "            inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "            inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "            inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "            outputs, aux_losses = model((inputs1, inputs2))\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = accuracy(outputs, labels)\n",
    "            aux_losses = sum(aux_losses) if aux_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "            aux_losses /= 2 #Doubled input\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "            epoch_reg.append(aux_losses.item())\n",
    "\n",
    "        epoch_loss, epoch_acc, epoch_reg = np.mean(epoch_loss), np.mean(epoch_acc), np.mean(epoch_reg)\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "          best_acc = epoch_acc\n",
    "          save_model(model, optimizer, name)\n",
    "      \n",
    "      else:\n",
    "        epoch_loss, epoch_acc, epoch_reg = 0.0, 0.0, 0.0\n",
    "\n",
    "      #epoch computing time\n",
    "      t = time.time() - t\n",
    "\n",
    "      print(f' - valid_loss: {epoch_loss:.4f} - valid_reg: {epoch_reg:.6f} - valid_acc: {epoch_acc:.4f} - epoch_time: {t:.4f} s')\n",
    " \n",
    "  checkpoint = torch.load(name)\n",
    "  return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egh-IbW76AN4"
   },
   "outputs": [],
   "source": [
    "def test(model, criterion, test_dataset):\n",
    "  epoch_loss, epoch_acc, epoch_reg = [], [], []\n",
    "\n",
    "  model.eval()\n",
    "  test_dataset.repeat()\n",
    "\n",
    "  process_inputs = lambda x: torch.Tensor(x.numpy()).to(torch.int64)\n",
    "\n",
    "  t = time.time()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(iter(test_dataset)):\n",
    "      inputs1, inputs2, labels = data['inputs1'], data['inputs2'], data['targets']\n",
    "      inputs1, inputs2, labels = process_inputs(inputs1), process_inputs(inputs2), process_inputs(labels)\n",
    "      inputs1, inputs2, labels = inputs1.cuda(), inputs2.cuda(), labels.cuda()\n",
    "\n",
    "      outputs, aux_losses = model((inputs1, inputs2))\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = accuracy(outputs, labels)\n",
    "      aux_losses = sum(aux_losses) if aux_losses else torch.Tensor([ 0.0 ]).cuda()\n",
    "      aux_losses /= 2 #Doubled input\n",
    "\n",
    "      epoch_loss.append(loss.item())\n",
    "      epoch_acc.append(acc)\n",
    "      epoch_reg.append(aux_losses.item())\n",
    "\n",
    "  t = time.time() - t\n",
    "\n",
    "  epoch_loss, epoch_acc, epoch_reg = np.mean(epoch_loss), np.mean(epoch_acc), np.mean(epoch_reg)\n",
    "\n",
    "  print(f' - test_loss: {epoch_loss:.4f} - test_reg: {epoch_reg:.6f} - test_acc: {epoch_acc:.4f} - test_time: {t:.4f} s')\n",
    "  return epoch_loss, epoch_reg, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4d0DhgWDbm3",
    "outputId": "609850ff-2fc0-4a4e-c25e-eb9949b9b9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1634306 params, ratio 1.02\n",
      "Epoch 0\n",
      "[====================] 200/200: - running_loss: 0.6809 - running_reg: 0.000000 - running_acc: 0.5518 - lr: 0.00001 - epoch_loss: 0.6887 - epoch_reg: 0.000000 - epoch_acc: 0.5377 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 128.0584 s\n",
      "Epoch 1\n",
      "[====================] 200/200: - running_loss: 0.6924 - running_reg: 0.000000 - running_acc: 0.5132 - lr: 0.00003 - epoch_loss: 0.6891 - epoch_reg: 0.000000 - epoch_acc: 0.5319 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9133 s\n",
      "Epoch 2\n",
      "[====================] 200/200: - running_loss: 0.6892 - running_reg: 0.000000 - running_acc: 0.5354 - lr: 0.00004 - epoch_loss: 0.6922 - epoch_reg: 0.000000 - epoch_acc: 0.5127 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1040 s\n",
      "Epoch 3\n",
      "[====================] 200/200: - running_loss: 0.6913 - running_reg: 0.000000 - running_acc: 0.5060 - lr: 0.00006 - epoch_loss: 0.6925 - epoch_reg: 0.000000 - epoch_acc: 0.5095 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9135 s\n",
      "Epoch 4\n",
      "[====================] 200/200: - running_loss: 0.6932 - running_reg: 0.000000 - running_acc: 0.5150 - lr: 0.00007 - epoch_loss: 0.6928 - epoch_reg: 0.000000 - epoch_acc: 0.5153 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0762 s\n",
      "Epoch 5\n",
      "[====================] 200/200: - running_loss: 0.6567 - running_reg: 0.000000 - running_acc: 0.6077 - lr: 0.00008 - epoch_loss: 0.6812 - epoch_reg: 0.000000 - epoch_acc: 0.5542 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1674 s\n",
      "Epoch 6\n",
      "[====================] 200/200: - running_loss: 0.5263 - running_reg: 0.000000 - running_acc: 0.7435 - lr: 0.00010 - epoch_loss: 0.5918 - epoch_reg: 0.000000 - epoch_acc: 0.6819 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.3008 s\n",
      "Epoch 7\n",
      "[====================] 200/200: - running_loss: 0.5679 - running_reg: 0.000000 - running_acc: 0.7180 - lr: 0.00011 - epoch_loss: 0.5587 - epoch_reg: 0.000000 - epoch_acc: 0.7108 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1146 s\n",
      "Epoch 8\n",
      "[====================] 200/200: - running_loss: 0.6311 - running_reg: 0.000000 - running_acc: 0.6207 - lr: 0.00013 - epoch_loss: 0.6185 - epoch_reg: 0.000000 - epoch_acc: 0.6488 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0427 s\n",
      "Epoch 9\n",
      "[====================] 200/200: - running_loss: 0.5102 - running_reg: 0.000000 - running_acc: 0.7449 - lr: 0.00014 - epoch_loss: 0.5887 - epoch_reg: 0.000000 - epoch_acc: 0.6828 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1703 s\n",
      "Epoch 10\n",
      "[====================] 200/200: - running_loss: 0.5943 - running_reg: 0.000000 - running_acc: 0.6762 - lr: 0.00015 - epoch_loss: 0.5684 - epoch_reg: 0.000000 - epoch_acc: 0.6955 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.8838 s\n",
      "Epoch 11\n",
      "[====================] 200/200: - running_loss: 0.5541 - running_reg: 0.000000 - running_acc: 0.7280 - lr: 0.00017 - epoch_loss: 0.5559 - epoch_reg: 0.000000 - epoch_acc: 0.7128 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9597 s\n",
      "Epoch 12\n",
      "[====================] 200/200: - running_loss: 0.5847 - running_reg: 0.000000 - running_acc: 0.6590 - lr: 0.00018 - epoch_loss: 0.5786 - epoch_reg: 0.000000 - epoch_acc: 0.6784 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9479 s\n",
      "Epoch 13\n",
      "[====================] 200/200: - running_loss: 0.5841 - running_reg: 0.000000 - running_acc: 0.6875 - lr: 0.00020 - epoch_loss: 0.5865 - epoch_reg: 0.000000 - epoch_acc: 0.6731 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0771 s\n",
      "Epoch 14\n",
      "[====================] 200/200: - running_loss: 0.5858 - running_reg: 0.000000 - running_acc: 0.6770 - lr: 0.00021 - epoch_loss: 0.6099 - epoch_reg: 0.000000 - epoch_acc: 0.6603 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1366 s\n",
      "Epoch 15\n",
      "[====================] 200/200: - running_loss: 0.5124 - running_reg: 0.000000 - running_acc: 0.7418 - lr: 0.00022 - epoch_loss: 0.5630 - epoch_reg: 0.000000 - epoch_acc: 0.6939 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0789 s\n",
      "Epoch 16\n",
      "[====================] 200/200: - running_loss: 0.5441 - running_reg: 0.000000 - running_acc: 0.7231 - lr: 0.00024 - epoch_loss: 0.5296 - epoch_reg: 0.000000 - epoch_acc: 0.7294 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0874 s\n",
      "Epoch 17\n",
      "[====================] 200/200: - running_loss: 0.6077 - running_reg: 0.000000 - running_acc: 0.6663 - lr: 0.00025 - epoch_loss: 0.5677 - epoch_reg: 0.000000 - epoch_acc: 0.7006 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1729 s\n",
      "Epoch 18\n",
      "[====================] 200/200: - running_loss: 0.6337 - running_reg: 0.000000 - running_acc: 0.6407 - lr: 0.00027 - epoch_loss: 0.6261 - epoch_reg: 0.000000 - epoch_acc: 0.6400 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0662 s\n",
      "Epoch 19\n",
      "[====================] 200/200: - running_loss: 0.6329 - running_reg: 0.000000 - running_acc: 0.6296 - lr: 0.00028 - epoch_loss: 0.6341 - epoch_reg: 0.000000 - epoch_acc: 0.6361 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9785 s\n",
      "Epoch 20\n",
      "[====================] 200/200: - running_loss: 0.6402 - running_reg: 0.000000 - running_acc: 0.6056 - lr: 0.00029 - epoch_loss: 0.6441 - epoch_reg: 0.000000 - epoch_acc: 0.6178 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.0522 s\n",
      "Epoch 21\n",
      "[====================] 200/200: - running_loss: 0.6111 - running_reg: 0.000000 - running_acc: 0.6831 - lr: 0.00031 - epoch_loss: 0.6192 - epoch_reg: 0.000000 - epoch_acc: 0.6533 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9697 s\n",
      "Epoch 22\n",
      "[====================] 200/200: - running_loss: 0.6200 - running_reg: 0.000000 - running_acc: 0.6490 - lr: 0.00032 - epoch_loss: 0.6029 - epoch_reg: 0.000000 - epoch_acc: 0.6553 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 124.0912 s\n",
      "Epoch 23\n",
      "[====================] 200/200: - running_loss: 0.5538 - running_reg: 0.000000 - running_acc: 0.6978 - lr: 0.00034 - epoch_loss: 0.5431 - epoch_reg: 0.000000 - epoch_acc: 0.7195 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 121.9768 s\n",
      "Epoch 24\n",
      "[====================] 200/200: - running_loss: 0.5801 - running_reg: 0.000000 - running_acc: 0.6874 - lr: 0.00035 - epoch_loss: 0.5678 - epoch_reg: 0.000000 - epoch_acc: 0.6988 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1461 s\n",
      "Epoch 25\n",
      "[====================] 200/200: - running_loss: 0.5905 - running_reg: 0.000000 - running_acc: 0.6815 - lr: 0.00036 - epoch_loss: 0.5870 - epoch_reg: 0.000000 - epoch_acc: 0.6772 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.2086 s\n",
      "Epoch 26\n",
      "[====================] 200/200: - running_loss: 0.6026 - running_reg: 0.000000 - running_acc: 0.6358 - lr: 0.00038 - epoch_loss: 0.5882 - epoch_reg: 0.000000 - epoch_acc: 0.6848 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.1943 s\n",
      "Epoch 27\n",
      "[====================] 200/200: - running_loss: 0.5876 - running_reg: 0.000000 - running_acc: 0.6861 - lr: 0.00039 - epoch_loss: 0.5921 - epoch_reg: 0.000000 - epoch_acc: 0.6764 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.4897 s\n",
      "Epoch 28\n",
      "[====================] 200/200: - running_loss: 0.5004 - running_reg: 0.000000 - running_acc: 0.7546 - lr: 0.00041 - epoch_loss: 0.5360 - epoch_reg: 0.000000 - epoch_acc: 0.7247 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.2275 s\n",
      "Epoch 29\n",
      "[====================] 200/200: - running_loss: 0.3704 - running_reg: 0.000000 - running_acc: 0.8256 - lr: 0.00042 - epoch_loss: 0.4329 - epoch_reg: 0.000000 - epoch_acc: 0.7969 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 122.4127 s\n",
      "Epoch 30\n",
      "[====================] 200/200: - running_loss: 0.4897 - running_reg: 0.000000 - running_acc: 0.7774 - lr: 0.00043 - epoch_loss: 0.4382 - epoch_reg: 0.000000 - epoch_acc: 0.7922 - valid_loss: 0.6799 - valid_reg: 0.000000 - valid_acc: 0.6123 - epoch_time: 259.1057 s\n",
      "Epoch 31\n",
      "[====================] 200/200: - running_loss: 0.5433 - running_reg: 0.000000 - running_acc: 0.7172 - lr: 0.00045 - epoch_loss: 0.5010 - epoch_reg: 0.000000 - epoch_acc: 0.7467 - valid_loss: 0.6604 - valid_reg: 0.000000 - valid_acc: 0.6314 - epoch_time: 261.5486 s\n",
      "Epoch 32\n",
      "[====================] 200/200: - running_loss: 0.4685 - running_reg: 0.000000 - running_acc: 0.7753 - lr: 0.00046 - epoch_loss: 0.5030 - epoch_reg: 0.000000 - epoch_acc: 0.7462 - valid_loss: 0.6753 - valid_reg: 0.000000 - valid_acc: 0.6246 - epoch_time: 265.3191 s\n",
      "Epoch 33\n",
      "[====================] 200/200: - running_loss: 0.4664 - running_reg: 0.000000 - running_acc: 0.7790 - lr: 0.00048 - epoch_loss: 0.4625 - epoch_reg: 0.000000 - epoch_acc: 0.7769 - valid_loss: 0.7114 - valid_reg: 0.000000 - valid_acc: 0.6410 - epoch_time: 264.5034 s\n",
      "Epoch 34\n",
      "[====================] 200/200: - running_loss: 0.4616 - running_reg: 0.000000 - running_acc: 0.7760 - lr: 0.00049 - epoch_loss: 0.4612 - epoch_reg: 0.000000 - epoch_acc: 0.7748 - valid_loss: 0.7984 - valid_reg: 0.000000 - valid_acc: 0.6399 - epoch_time: 265.3974 s\n",
      "Epoch 35\n",
      "[====================] 200/200: - running_loss: 0.5206 - running_reg: 0.000000 - running_acc: 0.7332 - lr: 0.00050 - epoch_loss: 0.4946 - epoch_reg: 0.000000 - epoch_acc: 0.7500 - valid_loss: 0.8125 - valid_reg: 0.000000 - valid_acc: 0.6246 - epoch_time: 265.6127 s\n",
      "Epoch 36\n",
      "[====================] 200/200: - running_loss: 0.4988 - running_reg: 0.000000 - running_acc: 0.7567 - lr: 0.00052 - epoch_loss: 0.5112 - epoch_reg: 0.000000 - epoch_acc: 0.7447 - valid_loss: 0.7472 - valid_reg: 0.000000 - valid_acc: 0.6456 - epoch_time: 265.9250 s\n",
      "Epoch 37\n",
      "[====================] 200/200: - running_loss: 0.5475 - running_reg: 0.000000 - running_acc: 0.7076 - lr: 0.00053 - epoch_loss: 0.5405 - epoch_reg: 0.000000 - epoch_acc: 0.7264 - valid_loss: 0.5910 - valid_reg: 0.000000 - valid_acc: 0.6796 - epoch_time: 263.9090 s\n",
      "Epoch 38\n",
      "[====================] 200/200: - running_loss: 0.4958 - running_reg: 0.000000 - running_acc: 0.7623 - lr: 0.00054 - epoch_loss: 0.5214 - epoch_reg: 0.000000 - epoch_acc: 0.7306 - valid_loss: 0.6609 - valid_reg: 0.000000 - valid_acc: 0.6284 - epoch_time: 264.6382 s\n",
      "Epoch 39\n",
      "[====================] 200/200: - running_loss: 0.5324 - running_reg: 0.000000 - running_acc: 0.7242 - lr: 0.00056 - epoch_loss: 0.5034 - epoch_reg: 0.000000 - epoch_acc: 0.7478 - valid_loss: 0.5955 - valid_reg: 0.000000 - valid_acc: 0.6779 - epoch_time: 265.4445 s\n",
      "Epoch 40\n",
      "[====================] 200/200: - running_loss: 0.5814 - running_reg: 0.000000 - running_acc: 0.7058 - lr: 0.00055 - epoch_loss: 0.5326 - epoch_reg: 0.000000 - epoch_acc: 0.7320 - valid_loss: 0.5897 - valid_reg: 0.000000 - valid_acc: 0.6722 - epoch_time: 264.6992 s\n",
      "Epoch 41\n",
      "[====================] 200/200: - running_loss: 0.5706 - running_reg: 0.000000 - running_acc: 0.7081 - lr: 0.00055 - epoch_loss: 0.5738 - epoch_reg: 0.000000 - epoch_acc: 0.6942 - valid_loss: 0.6182 - valid_reg: 0.000000 - valid_acc: 0.6729 - epoch_time: 263.2467 s\n",
      "Epoch 42\n",
      "[====================] 200/200: - running_loss: 0.5336 - running_reg: 0.000000 - running_acc: 0.7201 - lr: 0.00054 - epoch_loss: 0.5730 - epoch_reg: 0.000000 - epoch_acc: 0.6948 - valid_loss: 0.6203 - valid_reg: 0.000000 - valid_acc: 0.6667 - epoch_time: 267.4004 s\n",
      "Epoch 43\n",
      "[====================] 200/200: - running_loss: 0.5791 - running_reg: 0.000000 - running_acc: 0.6962 - lr: 0.00053 - epoch_loss: 0.5770 - epoch_reg: 0.000000 - epoch_acc: 0.6895 - valid_loss: 0.5921 - valid_reg: 0.000000 - valid_acc: 0.6869 - epoch_time: 266.2934 s\n",
      "Epoch 44\n",
      "[====================] 200/200: - running_loss: 0.5487 - running_reg: 0.000000 - running_acc: 0.7047 - lr: 0.00053 - epoch_loss: 0.5659 - epoch_reg: 0.000000 - epoch_acc: 0.7028 - valid_loss: 0.6020 - valid_reg: 0.000000 - valid_acc: 0.6599 - epoch_time: 264.9817 s\n",
      "Epoch 45\n",
      "[====================] 200/200: - running_loss: 0.5676 - running_reg: 0.000000 - running_acc: 0.7150 - lr: 0.00052 - epoch_loss: 0.5337 - epoch_reg: 0.000000 - epoch_acc: 0.7152 - valid_loss: 0.6151 - valid_reg: 0.000000 - valid_acc: 0.6519 - epoch_time: 266.8652 s\n",
      "Epoch 46\n",
      "[====================] 200/200: - running_loss: 0.5118 - running_reg: 0.000000 - running_acc: 0.7313 - lr: 0.00052 - epoch_loss: 0.5152 - epoch_reg: 0.000000 - epoch_acc: 0.7347 - valid_loss: 0.6044 - valid_reg: 0.000000 - valid_acc: 0.6709 - epoch_time: 265.9657 s\n",
      "Epoch 47\n",
      "[====================] 200/200: - running_loss: 0.5151 - running_reg: 0.000000 - running_acc: 0.7401 - lr: 0.00051 - epoch_loss: 0.5093 - epoch_reg: 0.000000 - epoch_acc: 0.7453 - valid_loss: 0.6014 - valid_reg: 0.000000 - valid_acc: 0.6749 - epoch_time: 268.4280 s\n",
      "Epoch 48\n",
      "[====================] 200/200: - running_loss: 0.5435 - running_reg: 0.000000 - running_acc: 0.7100 - lr: 0.00051 - epoch_loss: 0.5347 - epoch_reg: 0.000000 - epoch_acc: 0.7244 - valid_loss: 0.6054 - valid_reg: 0.000000 - valid_acc: 0.6774 - epoch_time: 268.4025 s\n",
      "Epoch 49\n",
      "[====================] 200/200: - running_loss: 0.5221 - running_reg: 0.000000 - running_acc: 0.7178 - lr: 0.00050 - epoch_loss: 0.5275 - epoch_reg: 0.000000 - epoch_acc: 0.7269 - valid_loss: 0.5820 - valid_reg: 0.000000 - valid_acc: 0.6890 - epoch_time: 268.1594 s\n",
      "Epoch 50\n",
      "[====================] 200/200: - running_loss: 0.4823 - running_reg: 0.000000 - running_acc: 0.7756 - lr: 0.00050 - epoch_loss: 0.5133 - epoch_reg: 0.000000 - epoch_acc: 0.7381 - valid_loss: 0.5832 - valid_reg: 0.000000 - valid_acc: 0.6867 - epoch_time: 266.1615 s\n",
      "Epoch 51\n",
      "[====================] 200/200: - running_loss: 0.3982 - running_reg: 0.000000 - running_acc: 0.8137 - lr: 0.00049 - epoch_loss: 0.4165 - epoch_reg: 0.000000 - epoch_acc: 0.8036 - valid_loss: 0.5899 - valid_reg: 0.000000 - valid_acc: 0.6893 - epoch_time: 263.8607 s\n",
      "Epoch 52\n",
      "[====================] 200/200: - running_loss: 0.3164 - running_reg: 0.000000 - running_acc: 0.8662 - lr: 0.00049 - epoch_loss: 0.3002 - epoch_reg: 0.000000 - epoch_acc: 0.8684 - valid_loss: 0.6981 - valid_reg: 0.000000 - valid_acc: 0.6475 - epoch_time: 263.7452 s\n",
      "Epoch 53\n",
      "[====================] 200/200: - running_loss: 0.3654 - running_reg: 0.000000 - running_acc: 0.8303 - lr: 0.00048 - epoch_loss: 0.3197 - epoch_reg: 0.000000 - epoch_acc: 0.8616 - valid_loss: 0.6018 - valid_reg: 0.000000 - valid_acc: 0.6845 - epoch_time: 272.6271 s\n",
      "Epoch 54\n",
      "[====================] 200/200: - running_loss: 0.4314 - running_reg: 0.000000 - running_acc: 0.7960 - lr: 0.00048 - epoch_loss: 0.4139 - epoch_reg: 0.000000 - epoch_acc: 0.8081 - valid_loss: 0.5772 - valid_reg: 0.000000 - valid_acc: 0.7052 - epoch_time: 276.2968 s\n",
      "Epoch 55\n",
      "[====================] 200/200: - running_loss: 0.3937 - running_reg: 0.000000 - running_acc: 0.8135 - lr: 0.00047 - epoch_loss: 0.4117 - epoch_reg: 0.000000 - epoch_acc: 0.8087 - valid_loss: 0.6471 - valid_reg: 0.000000 - valid_acc: 0.6670 - epoch_time: 275.8716 s\n",
      "Epoch 56\n",
      "[====================] 200/200: - running_loss: 0.3532 - running_reg: 0.000000 - running_acc: 0.8405 - lr: 0.00047 - epoch_loss: 0.3650 - epoch_reg: 0.000000 - epoch_acc: 0.8373 - valid_loss: 0.6433 - valid_reg: 0.000000 - valid_acc: 0.6958 - epoch_time: 276.0047 s\n",
      "Epoch 57\n",
      "[====================] 200/200: - running_loss: 0.3595 - running_reg: 0.000000 - running_acc: 0.8312 - lr: 0.00046 - epoch_loss: 0.3559 - epoch_reg: 0.000000 - epoch_acc: 0.8427 - valid_loss: 0.7838 - valid_reg: 0.000000 - valid_acc: 0.6769 - epoch_time: 275.9709 s\n",
      "Epoch 58\n",
      "[====================] 200/200: - running_loss: 0.4067 - running_reg: 0.000000 - running_acc: 0.8132 - lr: 0.00046 - epoch_loss: 0.3784 - epoch_reg: 0.000000 - epoch_acc: 0.8244 - valid_loss: 0.7091 - valid_reg: 0.000000 - valid_acc: 0.6969 - epoch_time: 267.7450 s\n",
      "Epoch 59\n",
      "[====================] 200/200: - running_loss: 0.5071 - running_reg: 0.000000 - running_acc: 0.7351 - lr: 0.00046 - epoch_loss: 0.4351 - epoch_reg: 0.000000 - epoch_acc: 0.7834 - valid_loss: 0.7865 - valid_reg: 0.000000 - valid_acc: 0.6315 - epoch_time: 266.4342 s\n",
      "Epoch 60\n",
      "[====================] 200/200: - running_loss: 0.4794 - running_reg: 0.000000 - running_acc: 0.7657 - lr: 0.00045 - epoch_loss: 0.4759 - epoch_reg: 0.000000 - epoch_acc: 0.7745 - valid_loss: 0.5662 - valid_reg: 0.000000 - valid_acc: 0.7114 - epoch_time: 265.7422 s\n",
      "Epoch 61\n",
      "[====================] 200/200: - running_loss: 0.4455 - running_reg: 0.000000 - running_acc: 0.7793 - lr: 0.00045 - epoch_loss: 0.4527 - epoch_reg: 0.000000 - epoch_acc: 0.7808 - valid_loss: 0.5474 - valid_reg: 0.000000 - valid_acc: 0.7240 - epoch_time: 273.8877 s\n",
      "Epoch 62\n",
      "[====================] 200/200: - running_loss: 0.4751 - running_reg: 0.000000 - running_acc: 0.7774 - lr: 0.00045 - epoch_loss: 0.4411 - epoch_reg: 0.000000 - epoch_acc: 0.7923 - valid_loss: 0.5420 - valid_reg: 0.000000 - valid_acc: 0.7300 - epoch_time: 273.8367 s\n",
      "Epoch 63\n",
      "[====================] 200/200: - running_loss: 0.4946 - running_reg: 0.000000 - running_acc: 0.7595 - lr: 0.00044 - epoch_loss: 0.4760 - epoch_reg: 0.000000 - epoch_acc: 0.7686 - valid_loss: 0.5474 - valid_reg: 0.000000 - valid_acc: 0.7101 - epoch_time: 274.5106 s\n",
      "Epoch 64\n",
      "[====================] 200/200: - running_loss: 0.5198 - running_reg: 0.000000 - running_acc: 0.7351 - lr: 0.00044 - epoch_loss: 0.4862 - epoch_reg: 0.000000 - epoch_acc: 0.7600 - valid_loss: 0.5671 - valid_reg: 0.000000 - valid_acc: 0.7088 - epoch_time: 275.0483 s\n",
      "Epoch 65\n",
      "[====================] 200/200: - running_loss: 0.5022 - running_reg: 0.000000 - running_acc: 0.7306 - lr: 0.00044 - epoch_loss: 0.4856 - epoch_reg: 0.000000 - epoch_acc: 0.7502 - valid_loss: 0.5578 - valid_reg: 0.000000 - valid_acc: 0.7158 - epoch_time: 275.0239 s\n",
      "Epoch 66\n",
      "[====================] 200/200: - running_loss: 0.5164 - running_reg: 0.000000 - running_acc: 0.7395 - lr: 0.00043 - epoch_loss: 0.5260 - epoch_reg: 0.000000 - epoch_acc: 0.7348 - valid_loss: 0.5651 - valid_reg: 0.000000 - valid_acc: 0.6988 - epoch_time: 268.3168 s\n",
      "Epoch 67\n",
      "[====================] 200/200: - running_loss: 0.4723 - running_reg: 0.000000 - running_acc: 0.7609 - lr: 0.00043 - epoch_loss: 0.4964 - epoch_reg: 0.000000 - epoch_acc: 0.7462 - valid_loss: 0.5981 - valid_reg: 0.000000 - valid_acc: 0.6882 - epoch_time: 265.8616 s\n",
      "Epoch 68\n",
      "[====================] 200/200: - running_loss: 0.5281 - running_reg: 0.000000 - running_acc: 0.7311 - lr: 0.00043 - epoch_loss: 0.4912 - epoch_reg: 0.000000 - epoch_acc: 0.7473 - valid_loss: 0.5531 - valid_reg: 0.000000 - valid_acc: 0.7066 - epoch_time: 271.2596 s\n",
      "Epoch 69\n",
      "[====================] 200/200: - running_loss: 0.4667 - running_reg: 0.000000 - running_acc: 0.7752 - lr: 0.00042 - epoch_loss: 0.4801 - epoch_reg: 0.000000 - epoch_acc: 0.7559 - valid_loss: 0.5735 - valid_reg: 0.000000 - valid_acc: 0.6978 - epoch_time: 274.3528 s\n",
      "Epoch 70\n",
      "[====================] 200/200: - running_loss: 0.4166 - running_reg: 0.000000 - running_acc: 0.7993 - lr: 0.00042 - epoch_loss: 0.4507 - epoch_reg: 0.000000 - epoch_acc: 0.7820 - valid_loss: 0.6088 - valid_reg: 0.000000 - valid_acc: 0.6970 - epoch_time: 274.4618 s\n",
      "Epoch 71\n",
      "[====================] 200/200: - running_loss: 0.4459 - running_reg: 0.000000 - running_acc: 0.8037 - lr: 0.00042 - epoch_loss: 0.4712 - epoch_reg: 0.000000 - epoch_acc: 0.7763 - valid_loss: 0.5699 - valid_reg: 0.000000 - valid_acc: 0.7152 - epoch_time: 274.5156 s\n",
      "Epoch 72\n",
      "[====================] 200/200: - running_loss: 0.4688 - running_reg: 0.000000 - running_acc: 0.7644 - lr: 0.00041 - epoch_loss: 0.4644 - epoch_reg: 0.000000 - epoch_acc: 0.7733 - valid_loss: 0.5420 - valid_reg: 0.000000 - valid_acc: 0.7314 - epoch_time: 275.5427 s\n",
      "Epoch 73\n",
      "[====================] 200/200: - running_loss: 0.3872 - running_reg: 0.000000 - running_acc: 0.8284 - lr: 0.00041 - epoch_loss: 0.4162 - epoch_reg: 0.000000 - epoch_acc: 0.8072 - valid_loss: 0.5646 - valid_reg: 0.000000 - valid_acc: 0.7091 - epoch_time: 274.6782 s\n",
      "Epoch 74\n",
      "[====================] 200/200: - running_loss: 0.2775 - running_reg: 0.000000 - running_acc: 0.8817 - lr: 0.00041 - epoch_loss: 0.3254 - epoch_reg: 0.000000 - epoch_acc: 0.8584 - valid_loss: 0.6425 - valid_reg: 0.000000 - valid_acc: 0.6978 - epoch_time: 265.5856 s\n",
      " - test_loss: 0.5430 - test_reg: 0.000000 - test_acc: 0.7236 - test_time: 128.7853 s\n",
      "\n",
      "Total accuracy: 0.7236\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(1): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup()\n",
    "\n",
    "  checkpoint = train_model(model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, 75, 200, skip_eval=30)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = test(model, criterion, test_dataset)\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDVb8nQ2m2go"
   },
   "outputs": [],
   "source": [
    "GLU x2: 0.7236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oJI-xf2xaLqc"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TEmbedding(nn.Module):\n",
    "  def __init__(self, num_embeddings, hidden_dim, seq_length=1024, padding_idx=0):\n",
    "    super(TEmbedding, self).__init__()\n",
    "    \n",
    "    self.num_embeddings = num_embeddings\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.seq_length = seq_length\n",
    "    self.padding_idx = padding_idx\n",
    "\n",
    "    self.embedding = nn.Embedding(num_embeddings, hidden_dim, padding_idx)\n",
    "    self.pos_embeds  = nn.Parameter(torch.zeros(1, self.seq_length, self.hidden_dim))\n",
    "\n",
    "    self.cls = nn.Parameter(torch.zeros(1, 1, self.hidden_dim)) #!!!!!!! INIT WITH ANOTHER VALUE IF REQUIRED\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size, seq_len = input.shape\n",
    "    \n",
    "    embed = self.embedding(input)\n",
    "    embed = embed + self.pos_embeds\n",
    "    embed = torch.cat([ self.cls.expand(batch_size, 1, -1), embed ], axis=1)\n",
    "\n",
    "    return embed\n",
    "    \n",
    "class TAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(TAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "    \n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "\n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    q = torch.mul(q, 1. / torch.sqrt(torch.tensor(self.qkv_dim)))\n",
    "\n",
    "    qk = torch.matmul(q, k.transpose(-1, -2))\n",
    "    qk = nn.Softmax(dim=-1)(qk)\n",
    "\n",
    "    def assertion_function(tsr):\n",
    "      tsr = torch.sum(tsr, axis=-1)\n",
    "      tsr = tsr - torch.ones_like(tsr)\n",
    "      return torch.max(torch.abs(tsr)) < 1e-5\n",
    "\n",
    "    assert assertion_function(qk)\n",
    "\n",
    "    qk = self.dropout(qk) #Like in TF implementation; could be done before Softmax by random -inf addition\n",
    "\n",
    "    out = torch.matmul(qk, v)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "\n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class HWLinear(nn.Module):\n",
    "  def __init__(self, num_heads, input_dim, output_dim, use_bias):\n",
    "    super(HWLinear, self).__init__()\n",
    "    \n",
    "    self.use_bias = use_bias\n",
    "    if use_bias:\n",
    "      self.bias   = nn.Parameter(torch.zeros( (1, num_heads, 1, output_dim)))\n",
    "\n",
    "    self.weight = nn.Parameter(torch.empty( (num_heads, input_dim, output_dim)))\n",
    "\n",
    "    def he_init(m):\n",
    "      s =  np.sqrt( 2. / input_dim )\n",
    "      m.data.normal_(0, s)\n",
    "\n",
    "    he_init(self.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.matmul(x, self.weight)\n",
    "    if self.use_bias:\n",
    "      x += self.bias\n",
    "    return x\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "  def __init__(self, lambda_, objects=None):\n",
    "      super(Lambda, self).__init__()\n",
    "      self.lambda_ = lambda_\n",
    "      self.objects = objects\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.objects is not None:\n",
    "      return self.lambda_(self.objects, x)\n",
    "    return self.lambda_(x)\n",
    "\n",
    "class LKAAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(LKAAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   = qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    #self.lka = nn.Sequential(\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.GELU(),\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.Softplus(beta=2.5),\n",
    "    #)\n",
    "\n",
    "    #256, 4, 16, 1024\n",
    "    #256, 64, 1, 1024\n",
    "    class AMGOLU(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, gate_rank, dropout_rate, gate_nonlinearity, kernel_nonlinearity, use_bias=False):\n",
    "        super(AMGOLU, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads= num_heads\n",
    "        \n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "\n",
    "        self.gate_weight_a = HWLinear(num_heads, self.head_dim, gate_rank, use_bias)\n",
    "        self.gate_weight_b = HWLinear(num_heads, gate_rank, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        forward_info = self.orth_weight(x)\n",
    "        forward_info = self.kernel_nonlinearity(forward_info)\n",
    "\n",
    "        gate_info = self.gate_weight_a(x)\n",
    "        gate_info = self.gate_weight_b(gate_info)\n",
    "        gate_info = self.gate_nonlinearity(gate_info)\n",
    "\n",
    "        x = forward_info * gate_info\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    class GatedOrthoKernel(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, dropout_rate=0.1, gate_nonlinearity=nn.Sigmoid(), kernel_nonlinearity=nn.Identity(), use_bias=False):\n",
    "        super(GatedOrthoKernel, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "        self.gate_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.kernel_nonlinearity(self.orth_weight(x)) * self.gate_nonlinearity(self.gate_weight(x))\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    self.lka = nn.Sequential(\n",
    "        \n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False),\n",
    "        \n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False)\n",
    "\n",
    "        #Lambda(lambda o, x: (o['act'](x[0]), x[1]), { 'act' : nn.Identity() })\n",
    "        \n",
    "    )\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    #BS x HEADS x SEQ x HEAD_DIM\n",
    "    \n",
    "    q, _ = self.lka((q, losses))\n",
    "    k, _ = self.lka((k, losses)) #Use this for var kernel\n",
    "\n",
    "    q = q / math.sqrt(self.head_dim)\n",
    "    k = k / math.sqrt(self.head_dim)\n",
    "\n",
    "    numerator = torch.matmul(k.unsqueeze(-1), v.unsqueeze(-2))\n",
    "    numerator = numerator.sum(axis=2)\n",
    "    numerator = torch.matmul(q, numerator)\n",
    "    \n",
    "    denominator = k.sum(axis=2).unsqueeze(-1)\n",
    "    denominator = q.matmul(denominator)\n",
    "\n",
    "    out = numerator / denominator\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    #TODO: INSERT DROPOUT\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(SimpleAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    #self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v) #BS x HEADS x SEQ x HEAD_DIM\n",
    "\n",
    "    _, _, seq_len, _ = q.shape\n",
    "\n",
    "    kv = torch.matmul(k.transpose(-1, -2), v)\n",
    "    kv *= 1 / math.sqrt(seq_len)\n",
    "    kv = self.dropout(kv)\n",
    "\n",
    "    out = torch.matmul(q, kv)\n",
    "    #out *= 1 / math.sqrt(self.head_dim)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    #out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, mlp_dim, num_heads, dropout_rate):\n",
    "    super(TBlock, self).__init__()\n",
    "\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.qkv_dim  = qkv_dim\n",
    "    self.mlp_dim  = mlp_dim\n",
    "\n",
    "    self.layernorm_input = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "    self.layernorm_inter = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "    self.attention = TAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, mlp_dim), nn.GELU(), nn.Dropout(dropout_rate),\n",
    "        nn.Linear(mlp_dim, hidden_dim), nn.Dropout(dropout_rate),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input, losses=[]):\n",
    "    x = self.layernorm_input(input)\n",
    "    x = self.attention(x, losses)\n",
    "\n",
    "    x = input + x\n",
    "\n",
    "    y = self.layernorm_inter(x)\n",
    "    x = self.ffn(y) + x\n",
    "\n",
    "    return x\n",
    "\n",
    "class DualClassifier(nn.Module):\n",
    "  def __init__(self, classes, hidden_dim, inter_dim):\n",
    "    super(DualClassifier, self).__init__()\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim * 2, inter_dim), nn.ReLU(),\n",
    "        nn.Linear(inter_dim, inter_dim // 2), nn.ReLU(),\n",
    "    )\n",
    "    self.output    = nn.Linear(inter_dim // 2, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    emb_1, emb_2 = x\n",
    "    x = torch.cat([ emb_1, emb_2 ], dim=-1)\n",
    "    x = x[:, 0, :]\n",
    "    x = self.ffn(x)\n",
    "    logits = self.output(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, classes, num_embeddings, seq_len, hidden_dim, qkv_dim, mlp_dim, num_heads, num_blocks, internal_dropout_rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "    \n",
    "    self.embed_layer = TEmbedding(num_embeddings, hidden_dim, seq_len)\n",
    "    self.blocks      = nn.ModuleList([ TBlock(hidden_dim, qkv_dim, mlp_dim, num_heads, internal_dropout_rate) for _ in range(num_blocks) ])\n",
    "    self.classifier  = DualClassifier(classes, hidden_dim, mlp_dim)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    additional_losses = []\n",
    "\n",
    "    emb_1 = self.embed_layer(inputs[0])\n",
    "    emb_2 = self.embed_layer(inputs[1])\n",
    "\n",
    "    for block in self.blocks:\n",
    "      emb_1 = block(emb_1, additional_losses)\n",
    "      emb_2 = block(emb_2, additional_losses)\n",
    "    \n",
    "    x = self.classifier((emb_1, emb_2))\n",
    "\n",
    "    return x, additional_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kcYVjhG0pLjh",
    "outputId": "b9df946b-4016-475c-e786-b35f44ad7bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1617922 params, ratio 1.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91a6084a50>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_schedule(warmup_steps):\n",
    "  def lr_schedule(step):\n",
    "    return 1.0 * np.minimum(1.0, step / warmup_steps) / np.sqrt(np.maximum(step, warmup_steps))\n",
    "\n",
    "  return lr_schedule\n",
    "\n",
    "lr=0.05\n",
    "weight_decay=0.1\n",
    "warmup=8000\n",
    "\n",
    "\n",
    "def const_schedule(lr):\n",
    "  def lr_schedule(step):\n",
    "    return lr\n",
    "  return lr_schedule\n",
    "\n",
    "def training_setup():\n",
    "  model = model_factory()\n",
    "  criterion = nn.CrossEntropyLoss().cuda()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  schedule_func = get_schedule(warmup)\n",
    "  #schedule_func = const_schedule(1.0) #<--------- TEMPORARY\n",
    "  scheduler = LambdaLR(optimizer, schedule_func)\n",
    "\n",
    "  return model, criterion, optimizer, schedule_func, scheduler\n",
    "\n",
    "_, _, _, schedule_func, _ = training_setup()\n",
    "\n",
    "plt.plot([ lr * schedule_func(i) for i in range(15000) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Hkqxr5EdpQ_Z",
    "outputId": "3ea7ca82-cdd4-4c83-9798-890ddac80e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1617922 params, ratio 1.01\n",
      "Epoch 0\n",
      "[====================] 200/200: - running_loss: 0.6835 - running_reg: 0.000000 - running_acc: 0.5578 - lr: 0.00001 - epoch_loss: 0.6906 - epoch_reg: 0.000000 - epoch_acc: 0.5256 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 104.1449 s\n",
      "Epoch 1\n",
      "[====================] 200/200: - running_loss: 0.6901 - running_reg: 0.000000 - running_acc: 0.5432 - lr: 0.00003 - epoch_loss: 0.6853 - epoch_reg: 0.000000 - epoch_acc: 0.5416 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 98.1498 s\n",
      "Epoch 2\n",
      "[====================] 200/200: - running_loss: 0.6921 - running_reg: 0.000000 - running_acc: 0.5284 - lr: 0.00004 - epoch_loss: 0.6941 - epoch_reg: 0.000000 - epoch_acc: 0.5078 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 98.6038 s\n",
      "Epoch 3\n",
      "[====================] 200/200: - running_loss: 0.6943 - running_reg: 0.000000 - running_acc: 0.4873 - lr: 0.00006 - epoch_loss: 0.6933 - epoch_reg: 0.000000 - epoch_acc: 0.5083 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 98.7471 s\n",
      "Epoch 4\n",
      "[====================] 200/200: - running_loss: 0.6910 - running_reg: 0.000000 - running_acc: 0.5275 - lr: 0.00007 - epoch_loss: 0.6924 - epoch_reg: 0.000000 - epoch_acc: 0.5180 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 98.9303 s\n",
      "Epoch 5\n",
      "[====================] 200/200: - running_loss: 0.6723 - running_reg: 0.000000 - running_acc: 0.5801 - lr: 0.00008 - epoch_loss: 0.6880 - epoch_reg: 0.000000 - epoch_acc: 0.5425 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.2186 s\n",
      "Epoch 6\n",
      "[====================] 200/200: - running_loss: 0.5647 - running_reg: 0.000000 - running_acc: 0.7170 - lr: 0.00010 - epoch_loss: 0.6405 - epoch_reg: 0.000000 - epoch_acc: 0.6264 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 101.3267 s\n",
      "Epoch 7\n",
      "[====================] 200/200: - running_loss: 0.5923 - running_reg: 0.000000 - running_acc: 0.6822 - lr: 0.00011 - epoch_loss: 0.5873 - epoch_reg: 0.000000 - epoch_acc: 0.6858 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 101.5669 s\n",
      "Epoch 8\n",
      "[====================] 200/200: - running_loss: 0.6617 - running_reg: 0.000000 - running_acc: 0.5614 - lr: 0.00013 - epoch_loss: 0.6316 - epoch_reg: 0.000000 - epoch_acc: 0.6250 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 101.0023 s\n",
      "Epoch 9\n",
      "[====================] 200/200: - running_loss: 0.5567 - running_reg: 0.000000 - running_acc: 0.7204 - lr: 0.00014 - epoch_loss: 0.6089 - epoch_reg: 0.000000 - epoch_acc: 0.6681 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.7029 s\n",
      "Epoch 10\n",
      "[====================] 200/200: - running_loss: 0.5738 - running_reg: 0.000000 - running_acc: 0.6955 - lr: 0.00015 - epoch_loss: 0.5749 - epoch_reg: 0.000000 - epoch_acc: 0.6944 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6045 s\n",
      "Epoch 11\n",
      "[====================] 200/200: - running_loss: 0.5589 - running_reg: 0.000000 - running_acc: 0.7028 - lr: 0.00017 - epoch_loss: 0.5560 - epoch_reg: 0.000000 - epoch_acc: 0.7084 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.7121 s\n",
      "Epoch 12\n",
      "[====================] 200/200: - running_loss: 0.5787 - running_reg: 0.000000 - running_acc: 0.6893 - lr: 0.00018 - epoch_loss: 0.5777 - epoch_reg: 0.000000 - epoch_acc: 0.6836 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6259 s\n",
      "Epoch 13\n",
      "[====================] 200/200: - running_loss: 0.6055 - running_reg: 0.000000 - running_acc: 0.6866 - lr: 0.00020 - epoch_loss: 0.5868 - epoch_reg: 0.000000 - epoch_acc: 0.6737 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6646 s\n",
      "Epoch 14\n",
      "[====================] 200/200: - running_loss: 0.5870 - running_reg: 0.000000 - running_acc: 0.6981 - lr: 0.00021 - epoch_loss: 0.5989 - epoch_reg: 0.000000 - epoch_acc: 0.6761 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6601 s\n",
      "Epoch 15\n",
      "[====================] 200/200: - running_loss: 0.5660 - running_reg: 0.000000 - running_acc: 0.6875 - lr: 0.00022 - epoch_loss: 0.5637 - epoch_reg: 0.000000 - epoch_acc: 0.6972 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.5624 s\n",
      "Epoch 16\n",
      "[====================] 200/200: - running_loss: 0.5856 - running_reg: 0.000000 - running_acc: 0.6666 - lr: 0.00024 - epoch_loss: 0.5365 - epoch_reg: 0.000000 - epoch_acc: 0.7198 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.5131 s\n",
      "Epoch 17\n",
      "[====================] 200/200: - running_loss: 0.6109 - running_reg: 0.000000 - running_acc: 0.6690 - lr: 0.00025 - epoch_loss: 0.5742 - epoch_reg: 0.000000 - epoch_acc: 0.6981 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 98.4643 s\n",
      "Epoch 18\n",
      "[====================] 200/200: - running_loss: 0.6126 - running_reg: 0.000000 - running_acc: 0.6545 - lr: 0.00027 - epoch_loss: 0.6187 - epoch_reg: 0.000000 - epoch_acc: 0.6533 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 99.0259 s\n",
      "Epoch 19\n",
      "[====================] 200/200: - running_loss: 0.6375 - running_reg: 0.000000 - running_acc: 0.6404 - lr: 0.00028 - epoch_loss: 0.6384 - epoch_reg: 0.000000 - epoch_acc: 0.6319 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.7200 s\n",
      "Epoch 20\n",
      "[====================] 200/200: - running_loss: 0.6259 - running_reg: 0.000000 - running_acc: 0.6300 - lr: 0.00029 - epoch_loss: 0.6329 - epoch_reg: 0.000000 - epoch_acc: 0.6266 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.8610 s\n",
      "Epoch 21\n",
      "[====================] 200/200: - running_loss: 0.6125 - running_reg: 0.000000 - running_acc: 0.6389 - lr: 0.00031 - epoch_loss: 0.6059 - epoch_reg: 0.000000 - epoch_acc: 0.6561 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6638 s\n",
      "Epoch 22\n",
      "[====================] 200/200: - running_loss: 0.6155 - running_reg: 0.000000 - running_acc: 0.6115 - lr: 0.00032 - epoch_loss: 0.5991 - epoch_reg: 0.000000 - epoch_acc: 0.6534 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 102.3875 s\n",
      "Epoch 23\n",
      "[====================] 200/200: - running_loss: 0.5376 - running_reg: 0.000000 - running_acc: 0.7114 - lr: 0.00034 - epoch_loss: 0.5576 - epoch_reg: 0.000000 - epoch_acc: 0.6995 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6585 s\n",
      "Epoch 24\n",
      "[====================] 200/200: - running_loss: 0.6031 - running_reg: 0.000000 - running_acc: 0.6745 - lr: 0.00035 - epoch_loss: 0.5740 - epoch_reg: 0.000000 - epoch_acc: 0.6931 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.8097 s\n",
      "Epoch 25\n",
      "[====================] 200/200: - running_loss: 0.6156 - running_reg: 0.000000 - running_acc: 0.6623 - lr: 0.00036 - epoch_loss: 0.5949 - epoch_reg: 0.000000 - epoch_acc: 0.6816 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6843 s\n",
      "Epoch 26\n",
      "[====================] 200/200: - running_loss: 0.6154 - running_reg: 0.000000 - running_acc: 0.6429 - lr: 0.00038 - epoch_loss: 0.5981 - epoch_reg: 0.000000 - epoch_acc: 0.6652 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.6861 s\n",
      "Epoch 27\n",
      "[====================] 200/200: - running_loss: 0.5424 - running_reg: 0.000000 - running_acc: 0.7277 - lr: 0.00039 - epoch_loss: 0.5885 - epoch_reg: 0.000000 - epoch_acc: 0.6814 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.8430 s\n",
      "Epoch 28\n",
      "[====================] 200/200: - running_loss: 0.4259 - running_reg: 0.000000 - running_acc: 0.7975 - lr: 0.00041 - epoch_loss: 0.5120 - epoch_reg: 0.000000 - epoch_acc: 0.7409 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.9193 s\n",
      "Epoch 29\n",
      "[====================] 200/200: - running_loss: 0.3485 - running_reg: 0.000000 - running_acc: 0.8379 - lr: 0.00042 - epoch_loss: 0.3928 - epoch_reg: 0.000000 - epoch_acc: 0.8228 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 100.8374 s\n",
      "Epoch 30\n",
      "[====================] 200/200: - running_loss: 0.4168 - running_reg: 0.000000 - running_acc: 0.7990 - lr: 0.00043 - epoch_loss: 0.3862 - epoch_reg: 0.000000 - epoch_acc: 0.8247 - valid_loss: 0.6650 - valid_reg: 0.000000 - valid_acc: 0.6267 - epoch_time: 211.0202 s\n",
      "Epoch 31\n",
      "[====================] 200/200: - running_loss: 0.5044 - running_reg: 0.000000 - running_acc: 0.7384 - lr: 0.00045 - epoch_loss: 0.4838 - epoch_reg: 0.000000 - epoch_acc: 0.7563 - valid_loss: 0.6599 - valid_reg: 0.000000 - valid_acc: 0.6295 - epoch_time: 216.0970 s\n",
      "Epoch 32\n",
      "[====================] 200/200: - running_loss: 0.4582 - running_reg: 0.000000 - running_acc: 0.7906 - lr: 0.00046 - epoch_loss: 0.4910 - epoch_reg: 0.000000 - epoch_acc: 0.7566 - valid_loss: 0.7336 - valid_reg: 0.000000 - valid_acc: 0.6382 - epoch_time: 212.8339 s\n",
      "Epoch 33\n",
      "[====================] 200/200: - running_loss: 0.4619 - running_reg: 0.000000 - running_acc: 0.7907 - lr: 0.00048 - epoch_loss: 0.4608 - epoch_reg: 0.000000 - epoch_acc: 0.7698 - valid_loss: 0.7737 - valid_reg: 0.000000 - valid_acc: 0.6345 - epoch_time: 213.0669 s\n",
      "Epoch 34\n",
      "[====================] 200/200: - running_loss: 0.4613 - running_reg: 0.000000 - running_acc: 0.7695 - lr: 0.00049 - epoch_loss: 0.4638 - epoch_reg: 0.000000 - epoch_acc: 0.7775 - valid_loss: 0.7246 - valid_reg: 0.000000 - valid_acc: 0.6481 - epoch_time: 212.1202 s\n",
      "Epoch 35\n",
      "[====================] 200/200: - running_loss: 0.4799 - running_reg: 0.000000 - running_acc: 0.7693 - lr: 0.00050 - epoch_loss: 0.4688 - epoch_reg: 0.000000 - epoch_acc: 0.7738 - valid_loss: 1.0256 - valid_reg: 0.000000 - valid_acc: 0.6390 - epoch_time: 214.3297 s\n",
      "Epoch 36\n",
      "[====================] 200/200: - running_loss: 0.4856 - running_reg: 0.000000 - running_acc: 0.7632 - lr: 0.00052 - epoch_loss: 0.5001 - epoch_reg: 0.000000 - epoch_acc: 0.7536 - valid_loss: 0.9648 - valid_reg: 0.000000 - valid_acc: 0.5991 - epoch_time: 214.0108 s\n",
      "Epoch 37\n",
      "[====================] 200/200: - running_loss: 0.5474 - running_reg: 0.000000 - running_acc: 0.7162 - lr: 0.00053 - epoch_loss: 0.5279 - epoch_reg: 0.000000 - epoch_acc: 0.7303 - valid_loss: 0.5854 - valid_reg: 0.000000 - valid_acc: 0.6801 - epoch_time: 215.7772 s\n",
      "Epoch 38\n",
      "[====================] 200/200: - running_loss: 0.4896 - running_reg: 0.000000 - running_acc: 0.7748 - lr: 0.00054 - epoch_loss: 0.5179 - epoch_reg: 0.000000 - epoch_acc: 0.7430 - valid_loss: 0.5774 - valid_reg: 0.000000 - valid_acc: 0.6916 - epoch_time: 216.9098 s\n",
      "Epoch 39\n",
      "[====================] 200/200: - running_loss: 0.4961 - running_reg: 0.000000 - running_acc: 0.7410 - lr: 0.00056 - epoch_loss: 0.4817 - epoch_reg: 0.000000 - epoch_acc: 0.7583 - valid_loss: 0.5913 - valid_reg: 0.000000 - valid_acc: 0.6935 - epoch_time: 218.6696 s\n",
      "Epoch 40\n",
      "[====================] 200/200: - running_loss: 0.5443 - running_reg: 0.000000 - running_acc: 0.7218 - lr: 0.00055 - epoch_loss: 0.5352 - epoch_reg: 0.000000 - epoch_acc: 0.7287 - valid_loss: 0.6129 - valid_reg: 0.000000 - valid_acc: 0.6854 - epoch_time: 222.8671 s\n",
      "Epoch 41\n",
      "[====================] 200/200: - running_loss: 0.5960 - running_reg: 0.000000 - running_acc: 0.6673 - lr: 0.00055 - epoch_loss: 0.5737 - epoch_reg: 0.000000 - epoch_acc: 0.6927 - valid_loss: 0.6040 - valid_reg: 0.000000 - valid_acc: 0.6710 - epoch_time: 215.8628 s\n",
      "Epoch 42\n",
      "[====================] 200/200: - running_loss: 0.5760 - running_reg: 0.000000 - running_acc: 0.6691 - lr: 0.00054 - epoch_loss: 0.5773 - epoch_reg: 0.000000 - epoch_acc: 0.6870 - valid_loss: 0.5883 - valid_reg: 0.000000 - valid_acc: 0.6837 - epoch_time: 212.3259 s\n",
      "Epoch 43\n",
      "[====================] 200/200: - running_loss: 0.5580 - running_reg: 0.000000 - running_acc: 0.6959 - lr: 0.00053 - epoch_loss: 0.5714 - epoch_reg: 0.000000 - epoch_acc: 0.6927 - valid_loss: 0.5974 - valid_reg: 0.000000 - valid_acc: 0.6783 - epoch_time: 221.9659 s\n",
      "Epoch 44\n",
      "[====================] 200/200: - running_loss: 0.5270 - running_reg: 0.000000 - running_acc: 0.7049 - lr: 0.00053 - epoch_loss: 0.5564 - epoch_reg: 0.000000 - epoch_acc: 0.6939 - valid_loss: 0.6385 - valid_reg: 0.000000 - valid_acc: 0.6373 - epoch_time: 218.3823 s\n",
      "Epoch 45\n",
      "[====================] 200/200: - running_loss: 0.5945 - running_reg: 0.000000 - running_acc: 0.6639 - lr: 0.00052 - epoch_loss: 0.5328 - epoch_reg: 0.000000 - epoch_acc: 0.7159 - valid_loss: 0.6275 - valid_reg: 0.000000 - valid_acc: 0.6368 - epoch_time: 215.6829 s\n",
      "Epoch 46\n",
      "[====================] 200/200: - running_loss: 0.5180 - running_reg: 0.000000 - running_acc: 0.7217 - lr: 0.00052 - epoch_loss: 0.5306 - epoch_reg: 0.000000 - epoch_acc: 0.7089 - valid_loss: 0.6082 - valid_reg: 0.000000 - valid_acc: 0.6582 - epoch_time: 214.6417 s\n",
      "Epoch 47\n",
      "[====================] 200/200: - running_loss: 0.5373 - running_reg: 0.000000 - running_acc: 0.7214 - lr: 0.00051 - epoch_loss: 0.5242 - epoch_reg: 0.000000 - epoch_acc: 0.7278 - valid_loss: 0.5931 - valid_reg: 0.000000 - valid_acc: 0.6861 - epoch_time: 219.1451 s\n",
      "Epoch 48\n",
      "[====================] 200/200: - running_loss: 0.5014 - running_reg: 0.000000 - running_acc: 0.7496 - lr: 0.00051 - epoch_loss: 0.5262 - epoch_reg: 0.000000 - epoch_acc: 0.7339 - valid_loss: 0.6045 - valid_reg: 0.000000 - valid_acc: 0.6767 - epoch_time: 224.1384 s\n",
      "Epoch 49\n",
      "[====================] 200/200: - running_loss: 0.5105 - running_reg: 0.000000 - running_acc: 0.7445 - lr: 0.00050 - epoch_loss: 0.5219 - epoch_reg: 0.000000 - epoch_acc: 0.7431 - valid_loss: 0.5860 - valid_reg: 0.000000 - valid_acc: 0.6721 - epoch_time: 215.5069 s\n",
      "Epoch 50\n",
      "[====================] 200/200: - running_loss: 0.4873 - running_reg: 0.000000 - running_acc: 0.7524 - lr: 0.00050 - epoch_loss: 0.5013 - epoch_reg: 0.000000 - epoch_acc: 0.7423 - valid_loss: 0.5626 - valid_reg: 0.000000 - valid_acc: 0.6999 - epoch_time: 216.8683 s\n",
      "Epoch 51\n",
      "[====================] 200/200: - running_loss: 0.3307 - running_reg: 0.000000 - running_acc: 0.8628 - lr: 0.00049 - epoch_loss: 0.3837 - epoch_reg: 0.000000 - epoch_acc: 0.8220 - valid_loss: 0.6832 - valid_reg: 0.000000 - valid_acc: 0.6658 - epoch_time: 224.2634 s\n",
      "Epoch 52\n",
      "[====================] 200/200: - running_loss: 0.2806 - running_reg: 0.000000 - running_acc: 0.8891 - lr: 0.00049 - epoch_loss: 0.2981 - epoch_reg: 0.000000 - epoch_acc: 0.8794 - valid_loss: 0.7403 - valid_reg: 0.000000 - valid_acc: 0.6260 - epoch_time: 226.5229 s\n",
      "Epoch 53\n",
      "[====================] 200/200: - running_loss: 0.3332 - running_reg: 0.000000 - running_acc: 0.8572 - lr: 0.00048 - epoch_loss: 0.3153 - epoch_reg: 0.000000 - epoch_acc: 0.8670 - valid_loss: 0.6141 - valid_reg: 0.000000 - valid_acc: 0.6877 - epoch_time: 225.5760 s\n",
      "Epoch 54\n",
      "[====================] 200/200: - running_loss: 0.4208 - running_reg: 0.000000 - running_acc: 0.8043 - lr: 0.00048 - epoch_loss: 0.3904 - epoch_reg: 0.000000 - epoch_acc: 0.8231 - valid_loss: 0.5712 - valid_reg: 0.000000 - valid_acc: 0.7103 - epoch_time: 221.5608 s\n",
      "Epoch 55\n",
      "[====================] 200/200: - running_loss: 0.3492 - running_reg: 0.000000 - running_acc: 0.8485 - lr: 0.00047 - epoch_loss: 0.4018 - epoch_reg: 0.000000 - epoch_acc: 0.8120 - valid_loss: 0.7029 - valid_reg: 0.000000 - valid_acc: 0.6800 - epoch_time: 223.5826 s\n",
      "Epoch 56\n",
      "[====================] 200/200: - running_loss: 0.3111 - running_reg: 0.000000 - running_acc: 0.8626 - lr: 0.00047 - epoch_loss: 0.3550 - epoch_reg: 0.000000 - epoch_acc: 0.8394 - valid_loss: 0.6783 - valid_reg: 0.000000 - valid_acc: 0.6847 - epoch_time: 223.9109 s\n",
      "Epoch 57\n",
      "[====================] 200/200: - running_loss: 0.3733 - running_reg: 0.000000 - running_acc: 0.8373 - lr: 0.00046 - epoch_loss: 0.3315 - epoch_reg: 0.000000 - epoch_acc: 0.8497 - valid_loss: 0.6959 - valid_reg: 0.000000 - valid_acc: 0.6754 - epoch_time: 217.5259 s\n",
      "Epoch 58\n",
      "[====================] 200/200: - running_loss: 0.3772 - running_reg: 0.000000 - running_acc: 0.8346 - lr: 0.00046 - epoch_loss: 0.3582 - epoch_reg: 0.000000 - epoch_acc: 0.8397 - valid_loss: 0.7524 - valid_reg: 0.000000 - valid_acc: 0.6769 - epoch_time: 216.7120 s\n",
      "Epoch 59\n",
      "[====================] 200/200: - running_loss: 0.4458 - running_reg: 0.000000 - running_acc: 0.7904 - lr: 0.00046 - epoch_loss: 0.4141 - epoch_reg: 0.000000 - epoch_acc: 0.8042 - valid_loss: 0.7718 - valid_reg: 0.000000 - valid_acc: 0.6792 - epoch_time: 223.8186 s\n",
      "Epoch 60\n",
      "[====================] 200/200: - running_loss: 0.4869 - running_reg: 0.000000 - running_acc: 0.7585 - lr: 0.00045 - epoch_loss: 0.4733 - epoch_reg: 0.000000 - epoch_acc: 0.7658 - valid_loss: 0.5420 - valid_reg: 0.000000 - valid_acc: 0.7209 - epoch_time: 218.0924 s\n",
      "Epoch 61\n",
      "[====================] 200/200: - running_loss: 0.4230 - running_reg: 0.000000 - running_acc: 0.7966 - lr: 0.00045 - epoch_loss: 0.4348 - epoch_reg: 0.000000 - epoch_acc: 0.7944 - valid_loss: 0.5717 - valid_reg: 0.000000 - valid_acc: 0.6991 - epoch_time: 218.6260 s\n",
      "Epoch 62\n",
      "[====================] 200/200: - running_loss: 0.4325 - running_reg: 0.000000 - running_acc: 0.7898 - lr: 0.00045 - epoch_loss: 0.4313 - epoch_reg: 0.000000 - epoch_acc: 0.7944 - valid_loss: 0.5390 - valid_reg: 0.000000 - valid_acc: 0.7273 - epoch_time: 223.4957 s\n",
      "Epoch 63\n",
      "[====================] 200/200: - running_loss: 0.4916 - running_reg: 0.000000 - running_acc: 0.7501 - lr: 0.00044 - epoch_loss: 0.4643 - epoch_reg: 0.000000 - epoch_acc: 0.7692 - valid_loss: 0.5539 - valid_reg: 0.000000 - valid_acc: 0.7033 - epoch_time: 223.4259 s\n",
      "Epoch 64\n",
      "[====================] 200/200: - running_loss: 0.5065 - running_reg: 0.000000 - running_acc: 0.7369 - lr: 0.00044 - epoch_loss: 0.4993 - epoch_reg: 0.000000 - epoch_acc: 0.7483 - valid_loss: 0.5211 - valid_reg: 0.000000 - valid_acc: 0.7318 - epoch_time: 225.9373 s\n",
      "Epoch 65\n",
      "[====================] 200/200: - running_loss: 0.5007 - running_reg: 0.000000 - running_acc: 0.7341 - lr: 0.00044 - epoch_loss: 0.4923 - epoch_reg: 0.000000 - epoch_acc: 0.7486 - valid_loss: 0.5705 - valid_reg: 0.000000 - valid_acc: 0.7091 - epoch_time: 226.2707 s\n",
      "Epoch 66\n",
      "[====================] 200/200: - running_loss: 0.5183 - running_reg: 0.000000 - running_acc: 0.7303 - lr: 0.00043 - epoch_loss: 0.5302 - epoch_reg: 0.000000 - epoch_acc: 0.7105 - valid_loss: 0.5580 - valid_reg: 0.000000 - valid_acc: 0.7075 - epoch_time: 217.4931 s\n",
      "Epoch 67\n",
      "[====================] 200/200: - running_loss: 0.4857 - running_reg: 0.000000 - running_acc: 0.7546 - lr: 0.00043 - epoch_loss: 0.4991 - epoch_reg: 0.000000 - epoch_acc: 0.7439 - valid_loss: 0.5638 - valid_reg: 0.000000 - valid_acc: 0.7051 - epoch_time: 224.3400 s\n",
      "Epoch 68\n",
      "[====================] 200/200: - running_loss: 0.5348 - running_reg: 0.000000 - running_acc: 0.7180 - lr: 0.00043 - epoch_loss: 0.4993 - epoch_reg: 0.000000 - epoch_acc: 0.7402 - valid_loss: 0.5667 - valid_reg: 0.000000 - valid_acc: 0.6982 - epoch_time: 226.4461 s\n",
      "Epoch 69\n",
      "[====================] 200/200: - running_loss: 0.4830 - running_reg: 0.000000 - running_acc: 0.7585 - lr: 0.00042 - epoch_loss: 0.4798 - epoch_reg: 0.000000 - epoch_acc: 0.7625 - valid_loss: 0.5984 - valid_reg: 0.000000 - valid_acc: 0.6790 - epoch_time: 225.1278 s\n",
      "Epoch 70\n",
      "[====================] 200/200: - running_loss: 0.4783 - running_reg: 0.000000 - running_acc: 0.7690 - lr: 0.00042 - epoch_loss: 0.4417 - epoch_reg: 0.000000 - epoch_acc: 0.7944 - valid_loss: 0.5862 - valid_reg: 0.000000 - valid_acc: 0.7043 - epoch_time: 217.6204 s\n",
      "Epoch 71\n",
      "[====================] 200/200: - running_loss: 0.5083 - running_reg: 0.000000 - running_acc: 0.7694 - lr: 0.00042 - epoch_loss: 0.4810 - epoch_reg: 0.000000 - epoch_acc: 0.7692 - valid_loss: 0.5864 - valid_reg: 0.000000 - valid_acc: 0.6795 - epoch_time: 224.3446 s\n",
      "Epoch 72\n",
      "[====================] 200/200: - running_loss: 0.4926 - running_reg: 0.000000 - running_acc: 0.7673 - lr: 0.00041 - epoch_loss: 0.4614 - epoch_reg: 0.000000 - epoch_acc: 0.7806 - valid_loss: 0.5423 - valid_reg: 0.000000 - valid_acc: 0.7180 - epoch_time: 226.3062 s\n",
      "Epoch 73\n",
      "[====================] 200/200: - running_loss: 0.3644 - running_reg: 0.000000 - running_acc: 0.8476 - lr: 0.00041 - epoch_loss: 0.4315 - epoch_reg: 0.000000 - epoch_acc: 0.7981 - valid_loss: 0.5789 - valid_reg: 0.000000 - valid_acc: 0.7214 - epoch_time: 226.0829 s\n",
      "Epoch 74\n",
      "[====================] 200/200: - running_loss: 0.2485 - running_reg: 0.000000 - running_acc: 0.8952 - lr: 0.00041 - epoch_loss: 0.3213 - epoch_reg: 0.000000 - epoch_acc: 0.8580 - valid_loss: 0.7299 - valid_reg: 0.000000 - valid_acc: 0.6917 - epoch_time: 216.4717 s\n",
      " - test_loss: 0.5307 - test_reg: 0.000000 - test_acc: 0.7217 - test_time: 103.2981 s\n",
      "\n",
      "Total accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(1): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup()\n",
    "\n",
    "  checkpoint = train_model(model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, 75, 200, skip_eval=30)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = test(model, criterion, test_dataset)\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkYMZ_UrpRpM"
   },
   "outputs": [],
   "source": [
    "GLU: 0.7217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7l6zeg4w5f69"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TEmbedding(nn.Module):\n",
    "  def __init__(self, num_embeddings, hidden_dim, seq_length=1024, padding_idx=0):\n",
    "    super(TEmbedding, self).__init__()\n",
    "    \n",
    "    self.num_embeddings = num_embeddings\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.seq_length = seq_length\n",
    "    self.padding_idx = padding_idx\n",
    "\n",
    "    self.embedding = nn.Embedding(num_embeddings, hidden_dim, padding_idx)\n",
    "    self.pos_embeds  = nn.Parameter(torch.zeros(1, self.seq_length, self.hidden_dim))\n",
    "\n",
    "    self.cls = nn.Parameter(torch.zeros(1, 1, self.hidden_dim)) #!!!!!!! INIT WITH ANOTHER VALUE IF REQUIRED\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size, seq_len = input.shape\n",
    "    \n",
    "    embed = self.embedding(input)\n",
    "    embed = embed + self.pos_embeds\n",
    "    embed = torch.cat([ self.cls.expand(batch_size, 1, -1), embed ], axis=1)\n",
    "\n",
    "    return embed\n",
    "    \n",
    "class TAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(TAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "    \n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "\n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    q = torch.mul(q, 1. / torch.sqrt(torch.tensor(self.qkv_dim)))\n",
    "\n",
    "    qk = torch.matmul(q, k.transpose(-1, -2))\n",
    "    qk = nn.Softmax(dim=-1)(qk)\n",
    "\n",
    "    def assertion_function(tsr):\n",
    "      tsr = torch.sum(tsr, axis=-1)\n",
    "      tsr = tsr - torch.ones_like(tsr)\n",
    "      return torch.max(torch.abs(tsr)) < 1e-5\n",
    "\n",
    "    assert assertion_function(qk)\n",
    "\n",
    "    qk = self.dropout(qk) #Like in TF implementation; could be done before Softmax by random -inf addition\n",
    "\n",
    "    out = torch.matmul(qk, v)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "\n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class HWLinear(nn.Module):\n",
    "  def __init__(self, num_heads, input_dim, output_dim, use_bias):\n",
    "    super(HWLinear, self).__init__()\n",
    "    \n",
    "    self.use_bias = use_bias\n",
    "    if use_bias:\n",
    "      self.bias   = nn.Parameter(torch.zeros( (1, num_heads, 1, output_dim)))\n",
    "\n",
    "    self.weight = nn.Parameter(torch.empty( (num_heads, input_dim, output_dim)))\n",
    "\n",
    "    def he_init(m):\n",
    "      s =  np.sqrt( 2. / input_dim )\n",
    "      m.data.normal_(0, s)\n",
    "\n",
    "    he_init(self.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.matmul(x, self.weight)\n",
    "    if self.use_bias:\n",
    "      x += self.bias\n",
    "    return x\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "  def __init__(self, lambda_, objects=None):\n",
    "      super(Lambda, self).__init__()\n",
    "      self.lambda_ = lambda_\n",
    "      self.objects = objects\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.objects is not None:\n",
    "      return self.lambda_(self.objects, x)\n",
    "    return self.lambda_(x)\n",
    "\n",
    "class LKAAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(LKAAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   = qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    #self.lka = nn.Sequential(\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.GELU(),\n",
    "    #  nn.Linear(self.head_dim, self.head_dim), nn.Softplus(beta=2.5),\n",
    "    #)\n",
    "\n",
    "    #256, 4, 16, 1024\n",
    "    #256, 64, 1, 1024\n",
    "    class AMGOLU(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, gate_rank, dropout_rate, gate_nonlinearity, kernel_nonlinearity, use_bias=False):\n",
    "        super(AMGOLU, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads= num_heads\n",
    "        \n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "\n",
    "        self.gate_weight_a = HWLinear(num_heads, self.head_dim, gate_rank, use_bias)\n",
    "        self.gate_weight_b = HWLinear(num_heads, gate_rank, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        forward_info = self.orth_weight(x)\n",
    "        forward_info = self.kernel_nonlinearity(forward_info)\n",
    "\n",
    "        gate_info = self.gate_weight_a(x)\n",
    "        gate_info = self.gate_weight_b(gate_info)\n",
    "        gate_info = self.gate_nonlinearity(gate_info)\n",
    "\n",
    "        x = forward_info * gate_info\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    class GatedOrthoKernel(nn.Module):\n",
    "      def __init__(self, num_heads, qkv_dim, dropout_rate=0.1, gate_nonlinearity=nn.Sigmoid(), kernel_nonlinearity=nn.Identity(), use_bias=False):\n",
    "        super(GatedOrthoKernel, self).__init__()\n",
    "\n",
    "        self.head_dim = qkv_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.orth_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "        self.orth_weight.weight = nn.Parameter(torch.stack([ nn.init.orthogonal_(torch.empty((self.head_dim, self.head_dim))) for _ in range(num_heads) ], dim=0))\n",
    "        self.gate_weight = HWLinear(num_heads, self.head_dim, self.head_dim, use_bias)\n",
    "\n",
    "        self.kernel_nonlinearity = kernel_nonlinearity\n",
    "        self.gate_nonlinearity   = gate_nonlinearity\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "      def forward(self, x):\n",
    "        x, losses = x\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.kernel_nonlinearity(self.orth_weight(x)) * self.gate_nonlinearity(self.gate_weight(x))\n",
    "        \n",
    "        loss = torch.eye(self.head_dim, device=self.orth_weight.weight.device).unsqueeze(0).expand(self.num_heads, -1, -1)\n",
    "        loss = nn.MSELoss()(torch.matmul(self.orth_weight.weight, self.orth_weight.weight.transpose(-1, -2)), loss)\n",
    "        loss *= LAMBDA\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        return x, losses\n",
    "\n",
    "    self.lka = nn.Sequential(\n",
    "        \n",
    "        AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        AMGOLU(self.num_heads, self.qkv_dim, self.head_dim // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False),\n",
    "        \n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False),\n",
    "        #GatedOrthoKernel(self.num_heads, self.qkv_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False)\n",
    "\n",
    "        #Lambda(lambda o, x: (o['act'](x[0]), x[1]), { 'act' : nn.Identity() })\n",
    "        \n",
    "    )\n",
    "\n",
    "    self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "    #BS x HEADS x SEQ x HEAD_DIM\n",
    "    \n",
    "    q, _ = self.lka((q, losses))\n",
    "    k, _ = self.lka((k, losses)) #Use this for var kernel\n",
    "\n",
    "    q = q / math.sqrt(self.head_dim)\n",
    "    k = k / math.sqrt(self.head_dim)\n",
    "\n",
    "    numerator = torch.matmul(k.unsqueeze(-1), v.unsqueeze(-2))\n",
    "    numerator = numerator.sum(axis=2)\n",
    "    numerator = torch.matmul(q, numerator)\n",
    "    \n",
    "    denominator = k.sum(axis=2).unsqueeze(-1)\n",
    "    denominator = q.matmul(denominator)\n",
    "\n",
    "    out = numerator / denominator\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    #TODO: INSERT DROPOUT\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    super(SimpleAttention, self).__init__()\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.qkv_dim   =qkv_dim\n",
    "    self.num_heads =num_heads\n",
    "\n",
    "    assert not qkv_dim % num_heads\n",
    "    \n",
    "    self.head_dim = qkv_dim // num_heads\n",
    "    \n",
    "    self.q = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.k = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "    self.v = nn.Linear(self.hidden_dim, self.qkv_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    #self.lin = nn.Linear(self.qkv_dim, self.hidden_dim)\n",
    "\n",
    "  def split_heads(self, x):\n",
    "    new_shape = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(* new_shape)\n",
    "    return x.permute(0, 2, 1, 3)\n",
    "\n",
    "  def forward(self, x, losses=[]):\n",
    "    q = self.q(x)\n",
    "    k = self.k(x)\n",
    "    v = self.v(x)\n",
    "\n",
    "    q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v) #BS x HEADS x SEQ x HEAD_DIM\n",
    "\n",
    "    _, _, seq_len, _ = q.shape\n",
    "\n",
    "    kv = torch.matmul(k.transpose(-1, -2), v)\n",
    "    kv *= 1 / math.sqrt(seq_len)\n",
    "    kv = self.dropout(kv)\n",
    "\n",
    "    out = torch.matmul(q, kv)\n",
    "    #out *= 1 / math.sqrt(self.head_dim)\n",
    "    out = out.permute(0, 2, 1, 3)\n",
    "    \n",
    "    new_shape = out.shape[:-2] + (self.qkv_dim,)\n",
    "    out = out.reshape(* new_shape)\n",
    "\n",
    "    #out = self.lin(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "  def __init__(self, hidden_dim, qkv_dim, mlp_dim, num_heads, dropout_rate):\n",
    "    super(TBlock, self).__init__()\n",
    "\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.qkv_dim  = qkv_dim\n",
    "    self.mlp_dim  = mlp_dim\n",
    "\n",
    "    self.layernorm_input = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "    self.layernorm_inter = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "    self.attention = TAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, mlp_dim), nn.GELU(), nn.Dropout(dropout_rate),\n",
    "        nn.Linear(mlp_dim, hidden_dim), nn.Dropout(dropout_rate),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input, losses=[]):\n",
    "    x = self.layernorm_input(input)\n",
    "    x = self.attention(x, losses)\n",
    "\n",
    "    x = input + x\n",
    "\n",
    "    y = self.layernorm_inter(x)\n",
    "    x = self.ffn(y) + x\n",
    "\n",
    "    return x\n",
    "\n",
    "class DualClassifier(nn.Module):\n",
    "  def __init__(self, classes, hidden_dim, inter_dim):\n",
    "    super(DualClassifier, self).__init__()\n",
    "\n",
    "    self.ffn       = nn.Sequential(\n",
    "        nn.Linear(hidden_dim * 2, inter_dim), nn.ReLU(),\n",
    "        nn.Linear(inter_dim, inter_dim // 2), nn.ReLU(),\n",
    "    )\n",
    "    self.output    = nn.Linear(inter_dim // 2, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    emb_1, emb_2 = x\n",
    "    x = torch.cat([ emb_1, emb_2 ], dim=-1)\n",
    "    x = x[:, 0, :]\n",
    "    x = self.ffn(x)\n",
    "    logits = self.output(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, classes, num_embeddings, seq_len, hidden_dim, qkv_dim, mlp_dim, num_heads, num_blocks, internal_dropout_rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "    \n",
    "    self.embed_layer = TEmbedding(num_embeddings, hidden_dim, seq_len)\n",
    "    self.blocks      = nn.ModuleList([ TBlock(hidden_dim, qkv_dim, mlp_dim, num_heads, internal_dropout_rate) for _ in range(num_blocks) ])\n",
    "    self.classifier  = DualClassifier(classes, hidden_dim, mlp_dim)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    additional_losses = []\n",
    "\n",
    "    emb_1 = self.embed_layer(inputs[0])\n",
    "    emb_2 = self.embed_layer(inputs[1])\n",
    "\n",
    "    for block in self.blocks:\n",
    "      emb_1 = block(emb_1, additional_losses)\n",
    "      emb_2 = block(emb_2, additional_losses)\n",
    "    \n",
    "    x = self.classifier((emb_1, emb_2))\n",
    "\n",
    "    return x, additional_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zxf0c1qJ5oL9",
    "outputId": "5141df9a-61c0-4940-fcb6-091bbe1cf029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1638402 params, ratio 1.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91a60fd290>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_schedule(warmup_steps):\n",
    "  def lr_schedule(step):\n",
    "    return 1.0 * np.minimum(1.0, step / warmup_steps) / np.sqrt(np.maximum(step, warmup_steps))\n",
    "\n",
    "  return lr_schedule\n",
    "\n",
    "lr=0.05\n",
    "weight_decay=0.1\n",
    "warmup=8000\n",
    "\n",
    "\n",
    "def const_schedule(lr):\n",
    "  def lr_schedule(step):\n",
    "    return lr\n",
    "  return lr_schedule\n",
    "\n",
    "def training_setup():\n",
    "  model = model_factory()\n",
    "  criterion = nn.CrossEntropyLoss().cuda()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  schedule_func = get_schedule(warmup)\n",
    "  #schedule_func = const_schedule(1.0) #<--------- TEMPORARY\n",
    "  scheduler = LambdaLR(optimizer, schedule_func)\n",
    "\n",
    "  return model, criterion, optimizer, schedule_func, scheduler\n",
    "\n",
    "_, _, _, schedule_func, _ = training_setup()\n",
    "\n",
    "plt.plot([ lr * schedule_func(i) for i in range(15000) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y62BRmNo5jQ6",
    "outputId": "40c2a2d6-d022-4f7d-9c40-dcd42a7e1921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model 1601538 params, new model 1638402 params, ratio 1.02\n",
      "Epoch 0\n",
      "[====================] 200/200: - running_loss: 0.6814 - running_reg: 0.000000 - running_acc: 0.5745 - lr: 0.00001 - epoch_loss: 0.6898 - epoch_reg: 0.000000 - epoch_acc: 0.5250 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 161.0362 s\n",
      "Epoch 1\n",
      "[====================] 200/200: - running_loss: 0.6902 - running_reg: 0.000000 - running_acc: 0.5285 - lr: 0.00003 - epoch_loss: 0.6895 - epoch_reg: 0.000000 - epoch_acc: 0.5250 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.2427 s\n",
      "Epoch 2\n",
      "[====================] 200/200: - running_loss: 0.6938 - running_reg: 0.000000 - running_acc: 0.4972 - lr: 0.00004 - epoch_loss: 0.6936 - epoch_reg: 0.000000 - epoch_acc: 0.5016 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.4205 s\n",
      "Epoch 3\n",
      "[====================] 200/200: - running_loss: 0.6952 - running_reg: 0.000000 - running_acc: 0.5122 - lr: 0.00006 - epoch_loss: 0.6927 - epoch_reg: 0.000000 - epoch_acc: 0.5133 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.5801 s\n",
      "Epoch 4\n",
      "[====================] 200/200: - running_loss: 0.6931 - running_reg: 0.000000 - running_acc: 0.5225 - lr: 0.00007 - epoch_loss: 0.6934 - epoch_reg: 0.000000 - epoch_acc: 0.5144 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 156.0166 s\n",
      "Epoch 5\n",
      "[====================] 200/200: - running_loss: 0.6888 - running_reg: 0.000000 - running_acc: 0.5359 - lr: 0.00008 - epoch_loss: 0.6910 - epoch_reg: 0.000000 - epoch_acc: 0.5275 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 156.1096 s\n",
      "Epoch 6\n",
      "[====================] 200/200: - running_loss: 0.6023 - running_reg: 0.000000 - running_acc: 0.6800 - lr: 0.00010 - epoch_loss: 0.6369 - epoch_reg: 0.000000 - epoch_acc: 0.6297 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.5346 s\n",
      "Epoch 7\n",
      "[====================] 200/200: - running_loss: 0.6070 - running_reg: 0.000000 - running_acc: 0.6630 - lr: 0.00011 - epoch_loss: 0.5926 - epoch_reg: 0.000000 - epoch_acc: 0.6841 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.2169 s\n",
      "Epoch 8\n",
      "[====================] 200/200: - running_loss: 0.6607 - running_reg: 0.000000 - running_acc: 0.6173 - lr: 0.00013 - epoch_loss: 0.6256 - epoch_reg: 0.000000 - epoch_acc: 0.6302 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.3427 s\n",
      "Epoch 9\n",
      "[====================] 200/200: - running_loss: 0.5872 - running_reg: 0.000000 - running_acc: 0.6772 - lr: 0.00014 - epoch_loss: 0.6231 - epoch_reg: 0.000000 - epoch_acc: 0.6355 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.9611 s\n",
      "Epoch 10\n",
      "[====================] 200/200: - running_loss: 0.5579 - running_reg: 0.000000 - running_acc: 0.7026 - lr: 0.00015 - epoch_loss: 0.5912 - epoch_reg: 0.000000 - epoch_acc: 0.6755 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.7152 s\n",
      "Epoch 11\n",
      "[====================] 200/200: - running_loss: 0.5691 - running_reg: 0.000000 - running_acc: 0.6726 - lr: 0.00017 - epoch_loss: 0.6000 - epoch_reg: 0.000000 - epoch_acc: 0.6625 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.9024 s\n",
      "Epoch 12\n",
      "[====================] 200/200: - running_loss: 0.6033 - running_reg: 0.000000 - running_acc: 0.6720 - lr: 0.00018 - epoch_loss: 0.6024 - epoch_reg: 0.000000 - epoch_acc: 0.6614 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.8895 s\n",
      "Epoch 13\n",
      "[====================] 200/200: - running_loss: 0.6131 - running_reg: 0.000000 - running_acc: 0.6571 - lr: 0.00020 - epoch_loss: 0.6024 - epoch_reg: 0.000000 - epoch_acc: 0.6625 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.7891 s\n",
      "Epoch 14\n",
      "[====================] 200/200: - running_loss: 0.6005 - running_reg: 0.000000 - running_acc: 0.6783 - lr: 0.00021 - epoch_loss: 0.6128 - epoch_reg: 0.000000 - epoch_acc: 0.6522 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 154.9877 s\n",
      "Epoch 15\n",
      "[====================] 200/200: - running_loss: 0.5319 - running_reg: 0.000000 - running_acc: 0.7330 - lr: 0.00022 - epoch_loss: 0.5773 - epoch_reg: 0.000000 - epoch_acc: 0.6795 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.0045 s\n",
      "Epoch 16\n",
      "[====================] 200/200: - running_loss: 0.5585 - running_reg: 0.000000 - running_acc: 0.6962 - lr: 0.00024 - epoch_loss: 0.5325 - epoch_reg: 0.000000 - epoch_acc: 0.7234 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 154.8947 s\n",
      "Epoch 17\n",
      "[====================] 200/200: - running_loss: 0.5928 - running_reg: 0.000000 - running_acc: 0.6988 - lr: 0.00025 - epoch_loss: 0.5708 - epoch_reg: 0.000000 - epoch_acc: 0.6972 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.2605 s\n",
      "Epoch 18\n",
      "[====================] 200/200: - running_loss: 0.6371 - running_reg: 0.000000 - running_acc: 0.6539 - lr: 0.00027 - epoch_loss: 0.6156 - epoch_reg: 0.000000 - epoch_acc: 0.6591 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.3652 s\n",
      "Epoch 19\n",
      "[====================] 200/200: - running_loss: 0.6494 - running_reg: 0.000000 - running_acc: 0.6218 - lr: 0.00028 - epoch_loss: 0.6336 - epoch_reg: 0.000000 - epoch_acc: 0.6319 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.0041 s\n",
      "Epoch 20\n",
      "[====================] 200/200: - running_loss: 0.6438 - running_reg: 0.000000 - running_acc: 0.6053 - lr: 0.00029 - epoch_loss: 0.6333 - epoch_reg: 0.000000 - epoch_acc: 0.6292 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.1358 s\n",
      "Epoch 21\n",
      "[====================] 200/200: - running_loss: 0.6270 - running_reg: 0.000000 - running_acc: 0.6165 - lr: 0.00031 - epoch_loss: 0.6160 - epoch_reg: 0.000000 - epoch_acc: 0.6384 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.0692 s\n",
      "Epoch 22\n",
      "[====================] 200/200: - running_loss: 0.6119 - running_reg: 0.000000 - running_acc: 0.6409 - lr: 0.00032 - epoch_loss: 0.6036 - epoch_reg: 0.000000 - epoch_acc: 0.6567 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 157.4140 s\n",
      "Epoch 23\n",
      "[====================] 200/200: - running_loss: 0.5537 - running_reg: 0.000000 - running_acc: 0.6950 - lr: 0.00034 - epoch_loss: 0.5579 - epoch_reg: 0.000000 - epoch_acc: 0.7005 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.1008 s\n",
      "Epoch 24\n",
      "[====================] 200/200: - running_loss: 0.5839 - running_reg: 0.000000 - running_acc: 0.6781 - lr: 0.00035 - epoch_loss: 0.5737 - epoch_reg: 0.000000 - epoch_acc: 0.6933 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.6471 s\n",
      "Epoch 25\n",
      "[====================] 200/200: - running_loss: 0.5814 - running_reg: 0.000000 - running_acc: 0.6687 - lr: 0.00036 - epoch_loss: 0.5947 - epoch_reg: 0.000000 - epoch_acc: 0.6723 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.8812 s\n",
      "Epoch 26\n",
      "[====================] 200/200: - running_loss: 0.6005 - running_reg: 0.000000 - running_acc: 0.6729 - lr: 0.00038 - epoch_loss: 0.5946 - epoch_reg: 0.000000 - epoch_acc: 0.6725 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.6905 s\n",
      "Epoch 27\n",
      "[====================] 200/200: - running_loss: 0.5477 - running_reg: 0.000000 - running_acc: 0.7236 - lr: 0.00039 - epoch_loss: 0.5744 - epoch_reg: 0.000000 - epoch_acc: 0.6820 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.8052 s\n",
      "Epoch 28\n",
      "[====================] 200/200: - running_loss: 0.4944 - running_reg: 0.000000 - running_acc: 0.7660 - lr: 0.00041 - epoch_loss: 0.5200 - epoch_reg: 0.000000 - epoch_acc: 0.7392 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.2316 s\n",
      "Epoch 29\n",
      "[====================] 200/200: - running_loss: 0.3982 - running_reg: 0.000000 - running_acc: 0.8184 - lr: 0.00042 - epoch_loss: 0.4306 - epoch_reg: 0.000000 - epoch_acc: 0.7983 - valid_loss: 0.0000 - valid_reg: 0.000000 - valid_acc: 0.0000 - epoch_time: 155.1859 s\n",
      "Epoch 30\n",
      "[====================] 200/200: - running_loss: 0.4056 - running_reg: 0.000000 - running_acc: 0.8260 - lr: 0.00043 - epoch_loss: 0.4018 - epoch_reg: 0.000000 - epoch_acc: 0.8173 - valid_loss: 0.6952 - valid_reg: 0.000000 - valid_acc: 0.6268 - epoch_time: 329.2436 s\n",
      "Epoch 31\n",
      "[====================] 200/200: - running_loss: 0.5027 - running_reg: 0.000000 - running_acc: 0.7549 - lr: 0.00045 - epoch_loss: 0.4850 - epoch_reg: 0.000000 - epoch_acc: 0.7611 - valid_loss: 0.6424 - valid_reg: 0.000000 - valid_acc: 0.6427 - epoch_time: 336.7076 s\n",
      "Epoch 32\n",
      "[====================] 200/200: - running_loss: 0.4428 - running_reg: 0.000000 - running_acc: 0.7877 - lr: 0.00046 - epoch_loss: 0.4768 - epoch_reg: 0.000000 - epoch_acc: 0.7661 - valid_loss: 0.6685 - valid_reg: 0.000000 - valid_acc: 0.6525 - epoch_time: 339.0560 s\n",
      "Epoch 33\n",
      "[====================] 200/200: - running_loss: 0.4547 - running_reg: 0.000000 - running_acc: 0.7814 - lr: 0.00048 - epoch_loss: 0.4695 - epoch_reg: 0.000000 - epoch_acc: 0.7681 - valid_loss: 0.7257 - valid_reg: 0.000000 - valid_acc: 0.6252 - epoch_time: 338.1967 s\n",
      "Epoch 34\n",
      "[====================] 200/200: - running_loss: 0.4551 - running_reg: 0.000000 - running_acc: 0.7708 - lr: 0.00049 - epoch_loss: 0.4430 - epoch_reg: 0.000000 - epoch_acc: 0.7867 - valid_loss: 0.6775 - valid_reg: 0.000000 - valid_acc: 0.6481 - epoch_time: 338.1756 s\n",
      "Epoch 35\n",
      "[====================] 200/200: - running_loss: 0.4965 - running_reg: 0.000000 - running_acc: 0.7464 - lr: 0.00050 - epoch_loss: 0.4525 - epoch_reg: 0.000000 - epoch_acc: 0.7748 - valid_loss: 0.7665 - valid_reg: 0.000000 - valid_acc: 0.6547 - epoch_time: 337.5280 s\n",
      "Epoch 36\n",
      "[====================] 200/200: - running_loss: 0.5024 - running_reg: 0.000000 - running_acc: 0.7409 - lr: 0.00052 - epoch_loss: 0.4991 - epoch_reg: 0.000000 - epoch_acc: 0.7497 - valid_loss: 0.8704 - valid_reg: 0.000000 - valid_acc: 0.6369 - epoch_time: 339.1729 s\n",
      "Epoch 37\n",
      "[====================] 200/200: - running_loss: 0.5301 - running_reg: 0.000000 - running_acc: 0.7399 - lr: 0.00053 - epoch_loss: 0.5286 - epoch_reg: 0.000000 - epoch_acc: 0.7380 - valid_loss: 0.6011 - valid_reg: 0.000000 - valid_acc: 0.6779 - epoch_time: 337.5435 s\n",
      "Epoch 38\n",
      "[====================] 200/200: - running_loss: 0.4992 - running_reg: 0.000000 - running_acc: 0.7642 - lr: 0.00054 - epoch_loss: 0.5221 - epoch_reg: 0.000000 - epoch_acc: 0.7316 - valid_loss: 0.6316 - valid_reg: 0.000000 - valid_acc: 0.6707 - epoch_time: 337.7823 s\n",
      "Epoch 39\n",
      "[====================] 200/200: - running_loss: 0.5216 - running_reg: 0.000000 - running_acc: 0.7652 - lr: 0.00056 - epoch_loss: 0.4941 - epoch_reg: 0.000000 - epoch_acc: 0.7633 - valid_loss: 0.6297 - valid_reg: 0.000000 - valid_acc: 0.6560 - epoch_time: 337.7262 s\n",
      "Epoch 40\n",
      "[====================] 200/200: - running_loss: 0.5326 - running_reg: 0.000000 - running_acc: 0.7373 - lr: 0.00055 - epoch_loss: 0.5256 - epoch_reg: 0.000000 - epoch_acc: 0.7316 - valid_loss: 0.5890 - valid_reg: 0.000000 - valid_acc: 0.6873 - epoch_time: 339.8095 s\n",
      "Epoch 41\n",
      "[====================] 200/200: - running_loss: 0.5674 - running_reg: 0.000000 - running_acc: 0.6885 - lr: 0.00055 - epoch_loss: 0.5616 - epoch_reg: 0.000000 - epoch_acc: 0.7072 - valid_loss: 0.5621 - valid_reg: 0.000000 - valid_acc: 0.7041 - epoch_time: 340.1254 s\n",
      "Epoch 42\n",
      "[====================] 200/200: - running_loss: 0.5760 - running_reg: 0.000000 - running_acc: 0.7082 - lr: 0.00054 - epoch_loss: 0.5626 - epoch_reg: 0.000000 - epoch_acc: 0.6986 - valid_loss: 0.5964 - valid_reg: 0.000000 - valid_acc: 0.6763 - epoch_time: 338.7727 s\n",
      "Epoch 43\n",
      "[====================] 200/200: - running_loss: 0.5670 - running_reg: 0.000000 - running_acc: 0.7099 - lr: 0.00053 - epoch_loss: 0.5713 - epoch_reg: 0.000000 - epoch_acc: 0.6925 - valid_loss: 0.5837 - valid_reg: 0.000000 - valid_acc: 0.6759 - epoch_time: 338.4898 s\n",
      "Epoch 44\n",
      "[====================] 200/200: - running_loss: 0.5508 - running_reg: 0.000000 - running_acc: 0.7023 - lr: 0.00053 - epoch_loss: 0.5601 - epoch_reg: 0.000000 - epoch_acc: 0.6916 - valid_loss: 0.5888 - valid_reg: 0.000000 - valid_acc: 0.6753 - epoch_time: 337.7051 s\n",
      "Epoch 45\n",
      "[====================] 200/200: - running_loss: 0.5961 - running_reg: 0.000000 - running_acc: 0.6702 - lr: 0.00052 - epoch_loss: 0.5336 - epoch_reg: 0.000000 - epoch_acc: 0.7189 - valid_loss: 0.6089 - valid_reg: 0.000000 - valid_acc: 0.6589 - epoch_time: 342.0288 s\n",
      "Epoch 46\n",
      "[====================] 200/200: - running_loss: 0.5192 - running_reg: 0.000000 - running_acc: 0.7436 - lr: 0.00052 - epoch_loss: 0.5313 - epoch_reg: 0.000000 - epoch_acc: 0.7172 - valid_loss: 0.5853 - valid_reg: 0.000000 - valid_acc: 0.6844 - epoch_time: 340.6982 s\n",
      "Epoch 47\n",
      "[====================] 200/200: - running_loss: 0.5162 - running_reg: 0.000000 - running_acc: 0.7441 - lr: 0.00051 - epoch_loss: 0.5259 - epoch_reg: 0.000000 - epoch_acc: 0.7344 - valid_loss: 0.5868 - valid_reg: 0.000000 - valid_acc: 0.6837 - epoch_time: 343.1602 s\n",
      "Epoch 48\n",
      "[====================] 200/200: - running_loss: 0.5383 - running_reg: 0.000000 - running_acc: 0.7364 - lr: 0.00051 - epoch_loss: 0.5354 - epoch_reg: 0.000000 - epoch_acc: 0.7259 - valid_loss: 0.6318 - valid_reg: 0.000000 - valid_acc: 0.6442 - epoch_time: 342.0691 s\n",
      "Epoch 49\n",
      "[====================] 200/200: - running_loss: 0.5340 - running_reg: 0.000000 - running_acc: 0.7342 - lr: 0.00050 - epoch_loss: 0.5438 - epoch_reg: 0.000000 - epoch_acc: 0.7167 - valid_loss: 0.5716 - valid_reg: 0.000000 - valid_acc: 0.6967 - epoch_time: 341.7609 s\n",
      "Epoch 50\n",
      "[====================] 200/200: - running_loss: 0.4707 - running_reg: 0.000000 - running_acc: 0.7904 - lr: 0.00050 - epoch_loss: 0.5017 - epoch_reg: 0.000000 - epoch_acc: 0.7466 - valid_loss: 0.5854 - valid_reg: 0.000000 - valid_acc: 0.6957 - epoch_time: 342.1950 s\n",
      "Epoch 51\n",
      "[====================] 200/200: - running_loss: 0.3506 - running_reg: 0.000000 - running_acc: 0.8430 - lr: 0.00049 - epoch_loss: 0.3987 - epoch_reg: 0.000000 - epoch_acc: 0.8139 - valid_loss: 0.6654 - valid_reg: 0.000000 - valid_acc: 0.6605 - epoch_time: 343.5972 s\n",
      "Epoch 52\n",
      "[====================] 200/200: - running_loss: 0.2865 - running_reg: 0.000000 - running_acc: 0.8792 - lr: 0.00049 - epoch_loss: 0.2963 - epoch_reg: 0.000000 - epoch_acc: 0.8739 - valid_loss: 0.6667 - valid_reg: 0.000000 - valid_acc: 0.6435 - epoch_time: 342.7806 s\n",
      "Epoch 53\n",
      "[====================] 200/200: - running_loss: 0.3333 - running_reg: 0.000000 - running_acc: 0.8517 - lr: 0.00048 - epoch_loss: 0.3146 - epoch_reg: 0.000000 - epoch_acc: 0.8641 - valid_loss: 0.6712 - valid_reg: 0.000000 - valid_acc: 0.6622 - epoch_time: 342.3106 s\n",
      "Epoch 54\n",
      "[====================] 200/200: - running_loss: 0.4128 - running_reg: 0.000000 - running_acc: 0.7977 - lr: 0.00048 - epoch_loss: 0.3800 - epoch_reg: 0.000000 - epoch_acc: 0.8288 - valid_loss: 0.5688 - valid_reg: 0.000000 - valid_acc: 0.7149 - epoch_time: 341.9168 s\n",
      "Epoch 55\n",
      "[====================] 200/200: - running_loss: 0.3567 - running_reg: 0.000000 - running_acc: 0.8267 - lr: 0.00047 - epoch_loss: 0.3921 - epoch_reg: 0.000000 - epoch_acc: 0.8153 - valid_loss: 0.6356 - valid_reg: 0.000000 - valid_acc: 0.6808 - epoch_time: 341.9218 s\n",
      "Epoch 56\n",
      "[====================] 200/200: - running_loss: 0.3344 - running_reg: 0.000000 - running_acc: 0.8539 - lr: 0.00047 - epoch_loss: 0.3568 - epoch_reg: 0.000000 - epoch_acc: 0.8361 - valid_loss: 0.6946 - valid_reg: 0.000000 - valid_acc: 0.6815 - epoch_time: 341.0667 s\n",
      "Epoch 57\n",
      "[====================] 200/200: - running_loss: 0.3705 - running_reg: 0.000000 - running_acc: 0.8310 - lr: 0.00046 - epoch_loss: 0.3431 - epoch_reg: 0.000000 - epoch_acc: 0.8492 - valid_loss: 0.6435 - valid_reg: 0.000000 - valid_acc: 0.6880 - epoch_time: 343.1058 s\n",
      "Epoch 58\n",
      "[====================] 200/200: - running_loss: 0.3967 - running_reg: 0.000000 - running_acc: 0.8319 - lr: 0.00046 - epoch_loss: 0.3664 - epoch_reg: 0.000000 - epoch_acc: 0.8381 - valid_loss: 0.8062 - valid_reg: 0.000000 - valid_acc: 0.6767 - epoch_time: 341.8049 s\n",
      "Epoch 59\n",
      "[====================] 200/200: - running_loss: 0.4475 - running_reg: 0.000000 - running_acc: 0.7704 - lr: 0.00046 - epoch_loss: 0.4216 - epoch_reg: 0.000000 - epoch_acc: 0.7991 - valid_loss: 0.7322 - valid_reg: 0.000000 - valid_acc: 0.6781 - epoch_time: 341.6872 s\n",
      "Epoch 60\n",
      "[====================] 200/200: - running_loss: 0.4527 - running_reg: 0.000000 - running_acc: 0.7703 - lr: 0.00045 - epoch_loss: 0.4740 - epoch_reg: 0.000000 - epoch_acc: 0.7689 - valid_loss: 0.5462 - valid_reg: 0.000000 - valid_acc: 0.7297 - epoch_time: 341.3766 s\n",
      "Epoch 61\n",
      "[====================] 200/200: - running_loss: 0.4460 - running_reg: 0.000000 - running_acc: 0.8008 - lr: 0.00045 - epoch_loss: 0.4604 - epoch_reg: 0.000000 - epoch_acc: 0.7784 - valid_loss: 0.5618 - valid_reg: 0.000000 - valid_acc: 0.7059 - epoch_time: 341.6083 s\n",
      "Epoch 62\n",
      "[====================] 200/200: - running_loss: 0.4589 - running_reg: 0.000000 - running_acc: 0.7789 - lr: 0.00045 - epoch_loss: 0.4269 - epoch_reg: 0.000000 - epoch_acc: 0.8027 - valid_loss: 0.5462 - valid_reg: 0.000000 - valid_acc: 0.7268 - epoch_time: 342.6759 s\n",
      "Epoch 63\n",
      "[====================] 200/200: - running_loss: 0.4813 - running_reg: 0.000000 - running_acc: 0.7703 - lr: 0.00044 - epoch_loss: 0.4650 - epoch_reg: 0.000000 - epoch_acc: 0.7742 - valid_loss: 0.5416 - valid_reg: 0.000000 - valid_acc: 0.7104 - epoch_time: 342.3018 s\n",
      "Epoch 64\n",
      "[====================] 200/200: - running_loss: 0.4858 - running_reg: 0.000000 - running_acc: 0.7654 - lr: 0.00044 - epoch_loss: 0.4928 - epoch_reg: 0.000000 - epoch_acc: 0.7541 - valid_loss: 0.5185 - valid_reg: 0.000000 - valid_acc: 0.7331 - epoch_time: 341.8045 s\n",
      "Epoch 65\n",
      "[====================] 200/200: - running_loss: 0.4754 - running_reg: 0.000000 - running_acc: 0.7602 - lr: 0.00044 - epoch_loss: 0.4868 - epoch_reg: 0.000000 - epoch_acc: 0.7556 - valid_loss: 0.5451 - valid_reg: 0.000000 - valid_acc: 0.7313 - epoch_time: 342.1582 s\n",
      "Epoch 66\n",
      "[====================] 200/200: - running_loss: 0.4990 - running_reg: 0.000000 - running_acc: 0.7355 - lr: 0.00043 - epoch_loss: 0.5152 - epoch_reg: 0.000000 - epoch_acc: 0.7325 - valid_loss: 0.5290 - valid_reg: 0.000000 - valid_acc: 0.7344 - epoch_time: 343.4417 s\n",
      "Epoch 67\n",
      "[====================] 200/200: - running_loss: 0.4930 - running_reg: 0.000000 - running_acc: 0.7349 - lr: 0.00043 - epoch_loss: 0.5122 - epoch_reg: 0.000000 - epoch_acc: 0.7237 - valid_loss: 0.5725 - valid_reg: 0.000000 - valid_acc: 0.6808 - epoch_time: 341.7783 s\n",
      "Epoch 68\n",
      "[====================] 200/200: - running_loss: 0.5271 - running_reg: 0.000000 - running_acc: 0.7189 - lr: 0.00043 - epoch_loss: 0.4914 - epoch_reg: 0.000000 - epoch_acc: 0.7427 - valid_loss: 0.5495 - valid_reg: 0.000000 - valid_acc: 0.7131 - epoch_time: 342.1181 s\n",
      "Epoch 69\n",
      "[====================] 200/200: - running_loss: 0.4683 - running_reg: 0.000000 - running_acc: 0.7821 - lr: 0.00042 - epoch_loss: 0.4924 - epoch_reg: 0.000000 - epoch_acc: 0.7558 - valid_loss: 0.5501 - valid_reg: 0.000000 - valid_acc: 0.7135 - epoch_time: 340.9512 s\n",
      "Epoch 70\n",
      "[====================] 200/200: - running_loss: 0.4716 - running_reg: 0.000000 - running_acc: 0.7741 - lr: 0.00042 - epoch_loss: 0.4707 - epoch_reg: 0.000000 - epoch_acc: 0.7677 - valid_loss: 0.5726 - valid_reg: 0.000000 - valid_acc: 0.7093 - epoch_time: 343.8394 s\n",
      "Epoch 71\n",
      "[====================] 200/200: - running_loss: 0.4955 - running_reg: 0.000000 - running_acc: 0.7370 - lr: 0.00042 - epoch_loss: 0.4694 - epoch_reg: 0.000000 - epoch_acc: 0.7672 - valid_loss: 0.5713 - valid_reg: 0.000000 - valid_acc: 0.6960 - epoch_time: 341.9957 s\n",
      "Epoch 72\n",
      "[====================] 200/200: - running_loss: 0.4810 - running_reg: 0.000000 - running_acc: 0.7625 - lr: 0.00041 - epoch_loss: 0.4634 - epoch_reg: 0.000000 - epoch_acc: 0.7728 - valid_loss: 0.5232 - valid_reg: 0.000000 - valid_acc: 0.7364 - epoch_time: 342.5656 s\n",
      "Epoch 73\n",
      "[====================] 200/200: - running_loss: 0.4054 - running_reg: 0.000000 - running_acc: 0.8073 - lr: 0.00041 - epoch_loss: 0.4314 - epoch_reg: 0.000000 - epoch_acc: 0.7945 - valid_loss: 0.5606 - valid_reg: 0.000000 - valid_acc: 0.7158 - epoch_time: 343.0910 s\n",
      "Epoch 74\n",
      "[====================] 200/200: - running_loss: 0.2953 - running_reg: 0.000000 - running_acc: 0.8660 - lr: 0.00041 - epoch_loss: 0.3440 - epoch_reg: 0.000000 - epoch_acc: 0.8439 - valid_loss: 0.5865 - valid_reg: 0.000000 - valid_acc: 0.7023 - epoch_time: 343.2836 s\n",
      " - test_loss: 0.5327 - test_reg: 0.000000 - test_acc: 0.7260 - test_time: 166.7084 s\n",
      "\n",
      "Total accuracy: 0.7260\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(1): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup()\n",
    "\n",
    "  checkpoint = train_model(model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler, accumulation_steps, 75, 200, skip_eval=30)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = test(model, criterion, test_dataset)\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eys0HpXq5o5R"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "Copy of bpe_matching_setup_lka.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
