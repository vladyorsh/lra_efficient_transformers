{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d742373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yorshula/yorshula_master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce3729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lra.layers import *\n",
    "from lra.models import *\n",
    "from lra.setups import *\n",
    "from lra.utils  import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yorshula/long-range-arena')\n",
    "\n",
    "from lra_benchmarks.text_classification.input_pipeline import get_tc_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa77154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:38:52.393137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.395647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.459918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.462208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.464264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.466310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:52.471323: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 12:38:53.124344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:53.126550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:53.128605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:53.130198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:53.131904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:38:53.133428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.678762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.681219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.683347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.685095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.686830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.688823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36541 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:01.0, compute capability: 8.0\n",
      "2022-05-02 12:39:12.690972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 12:39:12.692793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 36541 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:02.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:39:13.943036: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "INFO:tensorflow:Finished preprocessing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:<MapDataset element_spec={'Source': TensorSpec(shape=(), dtype=tf.string, name=None), 'Target': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:<MapDataset element_spec={'Source': TensorSpec(shape=(), dtype=tf.string, name=None), 'Target': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset, encoder = get_tc_datasets(1, 'imdb_reviews', batch_size=BPE_CLS_SETUP['batch_size'], max_length=BPE_CLS_SETUP['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19bf20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BPE_CLS_SETUP['device'] = 'cuda:1'\n",
    "#LISTOPS_SETUP['model_type'] = ClassificationTransformerSkip\n",
    "\n",
    "def att_factory(hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    \n",
    "    lka = nn.Sequential(\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.0),\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.0),\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False, LAMBDA=0.0),\n",
    "        \n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.1),\n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.1),\n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False, LAMBDA=0.1)\n",
    "\n",
    "        #HeadWiseFF(num_heads, qkv_dim, dropout_rate, nn.Softplus(), use_bias=False, LAMBDA=0.1),   \n",
    "    )\n",
    "    return LKAAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, lka)\n",
    "    \n",
    "    #return FtAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "    #return SimpleAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, use_lin=True)\n",
    "    #return SimpleAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, use_lin=False)\n",
    "\n",
    "model, criterion, optimizer, schedule_func, scheduler = training_setup(BPE_CLS_SETUP, encoder.vocab_size, att_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "BPE_CLS_SETUP['device'] = 'cuda:1'\n",
    "#BPE_CLS_SETUP['steps'] = 20\n",
    "#BPE_CLS_SETUP['eval_period'] = 10\n",
    "\n",
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(1): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup(BPE_CLS_SETUP, encoder.vocab_size, att_factory)\n",
    "\n",
    "  checkpoint = train_cls_model(BPE_CLS_SETUP, model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = cls_test(model, criterion, test_dataset, BPE_CLS_SETUP['device'])\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1760925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationTransformer(\n",
       "  (embed_layer): TEmbedding(\n",
       "    (embedding): Embedding(257, 256, padding_idx=0)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): TBlock(\n",
       "      (layernorm_input): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TBlock(\n",
       "      (layernorm_input): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TBlock(\n",
       "      (layernorm_input): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TBlock(\n",
       "      (layernorm_input): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): TClassifier(\n",
       "    (layernorm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (ffn): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (1): GELU()\n",
       "    )\n",
       "    (output): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58714f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
