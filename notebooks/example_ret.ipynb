{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d742373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yorshula/yorshula_master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce3729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lra.layers import *\n",
    "from lra.models import *\n",
    "from lra.setups import *\n",
    "from lra.utils  import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yorshula/long-range-arena')\n",
    "\n",
    "\n",
    "from lra_benchmarks.matching.input_pipeline import get_matching_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa77154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/yorshula/lra_release/lra_release/tsv_data/new_aan_pairs.train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 13:38:44.104118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/yorshula/lra_release/lra_release/tsv_data/new_aan_pairs.eval.tsv\n",
      "INFO:tensorflow:/home/yorshula/lra_release/lra_release/tsv_data/new_aan_pairs.test.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 13:38:44.106400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.150964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.153047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.154822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.156536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.159473: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 13:38:44.808838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.811066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.813065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.814811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.816502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:38:44.818206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.839161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.847161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.849202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.850962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.852664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.854527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 35010 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:01.0, compute capability: 8.0\n",
      "2022-05-02 13:39:02.855835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 13:39:02.857593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 34302 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:02.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished getting dataset.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset, encoder = get_matching_datasets(1, None, tokenizer='char', data_dir='/home/yorshula/lra_release/lra_release/tsv_data', batch_size=BPE_MATCH_SETUP['batch_size'], max_length=BPE_MATCH_SETUP['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ed327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BPE_MATCH_SETUP['device'] = 'cuda:1'\n",
    "#LISTOPS_SETUP['model_type'] = MatchingTransformerSkip\n",
    "\n",
    "def att_factory(hidden_dim, qkv_dim, num_heads, dropout_rate):\n",
    "    \n",
    "    lka = nn.Sequential(\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.0),\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.0),\n",
    "        AMGOLU(num_heads, qkv_dim, qkv_dim // num_heads // 4, dropout_rate, nn.Sigmoid(), nn.Softplus(), False, LAMBDA=0.0),\n",
    "        \n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.1),\n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Identity(), False, LAMBDA=0.1),\n",
    "        #GatedOrthoKernel(num_heads, hidden_dim, dropout_rate, nn.Sigmoid(), nn.Softplus(), False, LAMBDA=0.1)\n",
    "\n",
    "        #HeadWiseFF(num_heads, qkv_dim, dropout_rate, nn.Softplus(), use_bias=False, LAMBDA=0.1),   \n",
    "    )\n",
    "    return LKAAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, lka)\n",
    "    \n",
    "    #return FtAttention(hidden_dim, qkv_dim, num_heads, dropout_rate)\n",
    "    #return SimpleAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, use_lin=True)\n",
    "    #return SimpleAttention(hidden_dim, qkv_dim, num_heads, dropout_rate, use_lin=False)\n",
    "\n",
    "model, criterion, optimizer, schedule_func, scheduler = training_setup(BPE_MATCH_SETUP, encoder.vocab_size, att_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f22cbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 13:42:49.000637: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1270 of 2048\n",
      "2022-05-02 13:42:53.181697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 10/10: - running_loss: 0.6936 - running_reg: 0.000000 - running_acc: 0.5242 - lr: 0.00000 - epoch_loss: 0.6937 - epoch_reg: 0.000000 - epoch_acc: 0.5188 - valid_loss: 0.6932 - valid_reg: 0.000000 - valid_acc: 0.5045 - epoch_time: 326.8389 s\n",
      "Epoch 1\n",
      "[====================] 10/10: - running_loss: 0.6948 - running_reg: 0.000000 - running_acc: 0.4552 - lr: 0.00000 - epoch_loss: 0.6951 - epoch_reg: 0.000000 - epoch_acc: 0.4469 - valid_loss: 0.6932 - valid_reg: 0.000000 - valid_acc: 0.5045 - epoch_time: 305.2100 s\n",
      " - test_loss: 0.6931 - test_reg: 0.000000 - test_acc: 0.5061 - test_time: 282.7273 s\n",
      "\n",
      "Total accuracy: 0.5061\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "BPE_MATCH_SETUP['device'] = 'cuda:1'\n",
    "#BPE_MATCH_SETUP['steps'] = 20\n",
    "#BPE_MATCH_SETUP['eval_period'] = 10\n",
    "\n",
    "test_accuracy = [  ]\n",
    "\n",
    "for i in range(1): ####!!!!!!!!!!!!!!\n",
    "  path = 'model_to_test_' + str(i) + '.b'\n",
    "\n",
    "  model, criterion, optimizer, schedule_func, scheduler = training_setup(BPE_MATCH_SETUP, encoder.vocab_size, att_factory)\n",
    "\n",
    "  checkpoint = train_matching_model(BPE_MATCH_SETUP, model, path, train_dataset, valid_dataset, optimizer, criterion, scheduler)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  \n",
    "  _, _, acc = matching_test(model, criterion, test_dataset, BPE_CLS_SETUP['device'])\n",
    "  test_accuracy.append(acc)\n",
    "\n",
    "test_accuracy = np.mean(test_accuracy)\n",
    "\n",
    "print(f'\\nTotal accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9fa8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingTransformer(\n",
       "  (embed_layer): TEmbedding(\n",
       "    (embedding): Embedding(257, 128, padding_idx=0)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): TBlock(\n",
       "      (layernorm_input): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): TBlock(\n",
       "      (layernorm_input): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): TBlock(\n",
       "      (layernorm_input): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): TBlock(\n",
       "      (layernorm_input): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (layernorm_inter): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (attention): LKAAttention(\n",
       "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (lka): Sequential(\n",
       "          (0): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Identity()\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): AMGOLU(\n",
       "            (orth_weight): HWLinear()\n",
       "            (gate_weight_a): HWLinear()\n",
       "            (gate_weight_b): HWLinear()\n",
       "            (kernel_nonlinearity): Softplus(beta=1, threshold=20)\n",
       "            (gate_nonlinearity): Sigmoid()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): GELU()\n",
       "        (5): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DualClassifier(\n",
       "    (ffn): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (output): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410e297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7299c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
